# Оглавление

I. **Введение в нейронные сети**
*   История и основы нейронных сетей.
*   Модель персептрона.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пороговая функция.
    *   Пример кода.
    *   Физический и геометрический смысл.

II. **Оптимизация персептрона**
*   Критерий персептрона и его оптимизация.
    *   Объяснение концепции.
    *   Математическая формализация.
*   Метод градиентного спуска.
    *   Обновление весов.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Градиентный спуск и его применение в персептроне.
    *   Обновление весов.
    *   Вычисление градиента.
    *   Пример кода.
    *   Физический и геометрический смысл.

III. **Алгоритмы обучения персептрона**
*   Алгоритм обучения персептрона с использованием случайных примеров.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Визуализация разделяющей прямой и точности.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.

IV. **Ограничения персептрона и многослойные сети**
*   Ограничения персептрона и задача исключающего ИЛИ.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Ограничения персептрона и распознавание рукописных цифр.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Обучение персептрона на распознавании цифр.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Многоклассовая классификация и метод "один против всех".
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Понижение размерности и метод главных компонент (PCA).
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.

V. **Современные нейросети**
*   Современные нейросети и многослойные персептроны.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Реализация линейного слоя в нейросети.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Линейный слой и функция softmax в нейросетях.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Функция ошибки кросс-энтропия.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Алгоритм градиентного спуска и вычисление производных.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Алгоритм обратного распространения ошибки.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Обучение нейросети и реализация класса для сети.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Обучение нейросети с промежуточными слоями.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Добавление промежуточных слоев и функций активации.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Многослойные нейросети и функции активации.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Признаки и их влияние на обучение нейросетей.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Переобучение и сложности многослойных нейросетей.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Переобучение и выбор архитектуры нейросети.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.
*   Заключение и дальнейшие шаги в обучении нейросетей.
    *   Объяснение концепции.
    *   Математическая формализация.
    *   Пример кода.
    *   Физический и геометрический смысл.

VI. **Итоговое заключение**
*   Краткое содержание основных тем.

# Введение

В к лекции будут рассмотрены основные этапы развития нейронных сетей и их применение в современных технологиях. **Персептрон**, как одна из первых моделей нейронных сетей, будет представлен как основа для понимания более сложных архитектур. Будут затронуты вопросы, связанные с историей создания персептрона, его математическим описанием и физическим смыслом, что позволит слушателям получить общее представление о принципах работы нейронных сетей.

Далее, в рамках лекции, будет рассмотрен **критерий персептрона и метод градиентного спуска**, необходимые для оптимизации весов модели и минимизации ошибок классификации. Метод градиентного спуска позволит находить оптимальные значения весов, минимизируя функцию ошибки. Также будут представлены примеры кода на языке Python, демонстрирующие реализацию основных алгоритмов и методов, используемых в нейронных сетях.

В заключительной части введения будут обозначены **ограничения персептрона**, такие как неспособность решать задачу исключающего ИЛИ (XOR), и рассмотрены возможности многослойных нейронных сетей для решения более сложных задач, например, распознавание рукописных цифр. Будет уделено внимание функциям активации, промежуточным слоям и выбору признаков, что позволит слушателям получить полное представление о современных нейросетях и их применении.

В завершение будет подчеркнута важность **предотвращения переобучения** и правильного выбора архитектуры нейросети для достижения высокой обобщающей способности модели. Лекция призвана дать слушателям как теоретические знания, так и практические навыки, необходимые для дальнейшего изучения и применения нейронных сетей в различных областях.

# Глоссарий терминов для лекции по искусственному интеллекту:

*   **Персептрон**: Простейшая модель нейронной сети, предназначенная для распознавания образов, предложенная Франком Розенблатом в 1957 году. Персептрон принимает на вход несколько сигналов, которые суммируются и обрабатываются с использованием весов для определения выходного сигнала.

*   **Веса (w)**: Параметры персептрона, определяющие важность каждого входного сигнала. Веса используются для вычисления взвешенной суммы входных данных.

*   **Пороговая функция (f)**: Функция активации, определяющая выход персептрона на основе взвешенной суммы входных данных. Если сумма превышает определенный порог (θ), нейрон "активируется" и выдает сигнал.

*   **Критерий персептрона**: Функция ошибки, используемая для оценки качества классификации данных персептроном. Критерий фокусируется на неправильно классифицированных точках.

*   **Метод градиентного спуска**: Итеративный алгоритм, используемый для минимизации функции ошибки путем обновления весов модели в направлении, противоположном градиенту.

*   **Скорость обучения (η)**: Параметр, определяющий величину шага при обновлении весов в методе градиентного спуска.

*   **Градиент (∇e(w))**: Вектор, указывающий направление наибольшего возрастания функции ошибки. В методе градиентного спуска веса обновляются в направлении, противоположном градиенту, чтобы минимизировать ошибку.

*   **Разделяющая прямая**: Линия, которая разделяет два класса в пространстве признаков. Уравнение разделяющей прямой определяется весами модели.

*   **Исключающее ИЛИ (XOR)**: Логическая операция, которая возвращает истинное значение (1), если один из входов истинный, но не оба одновременно. Персептрон не может решить задачу XOR, так как классы не линейно разделимы.

*   **Метод "один против всех" (one-vs-all)**: Подход к многоклассовой классификации, при котором для каждой категории обучается отдельный бинарный классификатор.

*   **Понижение размерности**: Процесс уменьшения количества признаков в наборе данных, сохраняя при этом наиболее важную информацию.

*   **Метод главных компонент (PCA)**: Метод понижения размерности, который проецирует многомерные данные на меньшую размерность, выделяя наиболее значимые направления (компоненты) в данных.

*   **Многослойный персептрон**: Нейронная сеть, состоящая из нескольких слоев нейронов. В отличие от однослойного персептрона, многослойные нейросети могут моделировать сложные функции и решать задачи, которые не поддаются линейной классификации.

*   **Линейный слой**: Основное вычислительное звено в нейросети, которое принимает входные данные и преобразует их в выходные значения с использованием весов и смещений.

*   **Функция softmax**: Функция, используемая для преобразования выходных значений нейронов в вероятности. Обеспечивает, чтобы сумма всех вероятностей равнялась единице.

*   **Кросс-энтропия**: Функция ошибки, используемая для оценки качества предсказаний нейросети. Измеряет различие между двумя распределениями вероятностей.

*   **Алгоритм обратного распространения ошибки**: Метод, который позволяет нейросети "учиться" на своих ошибках, вычисляя градиенты и обновляя параметры модели.

*   **Функции активации**: Нелинейные функции, добавляемые между слоями нейросети, такие как гиперболический тангенс (tanh), сигмоид (sigmoid) и ReLU (Rectified Linear Unit). Они вводят нелинейность в модель, что позволяет ей создавать сложные разделяющие поверхности.

*   **Переобучение (overfitting)**: Ситуация, когда модель слишком хорошо подстраивается под обучающие данные, что приводит к плохой обобщающей способности на новых данных.

*   **Признаки**: Входные данные, используемые для обучения модели. Правильный выбор и извлечение признаков могут значительно улучшить качество предсказаний.

---

# Summarization for Text

## Chunk 0

### **Название фрагмента: Это БАЗА**

## Принцип работы нейронной сети

Нейронные сети состоят из слоёв нейронов, где каждый нейрон выполняет простую операцию — линейную комбинацию входов с последующим применением функции активации. Это позволяет модели выражать нелинейные зависимости.

### Пример простой нейронной сети

Допустим, у нас есть нейронная сеть с тремя входами $x_1, x_2, x_3$ и двумя выходами $a_1, a_2$. Каждый выход представляет собой линейную комбинацию входов, аналогично линейной регрессии:

$$
a_i = w_{1i}x_1 + w_{2i}x_2 + w_{3i}x_3 + b_i, \quad i = 1, 2
$$

где $w_{ji}$ — веса, а $b_i$ — смещение для выхода $a_i$.

*Пояснение: Для каждого выхода $a_i$ в нейронной сети существует отдельный вектор весов $w_i$, который при умножении на вектор входных параметров $x = [x_1, x_2, ..., x_n]$ дает ожидаемый результат для этого выходного нейрона $a_i$. Это означает, что каждый выходной нейрон имеет свою уникальную линейную комбинацию входов, определенную соответствующими весами и смещением.

Математически это можно представить следующим образом для нейронной сети с $n$ входами и $m$ выходами. Для каждого выхода $a_i$ где $i = 1, 2, ..., m$:

$$
a_i = \sum_{j=1}^{n} w_{ji}x_j + b_i
$$

Здесь $w_{ji}$ является весом, связывающим $j$-й вход с $i$-м выходом, а $b_i$ — смещением для $i$-го выхода.

- **Вектор весов $w_i$** для выхода $a_i$ включает все веса, связанные с этим выходом: $w_i = [w_{1i}, w_{2i}, ..., w_{ni}]$.
- **Вектор входов $x$** состоит из всех входных параметров: $x = [x_1, x_2, ..., x_n]$.
- **Смещение $b_i$** добавляется к сумме произведений входов и их весов, позволяя сдвигать линейную комбинацию вверх или вниз на графике функции.

Таким образом, для каждого выхода существует своя уникальная линейная комбинация входных параметров, определенная вектором весов и смещением, что позволяет нейронной сети адаптироваться и обучаться для предсказания или классификации на основе входных данных.


### Функции активации

В нейронных сетях после вычисления линейной комбинации входов применяется функция активации, которая добавляет нелинейность. Одной из таких функций является логистическая функция (или сигмоид):

$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

Функция активации позволяет нейрону активироваться (или не активироваться) в зависимости от входного сигнала.

Если в многослойной сети не будет функции активации, то в этом случае каждый нейрон будет выполнять только линейное преобразование на входах, используя веса и смещения — константы в линейном уравнении. Неважно, сколько скрытых слоёв в нейронной сети. Эти слои будут вести себя одинаково, потому что композиция двух линейных функций сама является линейной функцией.

### Пример нейронной сети с скрытыми слоями

Рассмотрим нейронную сеть с тремя входами $x_1, x_2, x_3$, двумя промежуточными переменными $h_1, h_2$ и одним выходом $a$. Промежуточные переменные $h_1, h_2$ вычисляются как:

$$
h_i = \sigma(w_{1i}x_1 + w_{2i}x_2 + w_{3i}x_3 + b_i), \quad i = 1, 2
$$

Затем выход $a$ модели вычисляется на основе $h_1, h_2$:

$$
a = \sigma(w_{1}h_1 + w_{2}h_2 + b)
$$

### Матричное представление

Вычисления в нейронных сетях часто представляются в виде матричных операций для эффективности и удобства. Предположим, у нас есть вектор входов $x$ размерностью $p$, тогда матричное представление для двухслойной сети выглядит следующим образом:

$$
h = \sigma(W_1 x + b_1)
$$

$$
a = \sigma(W_2 h + b_2)
$$

где $W_1, W_2$ — матрицы весов, а $b_1, b_2$ — векторы смещений.


## Обучение нейронных сетей

Обучение нейронных сетей заключается в минимизации функции потерь, которая измеряет разницу между предсказаниями сети и реальными данными. Один из популярных методов оптимизации — стохастический градиентный спуск (SGD). Этот метод обновляет веса сети в направлении, противоположном градиенту функции потерь по этим весам:

$$
W_{t+1} = W_t - \eta \nabla L(W_t)
$$

где $W_t$ — веса на шаге $t$, $\eta$ — скорость обучения, $\nabla L(W_t)$ — градиент функции потерь по весам.

<div style="border: 1px solid #ccc; padding: 10px; border-radius: 5px;">

## Обучение нейронных сетей

Любую нейронную сеть можно записать функцией $f(x)$ от её входного вектора и параметров.
Обозначим:
- $X = [x_1, x_2, ..., x_n]$ — признаки обучающей выборки;
- $W = [w_1, w_2, ..., w_n]$ — набор всех параметров (весов) нейронной сети;
- $f(X, W) = \sigma(\sigma(\sigma(Xw_1)w_2)...w_{n-1})w_n$ — функция нейронной сети.

Также обозначим:

- $L(a, y)$ — функция потерь (например, MSE);
- $a$ — ответы модели;
- $y$ — ответы обучающей выборки.

Тогда задача обучения нейронной сети формулируется так:

$
  min L(f(X, W), y)
$

</div>

Минимум этой функции также находится алгоритмом SGD.
Алгоритм обучения нейронной сети такой же, как и алгоритм SGD для линейной регрессии. Только вместо градиента для линейной регрессии вычисляется градиент для нейронной сети:

$$
  \nabla L(f(X, W), y)
$$

В процессе обучения нейронной сети алгоритм обратного распространения ошибки вычисляет градиент функции потерь относительно каждого веса нейрона, используя цепочку дифференцирования. При этом необходимо вычислить производную функции активации нейрона, чтобы найти вклад каждого веса в градиент.

Пусть $L$ - функция потерь, $w$ - веса нейронов, $x$ - входные сигналы нейронов, $f$ - функция активации нейрона, тогда градиент функции потерь относительно весов нейронов вычисляется следующим образом:

$$
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w}
$$

где $a$ - выходной сигнал нейрона, $z$ - взвешенная сумма входных сигналов нейрона, $\frac{\partial L}{\partial a}$ - производная функции потерь по выходному сигналу нейрона, $\frac{\partial a}{\partial z}$ - производная функции активации нейрона, $\frac{\partial z}{\partial w}$ - производная взвешенной суммы входных сигналов нейрона по весам.

Аналогично, градиент функции потерь относительно входных сигналов нейронов вычисляется следующим образом:

$$
\frac{\partial L}{\partial x} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial x}
$$

где $\frac{\partial z}{\partial x}$ - производная взвешенной суммы входных сигналов нейрона по входным сигналам.

Эти формулы позволяют эффективно вычислять градиент функции потерь относительно весов и входных сигналов нейронов, и оптимизировать архитектуру нейронной сети в процессе обучения.

Дифференцирование функций активации необходимо для того, чтобы вычислить градиент функции потерь относительно весов нейронов, и тем самым оптимизировать веса нейронов в процессе обучения. Кроме того, дифференцирование нейронов также используется для вычисления градиента функции потерь относительно входных сигналов нейронов, что позволяет оптимизировать архитектуру нейронной сети и улучшать ее точность.

Таким образом, дифференцирование во время обучения нейронной сети является важной частью алгоритма обратного распространения ошибки, которая позволяет эффективно оптимизировать веса нейронов и архитектуру нейронной сети, и улучшать точность предсказаний нейронной сети.

## **Последовательная модель (Sequential)**

Модель Sequential в контексте нейронных сетей (часто используется в библиотеке Keras) представляет собой линейный стек слоёв. Контейнер Sequential строит сеть прямого распространения на основе заданных слоёв. В Sequential уже есть метод forward, в котором входной тензор последовательно проходит через все слои.
При инициализации объекта класса-контейнера Sequential в качестве параметров по очереди передаются слои, которые будут использованы.
  
Давайте рассмотрим основные аспекты и математические основы, на которых строится такая модель.

1. Слой полносвязной нейронной сети (Dense Layer).

В основном, модель Sequential строится на использовании полносвязных слоев. Формула для одного нейрона в полносвязном слое выглядит следующим образом:

- $[ y = \phi \left( \sum_{i=1}^{n} w_i x_i + b \right) ]$

где:
- $y$ — выход нейрона;
- $ϕ$ — функция активации;
- $w_i$ — вес $i$-го входа;
- $x_i$ — i-й вход;
- $b$ — смещение (bias);
- $n$ — количество входов.

2. Функции активации

Различные функции активации имеют разные математические выражения. Например:

- ReLU (Rectified Linear Unit): $ (\phi(x) = \max(0, x)) $
- Сигмоида: $ (\phi(x) = \frac{1}{1 + e^{-x}}) $
- Гиперболический тангенс: $ (\phi(x) = \tanh(x)) $

3. Пакетная нормализация (Batch Normalization)

Пакетная нормализация часто используется для ускорения обучения. Она нормализует выход каждого нейрона на основе статистик текущего мини-пакета (mini-batch). Математически это можно описать следующим образом:

- $ \text{BN}(x) = \gamma \left( \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} \right) + \beta $

где:

- $ \gamma, \beta $ - параметры масштаба и смещения, которые обучаются во время обучения;

- $ \mu, \sigma^2 $ - среднее и дисперсия мини-пакета;

- $ \epsilon $ - маленькое число, предотвращающее деление на ноль.

4. Оптимизаторы

Оптимизаторы используются для минимизации функции потерь $L$ по параметрам модели. Некоторые популярные оптимизаторы включают:

- SGD (Stochastic Gradient Descent):

  - $\theta_{\text{new}} = \theta_{\text{old}} - \eta \nabla_\theta L$
  
- Adam:
  - $m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t$

  - $v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2$
  
  - $\hat{m}_t = \frac{m_t}{1-\beta_1^t}$
  
  - $\hat{v}_t = \frac{v_t}{1-\beta_2^t}$
  
  - $\theta_{\text{new}} = \theta_{\text{old}} - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$

  где:

  - $θ$ — параметры модели;

  - $η$ — скорость обучения (learning rate);

  - $∇_θL$ — градиент функции потерь по параметрам;

  - $g_t$ — градиент на текущем шаге;

  - $β_1$, $β_2$, $ϵ$ — гиперпараметры алгоритма Adam;
  
  - $m_t$, $v_t$ — моменты первого и второго порядка.

5. Функции потерь

Функции потерь используются для оценки ошибки модели. Некоторые распространенные функции потерь:

MSE (Mean Squared Error) для задач регрессии:

  - $ L(y, \hat{y}) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 $

Crossentropy для задач классификации:

 - $ L(y, \hat{y}) = - \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} y_{ij} \log(\hat{y}_{ij}) $

 где:

 - $y$ и $\hat{y}$ — истинные и предсказанные значения;

 - $N$ — количество примеров в пакете;

 - $C$ — количество классов.

### Структура и гиперпараметры

В модели Sequential мы строим архитектуру нейронной сети, добавляя слои один за другим. Рассмотрим основные аспекты и гиперпараметры:

Слои (Layers)

- Dense layer: Полносвязный слой, где каждый узел соединен со всеми узлами в предыдущем слое;

- Convolutional layer: Слой, применяющий свёртку для обработки данных (чаще всего изображений);

- Recurrent layer: Слой, использующий рекуррентные соединения, подходит для работы с последовательностями данных.

Гиперпараметры для слоев:

- Units/neurons: Количество нейронов в слое (только для Dense);

- Activation function: Функция активации (например, relu, softmax);

- Kernel initializer: Метод инициализации весов;

- Bias initializer: Метод инициализации смещений.

Оптимизатор (Optimizer)

- Learning rate: Скорость обучения — шаг обновления весов;

- Momentum: Момент — параметр, учитывающий предыдущие градиенты для более стабильного обучения.

Функция потерь (Loss function)

- Часто используемые функции потерь: Mean Squared Error (для регрессии), Crossentropy (для классификации).

Метрики (Metrics)

- Например, accuracy для классификации.

Процесс обучения

- В процессе обучения модель Sequential использует метод обратного распространения ошибки (backpropagation) для оптимизации весов.

Математически это можно описать следующим образом:

Forward Pass

- Данные проходят через сеть, и на выходе получается предсказание. Вычисляется функция потерь, сравнивая предсказание с истинным значением.

Backward Pass

- Вычисляется градиент функции потерь по отношению к каждому весу (используя правило цепи). Веса обновляются в направлении, уменьшающем функцию потерь.

Математически обновление весов можно описать как:

- $W_{new} = W_{old}−learning rate⋅gradient$

### Пример кода

Теперь давайте реализуем многослойную нейросеть с промежуточным слоем и обучим ее на задаче классификации:

```python
class NeuralNetwork:
    def __init__(self):
        # Список слоев нейросети
        self.layers = []

    def add(self, layer):
        """
        Description:
            Добавление слоя в нейросеть.

        Args:
            layer: Слой, который нужно добавить.
        """
        self.layers.append(layer)

    def forward(self, x):
        """
        Description:
            Прямое распространение через нейросеть.

        Args:
            x: Входные данные.

        Returns:
            Выходные данные последнего слоя.
        """
        for layer in self.layers:
            x = layer.forward(x)            # Применяем метод forward для каждого слоя
        return x

    def backward(self, delta):
        """
        Description:
            Обратное распространение через нейросеть.

        Args:
            delta: Ошибка на выходе.

        Returns:
            Ошибка для предыдущего слоя.
        """
        for layer in reversed(self.layers):
            delta = layer.backward(delta)   # Применяем метод backward для каждого слоя
        return delta

    def update(self, learning_rate):
        """
        Description:
            Обновление весов и смещений всех слоев.

        Args:
            learning_rate: Скорость обучения.
        """
        for layer in self.layers:
            layer.update(learning_rate)     # Обновляем параметры каждого слоя

# Пример использования
nn = NeuralNetwork()
nn.add(Linear(784, 128))                            # Добавляем линейный слой
nn.add(Linear(128, 10))                             # Добавляем выходной слой

# Прямое распространение
output = nn.forward(X_train)                        # X_train - обучающие данные

# Обратное распространение
loss = cross_entropy_loss.forward(output, y_train)  # Вычисляем ошибку
delta = cross_entropy_loss.backward(loss)           # Вычисляем градиенты
nn.backward(delta)                                  # Обратное распространение
nn.update(learning_rate=0.01)                       # Обновление весов
```

### Объяснение кода

1. **Создаем класс `NeuralNetwork`**, который будет представлять всю нейросеть.
2. **Метод `add`** добавляет новый слой в нейросеть.
3. **Метод `forward`** выполняет прямое распространение через все слои, применяя метод `forward` для каждого слоя.
4. **Метод `backward`** выполняет обратное распространение, начиная с последнего слоя и применяя метод `backward` для каждого слоя.
5. **Метод `update`** обновляет веса и смещения всех слоев, используя заданную скорость обучения.
6. **Создаем экземпляр нейросети**, добавляем слои, выполняем прямое и обратное распространение, а затем обновляем веса.

### Физический и геометрический смысл

Добавление промежуточных слоев в нейросеть позволяет ей более эффективно обрабатывать данные и извлекать сложные зависимости. Это можно представить как многомерное пространство, где каждая цифра представлена в виде облака точек. Нейросеть, используя свои веса, может "научиться" различать эти облака, создавая сложные разделяющие поверхности, которые позволяют точно классифицировать входные данные. Это похоже на то, как человек учится различать объекты, обращая внимание на их характерные черты и особенности.

## Chunk 1

## **Модель персептрона**

В этом фрагменте мы сосредоточимся на модели персептрона, которая была предложена Франком Розенблатом в 1957 году. Персептрон — это простейшая модель нейронной сети, предназначенная для распознавания образов и классификации. Основная идея заключается в том, что нейрон принимает на вход несколько сигналов, которые суммируются и обрабатываются с использованием весов, чтобы определить, должен ли нейрон "активироваться" и выдать выходной сигнал. Персептрон послужил фундаментом для развития более сложных нейронных сетей и глубокого обучения.

### Объяснение концепции

Персептрон имитирует работу биологического нейрона в упрощенном виде. Он состоит из нескольких ключевых компонентов:

*   **Входы (Inputs):**  Персептрон принимает на вход один или несколько числовых значений, представляющих собой признаки объекта или данные для анализа. Эти входы формируют входной вектор $x = (x_1, x_2, ..., x_n)$.
*   **Веса (Weights):** Каждому входу соответствует определенный вес $w = (w_1, w_2, ..., w_n)$. Веса определяют важность каждого входа для принятия решения. В процессе обучения персептрона веса настраиваются таким образом, чтобы модель могла правильно классифицировать входные данные.
*   **Суммирующая функция (Summation Function):** Входные сигналы, умноженные на соответствующие веса, суммируются. К этой сумме может быть добавлен **порог смещения (bias)** $b$, который позволяет нейрону активироваться, даже если сумма взвешенных входов равна нулю.  Порог смещения можно рассматривать как еще один вес, связанный с фиктивным входом, всегда равным 1.
*   **Функция активации (Activation Function):**  Сумма, полученная на предыдущем этапе, передается на функцию активации. В классическом персептроне используется **пороговая функция**, которая сравнивает полученную сумму с определенным порогом $\theta$. Если сумма превышает порог, функция активации возвращает 1 (нейрон активирован), в противном случае - 0 (нейрон не активирован).  Функция активации определяет выходной сигнал персептрона $y$.

### Математическая формализация

Формально, выход персептрона можно записать следующим образом:

$$
y = f(w^T \cdot x + b)
$$

где:
- $y$ — выходной сигнал (обычно 0 или 1, но может быть и -1 или 1 в зависимости от реализации пороговой функции);
- $f$ — функция активации (в данном случае пороговая функция);
- $w^T$ — транспонированный вектор весов;
- $x$ — вектор входных признаков;
- $b$ — порог смещения (bias).

Пороговая функция $f$ может быть определена как:

$$
f(z) =
\begin{cases}
1, & \text{если } z \geq \theta \\
0, & \text{иначе}
\end{cases}
$$

где $\theta$ — пороговое значение.  Часто порог $\theta$ включают в порог смещения $b$. В этом случае, пороговая функция относительно нуля выглядит так:

$$
f(z) =
\begin{cases}
1, & \text{если } z \geq 0 \\
0, & \text{иначе}
\end{cases}
$$

где $z = w^T \cdot x + b$.

### Пример кода

Теперь давайте реализуем модель персептрона на языке Python. Вот пример кода:

```python
import numpy as np

class Perceptron:
    def __init__(self, learning_rate=0.1, n_iterations=1000):
        """
        Description:
            Инициализация персептрона.

        Args:
            learning_rate: Скорость обучения.
            n_iterations: Количество итераций для обучения.
        """
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        """
        Description:
            Обучение персептрона.

        Args:
            X: Входные данные (матрица признаков).
            y: Целевые значения (вектор меток).
        """
        n_samples, n_features = X.shape
        # Инициализация весов и смещения
        self.weights = np.zeros(n_features)
        self.bias = 0

        for _ in range(self.n_iterations):
            for idx, x_i in enumerate(X):
                linear_output = np.dot(x_i, self.weights) + self.bias
                y_predicted = self.activation_function(linear_output)

                # Обновление весов и смещения
                update = self.learning_rate * (y[idx] - y_predicted)
                self.weights += update * x_i
                self.bias += update

    def activation_function(self, x):
        """
        Description:
            Пороговая функция активации.

        Args:
            x: Входное значение.

        Returns:
            1, если x >= 0, иначе 0.
        """
        return 1 if x >= 0 else 0

    def predict(self, X):
        """
        Description:
            Прогнозирование на новых данных.

        Args:
            X: Входные данные (матрица признаков).

        Returns:
            Вектор предсказанных значений.
        """
        linear_output = np.dot(X, self.weights) + self.bias
        return [self.activation_function(x) for x in linear_output]
```

### Объяснение кода

1. **Импортируем библиотеку NumPy** для работы с массивами.
2. **Создаем класс Perceptron** с методами для обучения и предсказания.
3. **Метод `fit`** принимает входные данные $X$ и целевые значения $y$. Он инициализирует веса и смещение, а затем обновляет их в процессе обучения.
4. **Метод `activation_function`** реализует пороговую функцию, возвращая 1, если входное значение больше или равно нулю, и 0 в противном случае.
5. **Метод `predict`** используется для предсказания выходных значений на новых данных.

### Физический и геометрический смысл

Персептрон можно представить как простейшую модель нейронной сети, которая принимает несколько входных сигналов (например, световые сигналы от фотодатчиков) и выдает один выходной сигнал (например, "фигура распознана" или "фигура не распознана"). Это можно сравнить с работой человеческого мозга, где нейроны обрабатывают информацию и принимают решения на основе полученных сигналов.

## Chunk 2

### **Название фрагмента: Критерий персептрона и метод градиентного спуска**

**Предыдущий контекст:** В предыдущем фрагменте мы рассмотрели модель персептрона, которая принимает входные данные и выдает выходной сигнал, основываясь на весах и пороговой функции. Мы также обсудили, как персептрон может классифицировать данные на два класса.

## **Критерий персептрона и его оптимизация**

В этом фрагменте мы сосредоточимся на критерии персептрона, который используется для оценки ошибок классификации, и методе градиентного спуска, который помогает оптимизировать веса модели.

### Объяснение концепции

Критерий персептрона — это функция ошибки, которая измеряет, насколько хорошо модель классифицирует данные. Он фокусируется только на неправильно классифицированных точках, поскольку именно они влияют на качество модели. Если точка классифицируется неправильно, мы можем оценить ошибку как разницу между фактическим классом и предсказанным значением.

Для каждой неправильно классифицированной точки мы можем определить ошибку $e(w)$ как:

$$
e(w) = \sum_{i \in \text{ошибки}} |t_i - y_i|
$$

где:
- $t_i$ — истинный класс точки $i$;
- $y_i$ — предсказанный класс точки $i$.

Если точка классифицируется неправильно, то мы можем считать ошибку как величину, на которую предсказанное значение отклоняется от истинного. Например, если $y_i < 0$ для точки, которая должна быть классифицирована как 1, то ошибка будет равна $|y_i|$.

### Математическая формализация

Для неправильно классифицированных точек, ошибка может быть записана как:

$$
e(w) = \sum_{i} \max(0, -y_i) \quad \text{если } t_i = 1
$$

или

$$
e(w) = \sum_{i} \max(0, y_i) \quad \text{если } t_i = -1
$$

где $y_i = w^T x_i$ — предсказанное значение для точки $i$.

## **Градиентный метод минимизации (loss functions)**

Градиентный метод минимизации — это численный метод, который используется для нахождения локальных минимумов функции. Этот метод особенно полезен, когда функция имеет большое количество переменных, что делает аналитическое вычисление производных трудоемким и неэффективным.

### Объяснение концепции

1. **Градиент**: Градиент функции $f$ в точке $x$ — это вектор, который указывает направление наибольшего увеличения функции. Он определяется как:

$$
\nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right)
$$

где $x_1, x_2, \ldots, x_n$ — переменные функции.

2. **Направление убывания**: Направление, противоположное градиенту, указывает наибольшее убывание функции. Это позволяет нам двигаться в сторону, где функция уменьшается.

3. **Итеративный процесс**: Градиентный метод минимизации состоит в том, чтобы итеративно обновлять значения переменных, двигаясь в направлении, противоположном градиенту. Обновление переменных можно записать как:

$$
x_{k+1} = x_k - \alpha \nabla f(x_k)
$$

где:
- $x_k$ — текущее значение переменных;
- $x_{k+1}$ — новое значение переменных;
- $\alpha$ — шаг обучения (параметр, определяющий размер шага).

### Математическая формализация

Процесс минимизации можно описать следующим образом:

1. Начинаем с начального приближения $x_0$.
2. Вычисляем градиент $\nabla f(x_k)$.
3. Обновляем $x_k$ по формуле:

$$
x_{k+1} = x_k - \alpha \nabla f(x_k)
$$

4. Повторяем шаги 2 и 3 до тех пор, пока не достигнем заданной точности или максимального числа итераций.

## **Метод скорейшего спуска**

Метод скорейшего спуска — это итеративный алгоритм, используемый для нахождения локальных минимумов функции. Он основан на использовании градиента функции для определения направления, в котором функция убывает быстрее всего.

### Объяснение концепции

1. **Градиент**: Градиент функции $f$ в точке $x$ указывает направление наибольшего увеличения функции. Вектор градиента определяется как:

$$
\nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right)
$$

2. **Направление спуска**: Для нахождения локального минимума мы движемся в направлении, противоположном градиенту. Это можно записать как:

$$
x_{k+1} = x_k - \alpha \nabla f(x_k)
$$

где $x_k$ — текущее значение переменных, $x_{k+1}$ — новое значение, а $\alpha$ — шаг обучения.

3. **Условие ортогональности**: Для оптимального выбора шага необходимо, чтобы векторы градиента в текущей и следующей точках были перпендикулярны. Это условие гарантирует, что мы движемся в направлении, где функция убывает, и позволяет избежать ненужных колебаний.

### Математическая формализация

Для нахождения оптимального шага $\alpha$ мы можем использовать следующее условие:

$$
\nabla f(x_k) \cdot \nabla f(x_{k+1}) = 0
$$

где $\cdot$ обозначает скалярное произведение. Это условие гарантирует, что градиенты в двух точках перпендикулярны.

### **Пример:**

Предположим, нам нужно найти локальный минимум функции $f(x, y) = x^2 + y^2 + 2x + 4y + 5$.

**Шаг 1: Вычисление градиента**

Сначала найдем градиент функции $f(x, y)$. Частные производные по $x$ и $y$ будут:

$$
\frac{\partial f}{\partial x} = 2x + 2
$$

$$
\frac{\partial f}{\partial y} = 2y + 4
$$

Таким образом, градиент функции $f(x, y)$ равен:

$$
\nabla f(x, y) = \begin{pmatrix} 2x + 2 \\ 2y + 4 \end{pmatrix}
$$

**Шаг 2: Выбор начальной точки**

Выберем произвольную начальную точку, например, $x_0 = \begin{pmatrix} 0 \\ 0 \end{pmatrix}$.

**Шаг 3: Итерация 1**

* **Вычисление градиента в текущей точке:**

$$
\nabla f(0, 0) = \begin{pmatrix} 2(0) + 2 \\ 2(0) + 4 \end{pmatrix} = \begin{pmatrix} 2 \\ 4 \end{pmatrix}
$$

* **Определение направления спуска:** Направление спуска противоположно градиенту: $ - \nabla f(0, 0) = \begin{pmatrix} -2 \\ -4 \end{pmatrix}$.

* **Вычисление шага $\alpha$:**  Согласно условию ортогональности, градиент в следующей точке $x_1$ должен быть перпендикулярен направлению движения $x_1 - x_0 = -\alpha \nabla f(x_0)$. То есть, скалярное произведение $\nabla f(x_1)^T (x_1 - x_0) = 0$.

   Следующая точка будет иметь вид:
   $$
   x_1 = x_0 - \alpha \nabla f(x_0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix} - \alpha \begin{pmatrix} 2 \\ 4 \end{pmatrix} = \begin{pmatrix} -2\alpha \\ -4\alpha \end{pmatrix}
   $$

   Теперь найдем градиент в точке $x_1$:
   $$
   \nabla f(x_1) = \nabla f(-2\alpha, -4\alpha) = \begin{pmatrix} 2(-2\alpha) + 2 \\ 2(-4\alpha) + 4 \end{pmatrix} = \begin{pmatrix} -4\alpha + 2 \\ -8\alpha + 4 \end{pmatrix}
   $$

   Применяем условие ортогональности:
   $$
   \begin{pmatrix} -4\alpha + 2 \\ -8\alpha + 4 \end{pmatrix}^T \begin{pmatrix} -2 \\ -4 \end{pmatrix} = 0
   $$
   $$
   (-4\alpha + 2)(-2) + (-8\alpha + 4)(-4) = 0
   $$
   $$
   8\alpha - 4 + 32\alpha - 16 = 0
   $$
   $$
   40\alpha = 20
   $$
   $$
   \alpha = \frac{20}{40} = 0.5
   $$

* **Обновление значения переменных:**

   $$
   x_1 = \begin{pmatrix} 0 \\ 0 \end{pmatrix} - 0.5 \begin{pmatrix} 2 \\ 4 \end{pmatrix} = \begin{pmatrix} -1 \\ -2 \end{pmatrix}
   $$

**Шаг 4: Итерация 2**

* **Вычисление градиента в текущей точке:**

   $$
   \nabla f(-1, -2) = \begin{pmatrix} 2(-1) + 2 \\ 2(-2) + 4 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   $$

Поскольку градиент в точке $x_1 = \begin{pmatrix} -1 \\ -2 \end{pmatrix}$ равен нулю, мы достигли стационарной точки, которая в данном случае является локальным минимумом.

**Пояснение концепций:**

1. **Градиент:** Как видно из расчетов, градиент $\nabla f(x, y)$ указывает направление наибольшего возрастания функции в данной точке. В первой итерации градиент в точке $(0, 0)$ равен $\begin{pmatrix} 2 \\ 4 \end{pmatrix}$, что означает, что функция быстрее всего возрастает в этом направлении.

2. **Направление спуска:**  Для минимизации функции мы движемся в противоположном направлении градиенту. В нашем примере на первой итерации мы двигались в направлении $\begin{pmatrix} -2 \\ -4 \end{pmatrix}$.

3. **Условие ортогональности:**  Выбор шага $\alpha$ на каждой итерации основан на условии ортогональности. Это означает, что новое направление градиента должно быть перпендикулярно предыдущему направлению движения. В нашем примере мы нашли такое $\alpha$, при котором вектор градиента в новой точке $x_1$ оказался перпендикулярен вектору направления спуска на предыдущем шаге. Это обеспечивает более эффективное движение к минимуму, избегая "зигзагообразных" траекторий.

**Замечание:** В данном примере мы нашли минимум за одну итерацию, что связано с квадратичной природой целевой функции. Для более сложных функций метод скорейшего спуска может потребовать большего количества итераций для схождения к локальному минимуму.

## **Оптимизация шага в градиентном методе**

В градиентном методе, одном из фундаментальных алгоритмов оптимизации первого порядка, ключевую роль играет выбор размера шага $\alpha$ (также известного как learning rate или темп обучения). Этот параметр определяет, насколько сильно мы сдвигаемся в направлении, противоположном градиенту целевой функции на каждой итерации. Неправильный выбор шага может привести к медленной сходимости, колебаниям вокруг оптимума или даже расходимости алгоритма.

### **Почему важен выбор шага?**

Представьте себе спуск с горы в тумане, где ваша цель – достичь самой низкой точки (минимума функции). Градиент указывает направление самого крутого спуска. Размер вашего шага определяет, насколько большой шаг вы делаете в этом направлении.

* **Слишком маленький шаг:** Если шаг $\alpha$ слишком мал, то спуск будет очень медленным, потребуется огромное количество итераций, чтобы достичь минимума. Это может быть неприемлемо с точки зрения вычислительных ресурсов и времени.
* **Слишком большой шаг:** Если шаг $\alpha$ слишком велик, вы можете "перепрыгнуть" минимум, начав колебаться вокруг него или даже удаляясь от него. Это приведет к нестабильности и, в конечном итоге, к расходимости алгоритма.

Таким образом, задача оптимизации шага заключается в нахождении баланса между скоростью сходимости и стабильностью алгоритма.

### **Подходы к выбору шага**

Существует несколько основных подходов к определению величины шага $\alpha$:

1. **Фиксированный шаг (Constant Step Size):**
   * **Описание:** Самый простой подход, где значение $\alpha$ остается постоянным на протяжении всего процесса оптимизации.
   * **Преимущества:** Легкость реализации.
   * **Недостатки:** Требует тщательной настройки. Слишком большой шаг может привести к расходимости, а слишком маленький – к медленной сходимости. Оптимальное значение шага может зависеть от конкретной задачи и начальной точки.
   * **Применение:** Может работать хорошо для простых задач с гладкими функциями потерь.

2. **Адаптивный шаг (Adaptive Step Size):**
   * **Описание:**  Значение шага $\alpha$ изменяется в процессе итераций в зависимости от поведения функции потерь и градиента.
   * **Преимущества:** Потенциально более быстрая сходимость и лучшая устойчивость по сравнению с фиксированным шагом. Менее чувствителен к начальным настройкам.
   * **Недостатки:** Может быть сложнее в реализации и требовать дополнительных вычислений.

### **Методы адаптивного выбора шага**

В рамках адаптивного подхода существует несколько стратегий:

* **Линейный поиск (Line Search):**
    * **Идея:** На каждой итерации, после определения направления спуска (антиградиента), выполняется процедура поиска оптимального размера шага вдоль этого направления. Цель – найти такое значение $\alpha$, которое минимизирует функцию потерь в направлении спуска.
    * **Точный линейный поиск (Exact Line Search):**  Пытается найти глобальный минимум функции потерь вдоль направления спуска. Это может быть вычислительно затратно, особенно для сложных функций. Математически это соответствует решению задачи:
      $$
      \alpha^* = \arg\min_{\alpha > 0} f(x_k - \alpha \nabla f(x_k))
      $$
    * **Неточный линейный поиск (Inexact Line Search):**  Вместо поиска точного минимума, ищет "достаточно хорошее" значение шага, которое обеспечивает значительное уменьшение функции потерь. Существует несколько критериев для неточного линейного поиска, например, **условие Армихо (Armijo condition)**, **условие Гольдштейна (Goldstein condition)** и **условие Вулфа (Wolfe condition)**.
        * **Условие Армихо:**  Гарантирует, что уменьшение функции потерь будет пропорционально шагу и величине градиента:
          $$
          f(x_k - \alpha \nabla f(x_k)) \le f(x_k) - c \alpha \|\nabla f(x_k)\|^2
          $$
          где $c \in (0, 1)$ – константа (обычно выбирается маленькой, например, 0.1). Это условие обеспечивает "достаточное убывание" функции.

* **Методы, основанные на истории градиентов:**
    * **Метод Momentum:**  Добавляет "инерцию" к обновлению параметров, используя информацию о предыдущих градиентах. Это помогает преодолевать локальные минимумы и ускоряет сходимость в направлениях с устойчивым градиентом. Эффективно сглаживает колебания.
    * **Метод AdaGrad:**  Адаптирует размер шага для каждого параметра индивидуально, основываясь на накопленной сумме квадратов градиентов для этого параметра. Параметры с большими накопленными градиентами получают меньший шаг, а параметры с малыми – больший. Хорошо подходит для разреженных данных.
    * **Метод RMSProp:**  Улучшение AdaGrad, которое использует экспоненциально взвешенное скользящее среднее квадратов градиентов, что позволяет "забывать" старые градиенты и лучше адаптироваться к текущей ситуации.
    * **Метод Adam:**  Комбинирует идеи Momentum и RMSProp, используя как экспоненциально взвешенное скользящее среднее градиентов (для инерции), так и экспоненциально взвешенное скользящее среднее квадратов градиентов (для адаптации шага). Один из самых популярных и эффективных методов адаптивной оптимизации.

### **Математическая формализация**

Вернемся к вашей математической формализации и углубимся в детали:

1. **Функция потерь от шага:** Мы можем рассматривать функцию потерь как функцию одной переменной $\alpha$, фиксируя текущую точку $x_k$ и направление спуска $-\nabla f(x_k)$:
   $$
   \phi(\alpha) = f(x_k - \alpha \nabla f(x_k))
   $$
   Наша цель – найти такое $\alpha > 0$, которое минимизирует $\phi(\alpha)$.

2. **Производная функции потерь по шагу:**  Используя правило цепи для дифференцирования сложной функции, мы получаем производную $\phi(\alpha)$ по $\alpha$:
   $$
   \frac{d\phi(\alpha)}{d\alpha} = \frac{d}{d\alpha} f(x_k - \alpha \nabla f(x_k))
   $$
   Пусть $y(\alpha) = x_k - \alpha \nabla f(x_k)$. Тогда $\frac{dy}{d\alpha} = -\nabla f(x_k)$. Применяя правило цепи:
   $$
   \frac{d\phi(\alpha)}{d\alpha} = \nabla f(y(\alpha))^T \frac{dy}{d\alpha} = \nabla f(x_k - \alpha \nabla f(x_k))^T (-\nabla f(x_k))
   $$
   Таким образом:
   $$
   \frac{d\phi(\alpha)}{d\alpha} = -\nabla f(x_k)^T \nabla f(x_k - \alpha \nabla f(x_k))
   $$
   Здесь $\nabla f(x_k - \alpha \nabla f(x_k))$ – это градиент функции $f$, вычисленный в новой точке $x_{k+1} = x_k - \alpha \nabla f(x_k)$.

3. **Условие оптимальности для точного линейного поиска:** Для нахождения точки минимума функции $\phi(\alpha)$, мы приравниваем ее производную к нулю:
   $$
   \frac{d\phi(\alpha)}{d\alpha} = 0
   $$
   $$
   -\nabla f(x_k)^T \nabla f(x_k - \alpha \nabla f(x_k)) = 0
   $$
   Это означает, что градиент в текущей точке $\nabla f(x_k)$ ортогонален градиенту в новой точке $\nabla f(x_k - \alpha \nabla f(x_k))$. Геометрически это интерпретируется как поиск точки вдоль направления спуска, где касательная к поверхности уровня функции перпендикулярна направлению спуска.

### **Практические соображения**

* **Выбор начального шага:** Даже при использовании адаптивных методов, выбор разумного начального значения шага может ускорить сходимость.
* **Learning Rate Schedules (расписание изменения шага):**  Часто бывает полезно динамически изменять шаг в процессе обучения, например, уменьшая его со временем. Это может помочь в точной настройке вблизи минимума. Примеры расписаний: уменьшение на фиксированный коэффициент через определенное количество итераций, уменьшение на основе валидационной ошибки.
* **Влияние функции потерь:**  Гладкость и выпуклость функции потерь влияют на выбор оптимального шага. Для негладких или невыпуклых функций могут потребоваться более осторожные стратегии выбора шага.
* **Экспериментирование:**  На практике часто приходится экспериментировать с различными стратегиями и параметрами выбора шага, чтобы найти наилучший вариант для конкретной задачи.

```python
import numpy as np

class Perceptron:
    def __init__(self, learning_rate=0.1, n_iterations=1000):
        """
        Description:
            Инициализация персептрона.

        Args:
            learning_rate: Скорость обучения.
            n_iterations: Количество итераций для обучения.
        """
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        """
        Description:
            Обучение персептрона.

        Args:
            X: Входные данные (матрица признаков).
            y: Целевые значения (вектор меток).
        """
        n_samples, n_features = X.shape
        # Инициализация весов и смещения
        self.weights = np.zeros(n_features)
        self.bias = 0

        for _ in range(self.n_iterations):
            for idx, x_i in enumerate(X):
                linear_output = np.dot(x_i, self.weights) + self.bias
                y_predicted = self.activation_function(linear_output)

                # Обновление весов и смещения, если предсказание неверное
                if y[idx] != y_predicted:
                    update = self.learning_rate * (y[idx] - y_predicted)
                    self.weights += update * x_i
                    self.bias += update

    def activation_function(self, x):
        """
        Description:
            Пороговая функция активации.

        Args:
            x: Входное значение.

        Returns:
            1, если x >= 0, иначе -1.
        """
        return 1 if x >= 0 else -1

    def predict(self, X):
        """
        Description:
            Прогнозирование на новых данных.

        Args:
            X: Входные данные (матрица признаков).

        Returns:
            Вектор предсказанных значений.
        """
        linear_output = np.dot(X, self.weights) + self.bias
        return [self.activation_function(x) for x in linear_output]
```

### Объяснение кода

1. **Импортируем библиотеку NumPy** для работы с массивами.
2. **Создаем класс Perceptron** с методами для обучения и предсказания.
3. **Метод `fit`** принимает входные данные $X$ и целевые значения $y$. Он инициализирует веса и смещение, а затем обновляет их в процессе обучения, если предсказание неверное.
4. **Метод `activation_function`** реализует пороговую функцию, возвращая 1, если входное значение больше или равно нулю, и -1 в противном случае.
5. **Метод `predict`** используется для предсказания выходных значений на новых данных.

## Chunk 3

### **Название фрагмента: Алгоритм обучения персептрона с использованием случайных примеров**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метод градиентного спуска и его применение для оптимизации весов в модели персептрона. Мы также рассмотрели, как минимизировать функцию ошибки, используя градиент.

## **Алгоритм обучения персептрона**

В этом фрагменте мы сосредоточимся на алгоритме обучения персептрона, который использует случайные положительные и отрицательные примеры для обновления весов модели. Мы также рассмотрим, как вычисляется точность модели на каждом шаге.

### Объяснение концепции

Алгоритм обучения персептрона включает в себя следующие шаги:

1. **Инициализация весов**: Начинаем с нулевых или случайных значений весов.
2. **Выбор примеров**: На каждой итерации выбираем один положительный и один отрицательный пример из обучающего набора.
3. **Классификация**: Вычисляем значение $z$ как скалярное произведение положительного примера и вектора весов.
4. **Обновление весов**: Если положительный пример классифицируется как отрицательный (то есть $z < 0$), обновляем веса. Аналогично, если отрицательный пример классифицируется как положительный, также обновляем веса.
5. **Вычисление точности**: Каждые несколько итераций вычисляем точность модели, сравнивая предсказанные значения с истинными метками.

### Математическая формализация

Обновление весов можно записать следующим образом:

$$
w = w + \eta \cdot (t - y) \cdot x
$$

где:
- $w$ — вектор весов;
- $\eta$ — скорость обучения;
- $t$ — истинный класс (1 для положительного, -1 для отрицательного);
- $y$ — предсказанный класс;
- $x$ — вектор признаков.

### Пример кода

Теперь давайте реализуем алгоритм обучения персептрона на языке Python:

```python
import numpy as np
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt

class Perceptron:
    def __init__(self, learning_rate=0.1, n_iterations=1000, report_frequency=10):
        """
        Description:
            Инициализация персептрона.

        Args:
            learning_rate: Скорость обучения.
            n_iterations: Количество итераций для обучения.
            report_frequency: Частота отчетов о точности.
        """
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.report_frequency = report_frequency
        self.weights = None

    def fit(self, X, y):
        """
        Description:
            Обучение персептрона.

        Args:
            X: Входные данные (матрица признаков).
            y: Целевые значения (вектор меток).
        """
        n_samples, n_features = X.shape
        # Инициализация весов случайными значениями
        self.weights = np.random.rand(n_features)

        for iteration in range(self.n_iterations):
            # Случайный выбор положительного и отрицательного примера
            pos_idx = np.random.choice(np.where(y == 1)[0])
            neg_idx = np.random.choice(np.where(y == -1)[0])
            pos_example = X[pos_idx]
            neg_example = X[neg_idx]

            # Классификация положительного примера
            z_pos = np.dot(pos_example, self.weights)
            if z_pos < 0:  # Если классификация неверная
                self.weights += self.learning_rate * pos_example

            # Классификация отрицательного примера
            z_neg = np.dot(neg_example, self.weights)
            if z_neg >= 0:  # Если классификация неверная
                self.weights -= self.learning_rate * neg_example

            # Отчет о точности
            if iteration % self.report_frequency == 0:
                self.report_accuracy(X, y)

    def report_accuracy(self, X, y):
        """
        Description:
            Вычисление и вывод точности модели.

        Args:
            X: Входные данные (матрица признаков).
            y: Целевые значения (вектор меток).
        """
        predictions = np.dot(X, self.weights) >= 0
        accuracy = np.mean(predictions == (y == 1))
        print(f'Точность: {accuracy:.2f}')

# Генерация случайных данных
X, y = make_classification(n_samples=50, n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=42)
y = np.where(y == 0, -1, 1)  # Преобразование меток в -1 и 1

# Обучение персептрона
perceptron = Perceptron(learning_rate=0.1, n_iterations=100, report_frequency=10)
perceptron.fit(X, y)
```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами, scikit-learn для генерации данных и Matplotlib для визуализации.
2. **Создаем класс Perceptron** с методами для обучения и вычисления точности.
3. **Метод `fit`** принимает входные данные $X$ и целевые значения $y$. Он инициализирует веса случайными значениями и обновляет их на каждой итерации, выбирая случайные положительные и отрицательные примеры.
4. **Метод `report_accuracy`** вычисляет точность модели, сравнивая предсказанные значения с истинными метками и выводя результат.

## Chunk 4

### **Название фрагмента: Визуализация разделяющей прямой модели**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили алгоритм обучения персептрона, который использует случайные положительные и отрицательные примеры для обновления весов модели. Мы также рассмотрели, как вычисляется точность модели на каждом шаге.

## **Визуализация разделяющей прямой**

В этом фрагменте мы сосредоточимся на визуализации разделяющей прямой, которая используется для классификации, а также на отслеживании точности модели в процессе обучения.

### Объяснение концепции

Разделяющая прямая — это линия, которая отделяет два класса в пространстве признаков. Уравнение этой прямой можно записать как:

$$
w_0 x_0 + w_1 x_1 + w_2 = 0
$$

где:
- $w_0$, $w_1$, $w_2$ — веса модели;
- $x_0$, $x_1$ — признаки.

Мы можем выразить $x_1$ через $x_0$:

$$
x_1 = -\frac{w_0}{w_1} x_0 - \frac{w_2}{w_1}
$$

Это уравнение позволяет нам построить график разделяющей прямой. Важно учитывать, что если один из весов близок к нулю, это может привести к делению на ноль, поэтому необходимо обрабатывать такие случаи.

### Математическая формализация

Для построения разделяющей прямой мы можем использовать следующие шаги:

1. Проверяем, не равен ли $w_1$ нулю. Если равен, используем другой способ для построения.
2. Строим график, используя уравнение прямой.

### Пример кода

Теперь давайте реализуем визуализацию разделяющей прямой и точности модели на языке Python:

```python
from typing import Tuple

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification

class Perceptron:
    """
    Description:
        Класс, реализующий алгоритм перцептрона для классификации.

    Args:
        learning_rate: Скорость обучения (по умолчанию 0.1)
        n_iterations: Количество итераций обучения (по умолчанию 1000)

    Attributes:
        weights: Веса перцептрона
    """

    def __init__(self, learning_rate: float = 0.1, n_iterations: int = 1000):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights = None

    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        Description:
            Обучение перцептрона на данных X и y.

        Args:
            X: Матрица признаков
            y: Вектор меток классов

        Returns:
            None
        """
        n_samples, n_features = X.shape
        self.weights = np.random.rand(n_features)

        for iteration in range(self.n_iterations):
            pos_idx = np.random.choice(np.where(y == 1)[0])
            neg_idx = np.random.choice(np.where(y == -1)[0])
            pos_example = X[pos_idx]
            neg_example = X[neg_idx]

            z_pos = np.dot(pos_example, self.weights)
            if z_pos < 0:
                self.weights += self.learning_rate * pos_example

            z_neg = np.dot(neg_example, self.weights)
            if z_neg >= 0:
                self.weights -= self.learning_rate * neg_example

            if iteration % 10 == 0:
                self.report_accuracy(X, y)

    def report_accuracy(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        Description:
            Вывод точности модели на данных X и y.

        Args:
            X: Матрица признаков
            y: Вектор меток классов

        Returns:
            None
        """
        predictions = np.dot(X, self.weights) >= 0
        accuracy = np.mean(predictions == (y == 1))
        print(f'Точность: {accuracy:.2f}')

    def plot_decision_boundary(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        Description:
            Визуализация разделяющей прямой на графике.

        Args:
            X: Матрица признаков
            y: Вектор меток классов

        Returns:
            None
        """
        try:
            x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
            y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
            xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                                 np.arange(y_min, y_max, 0.01))

            # Используем только первые два веса для двумерного графика
            Z = np.dot(np.c_[xx.ravel(), yy.ravel()], self.weights[:2])
            Z = Z.reshape(xx.shape)

            plt.contourf(xx, yy, Z >= 0, alpha=0.5, cmap='coolwarm')
            plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')
            plt.title('Разделяющая прямая')
            plt.xlabel('Признак 1')
            plt.ylabel('Признак 2')
            plt.show()
        except ValueError as e:
            print(f"Ошибка при визуализации: {e}")

# Генерация случайных данных
X, y = make_classification(n_samples=50, n_features=2, n_classes=2,
                          n_informative=2, n_redundant=0, random_state=42)
y = np.where(y == 0, -1, 1)

# Обучение персептрона
perceptron = Perceptron(learning_rate=0.1, n_iterations=100)
perceptron.fit(X, y)

# Визуализация разделяющей прямой
perceptron.plot_decision_boundary(X, y)
```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами и Matplotlib для визуализации.
2. **Создаем класс Perceptron** с методами для обучения и визуализации.
3. **Метод `fit`** обучает модель, обновляя веса на основе случайных положительных и отрицательных примеров.
4. **Метод `report_accuracy`** вычисляет и выводит точность модели.
5. **Метод `plot_decision_boundary`** строит график разделяющей прямой, используя текущие веса модели.

## Chunk 5

### **Название фрагмента: Ограничения персептрона и задача исключающего ИЛИ**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили визуализацию разделяющей прямой и точности модели персептрона, а также механизм отслеживания изменений в процессе обучения. Мы также упомянули, что персептрон работает на основе математических формул и использует метод градиентного спуска для оптимизации весов.

## **Ограничения персептрона**

В этом фрагменте мы сосредоточимся на ограничениях персептрона, особенно в контексте решения задач, таких как исключающее ИЛИ. Мы также рассмотрим, почему персептрон не может решать некоторые задачи бинарной классификации.

### Объяснение концепции

Персептрон — это простейшая модель нейронной сети, которая может решать задачи бинарной классификации. Однако он имеет свои ограничения. Одной из таких задач является задача исключающего ИЛИ (XOR), которая не может быть решена с помощью простого персептрона.

**Исключающее ИЛИ** — это логическая операция, которая возвращает истинное значение (1), если один из входов истинный, но не оба одновременно. Это можно представить в виде таблицы истинности:

| Вход 1 | Вход 2 | Выход (XOR) |
|--------|--------|--------------|
| 0      | 0      | 0            |
| 0      | 1      | 1            |
| 1      | 0      | 1            |
| 1      | 1      | 0            |

Как видно из таблицы, выход равен 1 только в двух случаях: когда один из входов равен 1, а другой — 0. Персептрон, будучи линейной моделью, не может провести разделяющую линию, которая отделяет классы в этой задаче, поскольку классы не линейно разделимы.

### Математическая формализация

Для персептрона задача может быть представлена следующим образом:

$$
y = f(w_0 x_0 + w_1 x_1 + b)
$$

где:
- $y$ — предсказанный выход (0 или 1);
- $f$ — пороговая функция активации;
- $w_0$, $w_1$ — веса;
- $x_0$, $x_1$ — входные данные;
- $b$ — смещение.

Для задачи XOR не существует таких значений весов и смещения, которые позволили бы персептрону правильно классифицировать все возможные комбинации входов.

### Пример кода

Давайте рассмотрим, как можно реализовать проверку на возможность решения задачи XOR с помощью персептрона:

```python
import numpy as np

def activation_function(x: float) -> int:
    """
    Description:
        Функция активации, возвращающая 1, если входное значение больше или равно 0, иначе 0.

    Args:
        x: Входное значение для активации

    Returns:
        Активированное значение (0 или 1)

    Examples:
        >>> activation_function(0.5)
        1
        >>> activation_function(-0.5)
        0
    """
    return 1 if x >= 0 else 0

def check_xor_solution() -> None:
    """
    Description:
        Функция для проверки возможности решения задачи XOR с использованием
        линейного перцептрона.

    Args:
        None

    Returns:
        None

    Examples:
        >>> check_xor_solution()
        Вход: [0 0], Предсказание: 1, Ожидаемый выход: 0
        Вход: [0 1], Предсказание: 1, Ожидаемый выход: 1
        Вход: [1 0], Предсказание: 1, Ожидаемый выход: 1
        Вход: [1 1], Предсказание: 1, Ожидаемый выход: 0
    """
    # Входные данные для XOR
    X = np.array([[0, 0],
                  [0, 1],
                  [1, 0],
                  [1, 1]])

    # Идеальные выходные значения для XOR
    y = np.array([0, 1, 1, 0])

    # Инициализация весов и смещения
    weights = np.random.rand(2)
    bias = np.random.rand(1)

    # Проверка на возможность решения
    for i in range(len(X)):
        linear_output = np.dot(X[i], weights) + bias
        prediction = activation_function(linear_output)
        print(f'Вход: {X[i]}, Предсказание: {prediction}, Ожидаемый выход: {y[i]}')

# Запуск проверки
check_xor_solution()
```

### Объяснение кода

1. **Импортируем библиотеку NumPy** для работы с массивами.
2. **Определяем функцию активации**, которая возвращает 1, если входное значение больше или равно нулю, и 0 в противном случае.
3. **Создаем функцию `check_xor_solution`**, которая определяет входные данные и ожидаемые выходные значения для задачи XOR.
4. **Инициализируем случайные веса и смещение**.
5. **Проверяем предсказания для всех входных данных** и выводим результаты.

### Физический и геометрический смысл

Ограничения персептрона можно представить как невозможность провести разделяющую линию в многомерном пространстве, когда классы не линейно разделимы. Это можно сравнить с задачей разделения точек на плоскости, где точки одного класса находятся в углах квадрата, а точки другого класса — в центре. Персептрон не может провести прямую, которая разделяет эти точки, что делает его неэффективным для решения таких задач, как XOR. Это ограничение стало основой для разработки более сложных нейронных сетей, способных решать нелинейные задачи.

## Chunk 6

### **Название фрагмента: Ограничения персептрона и задача распознавания рукописных цифр**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили ограничения персептрона, особенно в контексте решения задачи исключающего ИЛИ (XOR). Мы выяснили, что персептрон не может решить эту задачу, так как классы не линейно разделимы.

## **Ограничения персептрона и распознавание рукописных цифр**

В этом фрагменте мы сосредоточимся на ограничениях персептрона в контексте более сложных задач, таких как распознавание рукописных цифр. Мы также рассмотрим, как использование многослойных нейронных сетей может помочь в решении этих задач.

### Объяснение концепции

Персептрон, будучи однослойной моделью, имеет серьезные ограничения в решении задач, которые требуют более сложных разделяющих поверхностей. Например, задача исключающего ИЛИ (XOR) является классическим примером, где персептрон не может провести разделяющую линию, которая отделяет классы.

Однако, несмотря на эти ограничения, нейронные сети в целом могут решать более сложные задачи, такие как распознавание рукописных цифр. Для этого достаточно использовать многослойные нейронные сети, которые могут создавать сложные разделяющие поверхности.

### Математическая формализация

Для задачи распознавания рукописных цифр мы можем использовать многослойную нейронную сеть, которая состоит из нескольких слоев нейронов. Каждый нейрон в скрытом слое может быть представлен следующим образом:

$$
y_j = f\left(\sum_{i=1}^{n} w_{ij} x_i + b_j\right)
$$

где:
- $y_j$ — выход нейрона $j$;
- $w_{ij}$ — вес, связывающий вход $i$ и нейрон $j$;
- $x_i$ — входные данные;
- $b_j$ — смещение для нейрона $j$;
- $f$ — функция активации (например, ReLU или sigmoid).

### Пример кода

Теперь давайте рассмотрим, как можно загрузить и визуализировать датасет MNIST, который содержит рукописные цифры:

```python
# Импорт библиотек
# -----------------------------------------------------------------------------
# Библиотеки для работы с данными
import numpy as np

# Библиотеки для визуализации
import matplotlib.pyplot as plt

# Библиотеки для машинного обучения
from sklearn.datasets import fetch_openml

def plot_digits(X: np.ndarray, y: np.ndarray) -> None:
    """
    Description:
        Визуализирует первые 10 цифр из датасета MNIST.

    Args:
        X: Массив изображений цифр.
        y: Массив меток цифр.

    Returns:
        None

    Raises:
        None

    Examples:
        >>> plot_digits(X, y)
        Отображает первые 10 цифр из датасета MNIST.
    """
    plt.figure(figsize=(10, 4))
    for index in range(10):
        plt.subplot(2, 5, index + 1)
        image = X[index].reshape(28, 28)
        plt.imshow(image, cmap='gray', interpolation='nearest')
        plt.axis('off')
        plt.title(f'Цифра: {y[index]}')
    plt.show()

# Загрузка датасета MNIST
mnist = fetch_openml('mnist_784', version=1, parser='auto')

# Преобразование данных в numpy массивы
X = mnist.data.to_numpy()
y = mnist.target.to_numpy().astype(np.uint8)

# Визуализация первых 10 цифр
plot_digits(X, y)
```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами и Matplotlib для визуализации.
2. **Загружаем датасет MNIST** с помощью функции `fetch_openml`.
3. **Преобразуем метки** в целые числа для удобства.
4. **Создаем функцию `plot_digits`**, которая визуализирует первые 10 цифр из датасета.
5. **Визуализируем цифры**, преобразуя каждую цифру в изображение размером 28x28 пикселей.

## Chunk 7

### **Название фрагмента: Многоклассовая классификация и метод "один против всех"**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как персептрон может быть использован для распознавания рукописных цифр, используя подход "один против всех". Мы также рассмотрели, как визуализировать веса и точность модели в процессе обучения.

## **Метод "один против всех" для многоклассовой классификации**

В этом фрагменте мы сосредоточимся на методе "один против всех" (one-vs-all), который позволяет свести многоклассовую классификацию к нескольким бинарным классификаторам. Мы также рассмотрим, как этот метод применяется для распознавания цифр.

### Объяснение концепции

Метод "один против всех" заключается в том, что для каждой категории (в нашем случае, для каждой цифры от 0 до 9) мы обучаем отдельный бинарный классификатор. Например, первый классификатор будет различать цифру 0 от всех остальных цифр, второй классификатор — цифру 1 от всех остальных и так далее.

Когда на вход подается новая цифра, она передается всем классификаторам, и каждый из них выдает предсказание. Классификатор, который выдает наибольшее значение решающей функции, определяет, к какой цифре относится входное изображение.

### Математическая формализация

Для каждого классификатора $k$ мы можем записать следующее уравнение:

$$
y_k = f(w_k^T x + b_k)
$$

где:
- $y_k$ — предсказанный выход для классификатора $k$;
- $w_k$ — вектор весов для классификатора $k$;
- $x$ — входные данные (пиксели изображения);
- $b_k$ — смещение для классификатора $k$;
- $f$ — функция активации.

### Пример кода

Теперь давайте реализуем метод "один против всех" для распознавания цифр 2 и 5:

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from typing import Tuple

# Загрузка датасета MNIST
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist['data'], mnist['target']
y = y.astype(np.uint8)

def set_mnist_positive_negative(pos_digit: int, neg_digit: int) -> Tuple[np.ndarray, np.ndarray]:
    """
    Description:
        Возвращает положительные и отрицательные примеры для заданных цифр.

    Args:
        pos_digit: Цифра, которая будет считаться положительным примером.
        neg_digit: Цифра, которая будет считаться отрицательным примером.

    Returns:
        Кортеж из двух массивов: положительные примеры и отрицательные примеры.

    Examples:
        >>> pos_examples, neg_examples = set_mnist_positive_negative(2, 5)
        >>> pos_examples.shape
        (5958, 784)
        >>> neg_examples.shape
        (5421, 784)
    """
    pos_examples = X[y == pos_digit]
    neg_examples = X[y == neg_digit]
    return pos_examples, neg_examples

class SimplePerceptron:
    """
    Description:
        Простой персептрон для обучения на двух классах.

    Args:
        learning_rate: Скорость обучения (по умолчанию 0.1).
        n_iterations: Количество итераций обучения (по умолчанию 100).

    Attributes:
        weights: Веса персептрона.
    """

    def __init__(self, learning_rate: float = 0.1, n_iterations: int = 100):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights = None

    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        Description:
            Обучает персептрон на данных.

        Args:
            X: Матрица признаков.
            y: Вектор меток классов.

        Returns:
            None
        """
        n_samples, n_features = X.shape
        self.weights = np.random.rand(n_features)

        for iteration in range(self.n_iterations):
            for idx in range(n_samples):
                linear_output = np.dot(X[idx], self.weights)
                prediction = 1 if linear_output >= 0 else 0
                error = y[idx] - prediction
                self.weights += self.learning_rate * error * X[idx]

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Description:
            Предсказывает метки классов для данных.

        Args:
            X: Матрица признаков.

        Returns:
            Вектор предсказанных меток классов.
        """
        linear_output = np.dot(X, self.weights)
        return np.array([1 if output >= 0 else 0 for output in linear_output])

# Получение примеров для цифр 2 и 5
pos_examples, neg_examples = set_mnist_positive_negative(2, 5)

# Объединение примеров для обучения
X_train = np.concatenate((pos_examples, neg_examples))
y_train = np.concatenate((np.ones(len(pos_examples)), np.zeros(len(neg_examples))))

# Обучение персептрона
perceptron = SimplePerceptron(learning_rate=0.1, n_iterations=100)
perceptron.fit(X_train, y_train)

# Проверка точности
accuracy = np.mean(perceptron.predict(X_train) == y_train)
print(f'Точность на обучающем наборе: {accuracy:.2f}')
```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами и Matplotlib для визуализации.
2. **Загружаем датасет MNIST** с помощью функции `fetch_openml`.
3. **Создаем функцию `set_mnist_positive_negative`**, которая получает положительные и отрицательные примеры для заданных цифр.
4. **Создаем класс `SimplePerceptron`** с методами для обучения и предсказания.
5. **Метод `fit`** обучает модель, обновляя веса на основе ошибок предсказания.
6. **Метод `predict`** возвращает предсказания для входных данных.
7. **Получаем примеры для цифр 2 и 5**, объединяем их для обучения и обучаем персептрон.
8. **Выводим точность на обучающем наборе**.

### Физический и геометрический смысл

Метод "один против всех" позволяет персептрону эффективно решать задачи многоклассовой классификации, разбивая их на несколько бинарных задач. Это можно представить как задачу разделения объектов на группы, где каждый классификатор отвечает за определенную группу. Визуально это можно представить как несколько разделяющих линий, каждая из которых отвечает за различие между одной цифрой и всеми остальными. Таким образом, персептрон может адаптироваться к более сложным задачам, чем просто бинарная классификация.

## Chunk 8

### **Название фрагмента: Понижение размерности и метод главных компонент (PCA)**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как персептрон обучается различать цифры, такие как 2 и 5, и как растут веса модели в процессе обучения. Мы также рассмотрели, что при сложных задачах, таких как различие между цифрами, точность может оставаться на уровне 0.9.

## **Метод главных компонент (PCA) для понижения размерности**

В этом фрагменте мы сосредоточимся на методе главных компонент (PCA), который позволяет понизить размерность данных, сохраняя при этом наиболее важные характеристики. Это особенно полезно в задачах классификации, где количество входных признаков может быть очень большим.

### Объяснение концепции

PCA — это метод, который используется для уменьшения размерности данных, сохраняя как можно больше информации. Он работает путем проекции многомерных данных на меньшую размерность, что позволяет выделить наиболее значимые направления (компоненты) в данных.

Представьте, что у вас есть облако точек в двумерном пространстве, представляющее два класса. Если вы хотите понизить размерность до одной, вы можете провести прямую, которая максимально разделяет эти классы. Если прямая проходит через точки так, что классы остаются максимально разделенными, это означает, что вы выбрали оптимальное направление для проекции.

### Математическая формализация

PCA работает следующим образом:

1. **Центрирование данных**: Вычисляем среднее значение для каждого признака и вычитаем его из данных.

   **Математическая запись:**

   Пусть у нас есть матрица данных $X$ размерности $n \times p$, где $n$ - количество наблюдений (объектов), а $p$ - количество признаков. Обозначим $x_{ij}$ как значение $i$-го наблюдения для $j$-го признака.

   Среднее значение для $j$-го признака ($\mu_j$) вычисляется как:

   $$
   \mu_j = \frac{1}{n} \sum_{i=1}^{n} x_{ij}
   $$

   Вектор средних значений $\mathbf{\mu}$ будет иметь размерность $1 \times p$:

   $$
   \mathbf{\mu} = [\mu_1, \mu_2, \dots, \mu_p]
   $$

   Центрированные данные $X_{centered}$ получаются путем вычитания вектора средних $\mathbf{\mu}$ из каждого наблюдения (строки) матрицы $X$.  Это можно представить как вычитание из каждого элемента $x_{ij}$ среднего значения соответствующего признака $\mu_j$:

   $$
   x'_{ij} = x_{ij} - \mu_j
   $$

   Таким образом, матрица центрированных данных $X_{centered}$ размерности $n \times p$ будет состоять из элементов $x'_{ij}$.

   **Пояснение:** Центрирование данных необходимо для того, чтобы среднее значение каждого признака стало равным нулю. Это упрощает дальнейшие вычисления, особенно при расчете ковариационной матрицы, так как ковариация теперь будет рассчитываться относительно начала координат.

2. **Ковариационная матрица**: Вычисляем ковариационную матрицу для центрированных данных.

   **Математическая запись:**

   Ковариационная матрица $C$ размерности $p \times p$ показывает ковариацию между каждой парой признаков. Для центрированных данных $X_{centered}$, ковариационная матрица $C$ вычисляется как:

   $$
   C = \frac{1}{n-1} X_{centered}^T X_{centered}
   $$

   где $X_{centered}^T$ - транспонированная матрица $X_{centered}$. Элемент $C_{jk}$ ковариационной матрицы, представляющий ковариацию между $j$-м и $k$-м признаками, вычисляется как:

   $$
   C_{jk} = \frac{1}{n-1} \sum_{i=1}^{n} x'_{ij} x'_{ik}
   $$

   **Пояснение:** Ковариационная матрица является симметричной и показывает, как признаки изменяются совместно. Диагональные элементы $C_{jj}$ представляют дисперсию $j$-го признака, а недиагональные элементы $C_{jk}$ (где $j \neq k$) представляют ковариацию между $j$-м и $k$-м признаками. Положительная ковариация означает, что признаки изменяются в одном направлении, отрицательная - в противоположных, а нулевая - что они не связаны линейно.

3. **Собственные значения и собственные векторы**: Находим собственные значения и собственные векторы ковариационной матрицы. Собственные векторы определяют направления, а собственные значения — величину разброса вдоль этих направлений.

   **Математическая запись:**

   Собственные значения $\lambda$ и собственные векторы $\mathbf{v}$ ковариационной матрицы $C$ находятся из уравнения:

   $$
   C \mathbf{v} = \lambda \mathbf{v}
   $$

   где $\mathbf{v}$ - собственный вектор размерности $p \times 1$, а $\lambda$ - собственное значение (скаляр).  Для нахождения собственных значений, необходимо решить характеристическое уравнение:

   $$
   \det(C - \lambda I) = 0
   $$

   где $I$ - единичная матрица размерности $p \times p$, а $\det$ обозначает детерминант матрицы. Решение этого уравнения даст $p$ собственных значений $\lambda_1, \lambda_2, \dots, \lambda_p$. Для каждого собственного значения $\lambda_i$ можно найти соответствующий собственный вектор $\mathbf{v}_i$, решая систему линейных уравнений $(C - \lambda_i I) \mathbf{v}_i = \mathbf{0}$.

   **Пояснение:** Собственные векторы ковариационной матрицы представляют собой направления в пространстве признаков, вдоль которых данные имеют наибольшую дисперсию. Собственные значения показывают величину дисперсии данных вдоль соответствующих собственных векторов. Чем больше собственное значение, тем больше информации (дисперсии) содержится в данных вдоль соответствующего собственного вектора.

4. **Выбор главных компонент**: Выбираем $k$ собственных векторов с наибольшими собственными значениями, чтобы получить $k$ главных компонент.

   **Математическая запись:**

   Сортируем собственные значения в порядке убывания: $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_p$.  Соответствующие собственные векторы также упорядочиваются в том же порядке: $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_p$.

   Выбираем первые $k$ собственных векторов $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_k$, соответствующих $k$ наибольшим собственным значениям $\lambda_1, \lambda_2, \dots, \lambda_k$. Эти $k$ собственных векторов называются главными компонентами.

   Матрица главных компонент $W$ размерности $p \times k$ формируется путем объединения выбранных собственных векторов в столбцы:

   $$
   W = [\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_k]
   $$

   Проекция исходных центрированных данных $X_{centered}$ на пространство главных компонент $X_{PCA}$ размерности $n \times k$ вычисляется как:

   $$
   X_{PCA} = X_{centered} W
   $$

   Каждая строка матрицы $X_{PCA}$ представляет собой новое представление исходного $i$-го наблюдения в пространстве $k$ главных компонент.

   **Пояснение:** Выбирая главные компоненты, соответствующие наибольшим собственным значениям, мы сохраняем наиболее важную информацию (наибольшую дисперсию) из исходных данных в меньшем количестве измерений.  Количество главных компонент $k$ выбирается таким образом, чтобы сохранить достаточное количество дисперсии, обычно выражаемое в процентах от общей дисперсии. Например, можно выбрать $k$ так, чтобы первые $k$ главных компонент объясняли, скажем, 95% общей дисперсии данных.

---

**Дополнительные замечания:**

*   **Нормировка собственных векторов:** Обычно собственные векторы нормируют, чтобы их длина (норма) была равна 1. Это не влияет на направление собственных векторов, но стандартизирует их масштаб.
*   **Выбор количества главных компонент ($k$):**  Существуют различные методы выбора оптимального $k$, включая анализ "каменистой осыпи" (scree plot) собственных значений и выбор на основе процента объясненной дисперсии.
*   **Применение PCA:** После понижения размерности с помощью PCA, полученные данные $X_{PCA}$ могут быть использованы для дальнейших задач, таких как классификация, кластеризация или визуализация.

### Пример кода

Теперь давайте реализуем метод PCA для визуализации данных и понижения размерности:

```python
from typing import Tuple

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA

# Загрузка датасета MNIST
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist['data'], mnist['target']
y = y.astype(np.uint8)

def apply_pca(X: np.ndarray, n_components: int = 2) -> np.ndarray:
    """
    Description:
        Применяет метод главных компонент (PCA) к данным.

    Args:
        X: Входные данные для применения PCA.
        n_components: Количество компонент для сохранения.

    Returns:
        Уменьшенные данные после применения PCA.

    Raises:
        ValueError: Если n_components меньше 1.

    Examples:
        >>> apply_pca(X, n_components=2)
        array([[...]])
    """
    if n_components < 1:
        raise ValueError("n_components должно быть больше или равно 1.")

    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)
    return X_reduced

# Применение PCA к данным
X_reduced = apply_pca(X)

def plot_pca(X_reduced: np.ndarray, y: np.ndarray) -> None:
    """
    Description:
        Визуализирует результаты PCA.

    Args:
        X_reduced: Уменьшенные данные после применения PCA.
        y: Метки классов для данных.

    Returns:
        None

    Raises:
        ValueError: Если X_reduced и y имеют разные длины.

    Examples:
        >>> plot_pca(X_reduced, y)
        (выводит график)
    """
    if len(X_reduced) != len(y):
        raise ValueError("X_reduced и y должны иметь одинаковую длину.")

    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(
        X_reduced[:, 0], X_reduced[:, 1], c=y, cmap='viridis', alpha=0.5
    )
    plt.colorbar(scatter)
    plt.title('PCA: Проекция данных MNIST на 2D')
    plt.xlabel('Первая главная компонента')
    plt.ylabel('Вторая главная компонента')
    plt.show()

# Визуализация результатов
plot_pca(X_reduced, y)
```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами, Matplotlib для визуализации и PCA из scikit-learn для понижения размерности.
2. **Загружаем датасет MNIST** с помощью функции `fetch_openml`.
3. **Создаем функцию `apply_pca`**, которая применяет PCA к данным и возвращает пониженные данные.
4. **Применяем PCA к данным** и сохраняем результат.
5. **Создаем функцию `plot_pca`**, которая визуализирует результаты PCA, отображая точки в двумерном пространстве.
6. **Визуализируем результаты**, показывая, как данные распределены в новом пространстве.

### Физический и геометрический смысл

PCA можно представить как способ "сжатия" многомерного пространства в более простую форму, сохраняя при этом важные характеристики данных. Это похоже на то, как мы можем смотреть на сложные объекты с разных углов, чтобы лучше понять их форму. В контексте распознавания цифр, использование PCA позволяет выделить ключевые особенности, которые помогают различать цифры, даже если они имеют схожие формы. Это делает задачу классификации более управляемой и эффективной, особенно когда данные имеют высокую размерность.

## Chunk 9

### **Название фрагмента: Современные нейросети и многослойные персептроны**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метод "один против всех" для многоклассовой классификации и как он применяется для распознавания цифр. Мы также рассмотрели, как персептрон может быть использован для различия между цифрами, такими как 2 и 5.

## **Современные нейросети и их архитектура**

В этом фрагменте мы сосредоточимся на современных нейросетях, которые представляют собой многослойные персептроны. Мы обсудим, как добавление многослойности и улучшение вычисления ошибки позволяют нейросетям решать более сложные задачи, чем простые персептроны.

### Объяснение концепции

Современные нейросети состоят из нескольких слоев нейронов, что позволяет им обрабатывать данные более эффективно. В отличие от однослойного персептрона, многослойные нейросети могут моделировать сложные функции и решать задачи, которые не поддаются линейной классификации.

Одной из ключевых особенностей многослойных нейросетей является возможность учитывать не только неправильно классифицированные примеры, но и правильно классифицированные, которые находятся близко к границе разделения. Это позволяет улучшить качество классификации.

Для многоклассовой классификации, например, распознавания цифр, мы можем использовать 10 нейронов на выходе, каждый из которых будет представлять одну цифру. Каждый нейрон будет иметь 784 веса, соответствующих пикселям изображения.

### Математическая формализация

Для многослойной нейросети с одним скрытым слоем и 10 выходными нейронами, выходной вектор $y$ можно выразить следующим образом:

$$
y = W \cdot x + b
$$

где:
- $y$ — выходной вектор размерности 10 (представляющий вероятности для каждой цифры);
- $W$ — матрица весов размерности $10 \times 784$;
- $x$ — входной вектор размерности 784 (пиксели изображения);
- $b$ — вектор смещений размерности 10.

Для получения вероятностей мы применяем функцию softmax:

$$
P(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{10} e^{y_j}}
$$

где $P(y_i)$ — вероятность того, что входное изображение соответствует цифре $i$.

### Пример кода

Теперь давайте реализуем простую многослойную нейросеть с использованием функции softmax для классификации цифр:

```python
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.preprocessing import OneHotEncoder
from typing import Any

# Загрузка датасета MNIST
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist['data'], mnist['target']
y = y.astype(np.uint8)

# Преобразуем y в массив NumPy
y = y.to_numpy()

# Применение one-hot кодирования для меток
encoder = OneHotEncoder()
# Преобразуем в плотный массив
y_onehot = encoder.fit_transform(y.reshape(-1, 1)).toarray()

def softmax(z: np.ndarray) -> np.ndarray:
    """
    Description:
        Вычисляет функцию softmax для входного массива.

    Args:
        z: Входной массив, для которого нужно вычислить softmax.

    Returns:
        Массив вероятностей после применения softmax.

    Examples:
        >>> softmax(np.array([[1, 2, 3], [1, 2, 3]]))
        array([[0.09003057, 0.24472847, 0.66524096],
               [0.09003057, 0.24472847, 0.66524096]])
    """
    exp_z = np.exp(z - np.max(z))  # Для стабильности вычислений
    return exp_z / exp_z.sum(axis=1, keepdims=True)

class SimpleNeuralNetwork:
    """
    Description:
        Простая многослойная нейросеть с одним скрытым слоем.

    Args:
        input_size: Размер входного слоя.
        hidden_size: Размер скрытого слоя.
        output_size: Размер выходного слоя.

    Attributes:
        W1: Веса для первого слоя.
        b1: Смещения для первого слоя.
        W2: Веса для второго слоя.
        b2: Смещения для второго слоя.
    """

    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:
        self.W1 = np.random.rand(input_size, hidden_size) * 0.01   # Веса для первого слоя
        self.b1 = np.zeros((1, hidden_size))                       # Смещения для первого слоя
        self.W2 = np.random.rand(hidden_size, output_size) * 0.01  # Веса для второго слоя
        self.b2 = np.zeros((1, output_size))                       # Смещения для второго слоя

    def forward(self, X: np.ndarray) -> np.ndarray:
        """
        Description:
            Выполняет прямое распространение для входного массива.

        Args:
            X: Входной массив данных.

        Returns:
            Массив вероятностей после применения softmax.

        Examples:
            >>> nn = SimpleNeuralNetwork(input_size=784, hidden_size=128, output_size=10)
            >>> predictions = nn.forward(X[:5])
            >>> print(predictions)
        """
        self.z1 = np.dot(X, self.W1) + self.b1          # Прямое распространение
        self.a1 = np.maximum(0, self.z1)                # Активация ReLU
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        return softmax(self.z2)                         # Применение softmax для получения вероятностей

# Создание и тестирование нейросети
nn = SimpleNeuralNetwork(input_size=784, hidden_size=128, output_size=10)
predictions = nn.forward(X[:5])  # Прогноз для первых 5 изображений
print(predictions)               # Вероятности для каждой цифры

```

### Объяснение кода

1. **Импортируем необходимые библиотеки**: NumPy для работы с массивами и scikit-learn для загрузки данных и кодирования меток.
2. **Загружаем датасет MNIST** и применяем one-hot кодирование для меток.
3. **Создаем функцию softmax**, которая нормализует выходные значения, чтобы они представляли вероятности.
4. **Создаем класс `SimpleNeuralNetwork`**, который инициализирует веса и смещения для двух слоев.
5. **Метод `forward`** выполняет прямое распространение через сеть, применяя активацию ReLU и softmax.
6. **Создаем экземпляр нейросети** и тестируем ее на первых 5 изображениях, выводя вероятности для каждой цифры.

### Физический и геометрический смысл

Многослойные нейросети позволяют моделировать сложные зависимости в данных, что делает их мощным инструментом для решения задач классификации. Визуально это можно представить как многомерное пространство, где каждая цифра представлена в виде облака точек. Нейросеть, используя свои веса, может "научиться" различать эти облака, создавая сложные разделяющие поверхности, которые позволяют точно классифицировать входные данные. Это похоже на то, как человек учится различать объекты, обращая внимание на их характерные черты и особенности.

## Chunk 10

### **Название фрагмента: Функция ошибки и кросс-энтропия в нейросетях**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили реализацию линейного слоя и функции softmax в многослойной нейросети. Мы также рассмотрели, как эти компоненты помогают преобразовывать входные данные в вероятности для классификации.

## **Функция ошибки кросс-энтропия**

В этом фрагменте мы сосредоточимся на функции ошибки, известной как кросс-энтропия, которая используется для оценки качества предсказаний нейросети. Мы обсудим, как она вычисляется и почему является эффективной для задач классификации.

### Объяснение концепции

Кросс-энтропия — это мера различия между двумя распределениями вероятностей. В контексте нейросетей она используется для оценки того, насколько хорошо предсказанные вероятности соответствуют истинным меткам классов. 

Когда нейросеть предсказывает вероятность для определенного класса, кросс-энтропия вычисляется следующим образом:

$$
L = -\log(p_c)
$$

где:
- $L$ — значение функции ошибки (кросс-энтропия);
- $p_c$ — предсказанная вероятность для правильного класса $c$.

Если вероятность равна 1 (то есть нейросеть уверенно предсказала правильный класс), то кросс-энтропия будет равна 0, что означает отсутствие ошибки. Если вероятность равна 0, то кросс-энтропия стремится к бесконечности, что указывает на серьезную ошибку в предсказании.

### Математическая формализация

Для многоклассовой классификации, где у нас есть $C$ классов, кросс-энтропия может быть записана как:

$$
L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{ic} \log(p_{ic})
$$

где:
- $N$ — количество примеров в мини-батче;
- $y_{ic}$ — бинарная переменная, указывающая, принадлежит ли пример $i$ классу $c$ (1, если принадлежит, и 0, если нет);
- $p_{ic}$ — предсказанная вероятность для примера $i$ и класса $c$.

### Пример кода

Теперь давайте реализуем класс для вычисления кросс-энтропии в Python:

```python
import numpy as np

class CrossEntropyLoss:
    def __init__(self):
        pass

    def forward(self, probabilities, target):
        """
        Description:
            Вычисление кросс-энтропии.

        Args:
            probabilities: Вероятности предсказанных классов.
            target: Целевой класс (истинные метки).

        Returns:
            Значение кросс-энтропии.
        """
        # Получаем вероятность для целевого класса
        p_c = probabilities[np.arange(len(target)), target]
        # Вычисляем кросс-энтропию
        loss = -np.mean(np.log(p_c + 1e-15))  # Добавляем малое значение для стабильности
        return loss

# Пример использования
# Предположим, у нас есть 5 примеров и 10 классов
probabilities = np.array([[0.1, 0.2, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
                          [0.0, 0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],
                          [0.3, 0.4, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]])

target = np.array([2, 2, 9, 1, 6])  # Целевые классы для 5 примеров

# Создание экземпляра класса и вычисление кросс-энтропии
loss_function = CrossEntropyLoss()
loss = loss_function.forward(probabilities, target)
print(f'Кросс-энтропия: {loss:.4f}')
```

### Объяснение кода

1. **Импортируем библиотеку NumPy** для работы с массивами.
2. **Создаем класс `CrossEntropyLoss`**, который будет вычислять кросс-энтропию.
3. **Метод `forward`** принимает вероятности предсказанных классов и целевые метки, вычисляет кросс-энтропию и возвращает ее значение.
4. **Пример использования**: создаем массив вероятностей для 5 примеров и целевые классы, затем вычисляем кросс-энтропию.

### Физический и геометрический смысл

Кросс-энтропия можно представить как способ измерения "расстояния" между предсказанным распределением вероятностей и истинным распределением классов. Это похоже на задачу нахождения наилучшего соответствия между двумя наборами данных, где мы хотим минимизировать ошибку предсказания. В контексте распознавания цифр, кросс-энтропия помогает нейросети "учиться" на своих ошибках, подталкивая ее к более точным предсказаниям, что в конечном итоге улучшает качество классификации.

## Chunk 11

### **Название фрагмента: Алгоритм градиентного спуска и вычисление производных**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили реализацию линейного слоя и функции softmax в нейросети, а также как эти компоненты помогают преобразовывать входные данные в вероятности для классификации. Мы также рассмотрели, как персептрон может быть адаптирован для работы с большими наборами данных.

## **Алгоритм градиентного спуска и вычисление производных**

В этом фрагменте мы сосредоточимся на алгоритме градиентного спуска, который используется для оптимизации параметров нейросети, таких как веса и смещения. Мы также обсудим, как вычисляются производные для функции ошибки, чтобы обновить параметры модели.

### Объяснение концепции

Градиентный спуск — это метод оптимизации, который используется для минимизации функции ошибки, изменяя параметры модели (веса и смещения) в направлении, противоположном градиенту функции ошибки. Это позволяет находить такие значения параметров, при которых ошибка минимальна.

Для обновления весов и смещений мы используем следующие уравнения:

$$
w^{(i+1)} = w^{(i)} - \eta \frac{\partial L}{\partial w}
$$

$$
b^{(i+1)} = b^{(i)} - \eta \frac{\partial L}{\partial b}
$$

где:
- $w^{(i)}$ и $b^{(i)}$ — текущие значения весов и смещений;
- $\eta$ — скорость обучения;
- $\frac{\partial L}{\partial w}$ и $\frac{\partial L}{\partial b}$ — производные функции ошибки по весам и смещениям.

### Математическая формализация

Для вычисления производных функции ошибки по весам и смещениям мы можем использовать цепное правило. Если функция ошибки $L$ зависит от вероятностей $p$, которые, в свою очередь, зависят от линейного выхода $z$, то мы можем записать:

$$
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial p} \cdot \frac{\partial p}{\partial z} \cdot \frac{\partial z}{\partial w}
$$

$$
\frac{\partial L}{\partial b} = \frac{\partial L}{\partial p} \cdot \frac{\partial p}{\partial z} \cdot \frac{\partial z}{\partial b}
$$

### Пример кода

Теперь давайте реализуем алгоритм градиентного спуска для обновления весов и смещений в нашей нейросети:

```python
import numpy as np
from typing import Tuple

class SimpleNeuralNetwork:
    """
    Description:
        Простая нейронная сеть с одним скрытым слоем.

    Args:
        input_size: Размер входного слоя
        hidden_size: Размер скрытого слоя
        output_size: Размер выходного слоя
        learning_rate: Скорость обучения

    Attributes:
        W1: Веса для первого слоя
        b1: Смещения для первого слоя
        W2: Веса для второго слоя
        b2: Смещения для второго слоя
        learning_rate: Скорость обучения
    """

    def __init__(self, input_size: int, hidden_size: int, output_size: int,
                 learning_rate: float = 0.01) -> None:
        """
        Description:
            Инициализация нейронной сети.

        Args:
            input_size: Размер входного слоя
            hidden_size: Размер скрытого слоя
            output_size: Размер выходного слоя
            learning_rate: Скорость обучения
        """
        self.W1 = np.random.rand(input_size, hidden_size) * 0.01
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.rand(hidden_size, output_size) * 0.01
        self.b2 = np.zeros((1, output_size))
        self.learning_rate = learning_rate

    def forward(self, X: np.ndarray) -> np.ndarray:
        """
        Description:
            Прямое распространение через сеть.

        Args:
            X: Входные данные

        Returns:
            Вероятности классов
        """
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = np.maximum(0, self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        return softmax(self.z2)

    def backward(self, X: np.ndarray, y: np.ndarray,
                 probabilities: np.ndarray) -> None:
        """
        Description:
            Обратное распространение ошибки и обновление весов.

        Args:
            X: Входные данные
            y: Метки классов (one-hot)
            probabilities: Вероятности классов, полученные на этапе прямого
                           распространения
        """
        m = y.shape[0]
        delta2 = probabilities - y
        dW2 = np.dot(self.a1.T, delta2) / m
        db2 = np.sum(delta2, axis=0, keepdims=True) / m

        delta1 = np.dot(delta2, self.W2.T) * (self.z1 > 0)
        dW1 = np.dot(X.T, delta1) / m
        db1 = np.sum(delta1, axis=0, keepdims=True) / m

        self.W1 -= self.learning_rate * dW1
        self.b1 -= self.learning_rate * db1
        self.W2 -= self.learning_rate * dW2
        self.b2 -= self.learning_rate * db2

def softmax(x: np.ndarray) -> np.ndarray:
    """
    Description:
        Вычисление функции softmax.

    Args:
        x: Входные данные

    Returns:
        Вероятности классов
    """
    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exp_x / exp_x.sum(axis=1, keepdims=True)

# Пример использования
if __name__ == "__main__":
    nn = SimpleNeuralNetwork(input_size=784, hidden_size=128, output_size=10)
    X_train = np.random.rand(100, 784)
    y_train = np.random.randint(0, 2, (100, 10))

    probabilities = nn.forward(X_train)
    nn.backward(X_train, y_train, probabilities)
```

### Объяснение кода

1. **Создаем класс `SimpleNeuralNetwork`**, который инициализирует веса и смещения для двух слоев.
2. **Метод `forward`** выполняет прямое распространение, вычисляя выходные значения на основе входных данных.
3. **Метод `backward`** вычисляет градиенты для весов и смещений, используя цепное правило, и обновляет их значения.
4. **Пример использования**: создаем экземпляр нейросети, генерируем случайные входные данные и метки, выполняем прямое и обратное распространение.

### Физический и геометрический смысл

Алгоритм градиентного спуска можно представить как процесс нахождения наилучшего пути к минимальной точке на поверхности ошибки. Это похоже на то, как человек учится на своих ошибках, корректируя свои действия, чтобы достичь желаемого результата. В контексте нейросетей, градиентный спуск позволяет модели "учиться" на своих ошибках, минимизируя функцию ошибки и улучшая качество предсказаний.

## Chunk 12

### **Название фрагмента: Алгоритм обратного распространения ошибки и обновление весов**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили реализацию линейного слоя и функции softmax в нейросети, а также как эти компоненты помогают преобразовывать входные данные в вероятности для классификации. Мы также рассмотрели, как персептрон может быть адаптирован для работы с большими наборами данных.

## **Обратное распространение ошибки (Backpropagation)**

Обратное распространение ошибки (Backpropagation) — это алгоритм обучения, используемый для эффективного обновления весов в многослойных нейронных сетях. Он основан на методе градиентного спуска, где обучение происходит путем минимизации функции потерь — разницы между фактическим выходом нейронной сети и ожидаемым результатом.

Процесс обратного распространения состоит из двух основных этапов:

- Прямое распространение (Forward Propagation): Входные данные подаются в нейронную сеть, и активации всех нейронов в сети вычисляются слой за слоем до выходного слоя. На этом этапе сеть использует текущие веса для предсказания выхода.

- Обратное распространение (Backpropagation): На этом этапе вычисляется градиент функции потерь относительно каждого веса в сети, показывая, как изменение веса влияет на общую ошибку. Это делается путем применения цепного правила из дифференциального исчисления для расчета градиентов функции потерь по весам, начиная с выходного слоя и двигаясь обратно к входному. Градиенты показывают направление, в котором веса должны быть изменены для минимизации ошибки.

После вычисления градиентов веса обновляются с использованием определенного шага обучения (learning rate), который определяет, насколько велико обновление. Шаг обучения является важным гиперпараметром, так как слишком большой шаг может привести к тому, что алгоритм будет "перепрыгивать" минимумы функции потерь, а слишком маленький — к медленному обучению.

Обратное распространение ошибки позволяет нейронным сетям обучаться от сложных данных, автоматически настраивая веса сети таким образом, чтобы минимизировать ошибку в предсказаниях. Этот процесс повторяется множество раз на различных наборах данных (эпохах), пока сеть не сможет достигнуть желаемой точности.

- ![Обратное распространение ошибки](https://raw.githubusercontent.com/Verbasik/Homework/main/Neuron/%D0%9E%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B5%20%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8.png)

Для обновления весов остаётся вычесть из них полученные значения градиентов, домноженные на шаг $η$.

Из предыдущих весов необходимо вычесть произведение скорости обучения на градиент, а не прибавить. Градиент показывает направление возрастания функции, а двигаться нужно в другую сторону.

### **Почему градиент рассчитывается для каждого веса отдельно?**

Каждый вес в нейронной сети влияет на выход сети по-разному. Градиент для каждого веса показывает, насколько сильно изменение этого веса повлияет на общую ошибку. Таким образом, для эффективного обучения необходимо учитывать индивидуальный вклад каждого веса в ошибку и обновлять их соответственно.

Таким образом, градиент действительно рассчитывается для каждого веса отдельно, и это позволяет нейронной сети эффективно обучаться, настраивая веса таким образом, чтобы минимизировать ошибку предсказаний. Важно правильно выбрать скорость обучения $( \eta )$, чтобы обеспечить баланс между скоростью обучения и стабильностью процесса.

### **Масштабирование на большие модели:**
Для моделей с миллиардами весов, таких как современные большие языковые модели (например, GPT-3, GPT-4), вычисление градиентов для каждого веса становится вычислительно очень затратным. Однако существуют методы и технологии, которые позволяют эффективно справляться с такими масштабами:

1. **Параллельные вычисления:**
   - Использование графических процессоров (GPU) и тензорных процессоров (TPU), которые могут выполнять множество операций одновременно.

2. **Оптимизации:**
   - Методы, такие как автоматическое дифференцирование (automatic differentiation), позволяют эффективно вычислять градиенты для всех весов за один проход.

3. **Распределенные вычисления:**
   - Использование кластеров из множества GPU/TPU для распределения вычислений градиентов между множеством устройств.

4. **Оптимизации памяти:**
   - Методы, такие как gradient checkpointing, позволяют экономить память, жертвуя некоторыми вычислениями.

### Пример обратного распространения

Рассмотрим простую двухслойную нейронную сеть с одним скрытым слоем. Пусть у нас есть вход $x$, веса первого слоя $W_1$, веса второго слоя $W_2$, и выход $y$. Обозначим активацию скрытого слоя как $h$ и активацию выходного слоя как $\hat{y}$.

#### Определения переменных:

- **$x$** — входные данные. Это вектор, содержащий значения признаков для одного примера из набора данных.
- **$W_1$** — матрица весов первого слоя. Она соединяет входной слой со скрытым слоем. Размерность этой матрицы зависит от количества входных признаков и количества нейронов в скрытом слое.
- **$W_2$** — матрица весов второго слоя. Она соединяет скрытый слой с выходным слоем. Размерность этой матрицы зависит от количества нейронов в скрытом слое и количества выходных нейронов.
- **$y$** — истинное значение (целевой выход) для данного примера из набора данных.
- **$h$** — активации скрытого слоя. Это результат применения активационной функции $f$ к линейной комбинации входных данных и весов первого слоя.
- **$\hat{y}$** — предсказанный выходной результат. Это результат применения активационной функции $f$ к линейной комбинации активаций скрытого слоя и весов второго слоя.
- **$\eta$** — шаг обучения (learning rate). Это гиперпараметр, который определяет размер шага, на который обновляются веса во время обучения.

1. **Прямое распространение:**

   На этапе прямого распространения входные данные $x$ проходят через нейронную сеть, и вычисляются активации всех нейронов до выходного слоя.

   Входной слой:
   $$
   h = f(W_1 \cdot x)
   $$
   Здесь $W_1 \cdot x$ представляет собой матричное умножение матрицы весов первого слоя на вектор входных данных. Функция активации $f$ применяется к результату, чтобы получить активации скрытого слоя $h$.

   Выходной слой:
   $$
   \hat{y} = f(W_2 \cdot h)
   $$
   Здесь $W_2 \cdot h$ представляет собой матричное умножение матрицы весов второго слоя на вектор активаций скрытого слоя. Функция активации $f$ применяется к результату, чтобы получить предсказанный выход $\hat{y}$.

2. **Обратное распространение:**

   На этапе обратного распространения вычисляется градиент функции потерь относительно каждого веса в сети. Это показывает, как изменение каждого веса влияет на общую ошибку.

   Вычисление ошибки:
   $$
   L = \frac{1}{2} (\hat{y} - y)^2
   $$
   Здесь $L$ — функция потерь (loss function), которая измеряет разницу между предсказанным выходом $\hat{y}$ и истинным значением $y$. Коэффициент $\frac{1}{2}$ используется для удобства при дифференцировании квадратичной функции.

   Градиент функции потерь по выходу:
   $$
   \frac{\partial L}{\partial \hat{y}} = \hat{y} - y
   $$
   Это показывает, насколько предсказанный выход $\hat{y}$ отличается от истинного значения $y$.

   Градиент функции потерь по весам второго слоя $W_2$:
   $$
   \frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial W_2} = (\hat{y} - y) \cdot h
   $$
   Здесь используется правило цепочки для вычисления градиента функции потерь по весам второго слоя. Градиент по $\hat{y}$ умножается на градиент $\hat{y}$ по $W_2$. Так как $\hat{y}$ зависит линейно от $W_2$, его производная по $W_2$ равна $h$.

   Градиент функции потерь по скрытому слою $h$:
   $$
   \frac{\partial L}{\partial h} = \frac{\partial L}{\partial \hat{y}} \cdot W_2 = (\hat{y} - y) \cdot W_2
   $$
   Здесь также используется правило цепочки. Градиент по $\hat{y}$ умножается на градиент $\hat{y}$ по $h$. Так как $h$ зависит линейно от $W_2$, его производная по $h$ равна $W_2$.

   Градиент функции потерь по весам первого слоя $W_1$:
   $$
   \frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial h} \cdot \frac{\partial h}{\partial W_1} = ((\hat{y} - y) \cdot W_2) \cdot x
   $$
   Здесь используется правило цепочки для вычисления градиента функции потерь по весам первого слоя. Градиент по $h$ умножается на градиент $h$ по $W_1$. Так как $h$ зависит линейно от $W_1$, его производная по $W_1$ равна $x$.

3. **Обновление весов:**

   Вес второго слоя:
   $$
   W_2 := W_2 - \eta \cdot \frac{\partial L}{\partial W_2}
   $$
   Здесь веса второго слоя обновляются путем вычитания градиента, умноженного на шаг обучения $\eta$. Это корректирует веса в направлении уменьшения функции потерь.

   Вес первого слоя:
   $$
   W_1 := W_1 - \eta \cdot \frac{\partial L}{\partial W_1}
   $$
   Аналогично, веса первого слоя обновляются путем вычитания градиента, умноженного на шаг обучения $\eta$.

Где $\eta$ — шаг обучения.

Таким образом, обратное распространение ошибки использует градиенты для обновления весов и минимизации функции потерь, позволяя нейронной сети обучаться на данных и улучшать свои предсказания.

### Пример кода

Теперь давайте реализуем метод обратного распространения для линейного слоя в Python:

```python
class Linear:
    def __init__(self, n_in, n_out):
        """
        Description:
            Инициализация линейного слоя.

        Args:
            n_in: Количество входных нейронов.
            n_out: Количество выходных нейронов.
        """
        self.W = np.random.normal(0, 1 / np.sqrt(n_in), (n_in, n_out))  # Инициализация весов
        self.b = np.zeros((1, n_out))                                   # Инициализация смещений
        self.delta_w = np.zeros_like(self.W)                            # Инициализация изменений весов
        self.delta_b = np.zeros_like(self.b)                            # Инициализация изменений смещений

    def forward(self, x):
        """
        Description:
            Прямое распространение через линейный слой.

        Args:
            x: Входные данные (матрица признаков).

        Returns:
            Выходные данные (результат линейного преобразования).
        """
        self.x = x                                                      # Сохраняем входные данные для обратного распространения
        return np.dot(x, self.W) + self.b                               # Вычисление выхода

    def backward(self, delta_z):
        """
        Description:
            Обратное распространение ошибки.

        Args:
            delta_z: Ошибка на выходе слоя.

        Returns:
            Изменение входных данных для следующего слоя.
        """
        self.delta_w = np.dot(self.x.T, delta_z)                        # Вычисление градиента для весов
        self.delta_b = np.sum(delta_z, axis=0, keepdims=True)           # Вычисление градиента для смещений
        return np.dot(delta_z, self.W.T)                                # Возвращаем изменение для входных данных

    def update(self, learning_rate):
        """
        Description:
            Обновление весов и смещений.

        Args:
            learning_rate: Скорость обучения.
        """
        self.W -= learning_rate * self.delta_w                          # Обновление весов
        self.b -= learning_rate * self.delta_b                          # Обновление смещений

# Пример использования
n_in = 784                                       # Количество входов (пиксели изображения)
n_out = 10                                       # Количество выходов (классы цифр)
linear_layer = Linear(n_in, n_out)

# Пример входных данных (например, одно изображение)
x_example = np.random.rand(1, n_in)              # Случайное изображение
linear_output = linear_layer.forward(x_example)  # Прямое распространение

# Пример ошибки на выходе
delta_z = np.random.rand(1, n_out)               # Случайная ошибка
delta_x = linear_layer.backward(delta_z)         # Обратное распространение

# Обновление весов
linear_layer.update(learning_rate=0.01)
```

### Объяснение кода

1. **Создаем класс `Linear`**, который инициализирует веса и смещения для линейного слоя.
2. **Метод `__init__`** инициализирует веса случайными значениями и смещения нулями, а также создает переменные для хранения изменений весов и смещений.
3. **Метод `forward`** выполняет прямое распространение, сохраняя входные данные для обратного распространения.
4. **Метод `backward`** вычисляет градиенты для весов и смещений на основе ошибки на выходе.
5. **Метод `update`** обновляет веса и смещения, используя вычисленные градиенты и скорость обучения.
6. **Пример использования**: создаем экземпляр линейного слоя, выполняем прямое и обратное распространение, а затем обновляем веса.

### Физический и геометрический смысл

Алгоритм обратного распространения ошибки можно представить как процесс, в котором нейросеть "учится" на своих ошибках, корректируя свои параметры для минимизации функции потерь. Это похоже на то, как человек учится на своих ошибках, корректируя свои действия, чтобы достичь желаемого результата. В контексте нейросетей, обратное распространение позволяет модели "настраивать" свои веса и смещения, чтобы улучшить качество предсказаний и повысить точность классификации.

## Chunk 13

### **Название фрагмента: Обучение нейросети и реализация класса для сети**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили алгоритм обратного распространения ошибки и как он используется для обновления весов в линейном слое. Мы также рассмотрели, как вычисляется точность предсказаний нейросети.

## **Обучение нейросети и реализация класса для сети**

В этом фрагменте мы сосредоточимся на процессе обучения нейросети, включая реализацию класса, который будет представлять всю сеть. Понимание принципов обучения нейросетей, особенно механизмов прямого и обратного распространения, является **фундаментальным для работы с глубоким обучением**.  Мы обсудим, как организовать слои и как выполняются ключевые процессы прямого и обратного распространения через всю сеть.

### Объяснение концепции

Нейросеть состоит из нескольких слоев, и каждый слой выполняет свои вычисления. При обучении нейросети мы используем два основных процесса: прямое распространение (forward pass) и обратное распространение (backward pass).

1. **Прямое распространение**: На этом этапе входные данные проходят через каждый слой нейросети. На выходе каждого слоя вычисляются активации, которые затем передаются на следующий слой.  Таким образом, сигнал распространяется от входа к выходу сети.
2. **Обратное распространение**: На этом этапе мы, **используя цепное правило**, вычисляем градиенты функции потерь по отношению к весам и смещениям каждого слоя, начиная с последнего.  Целью обратного распространения является **минимизация ошибки предсказания (функции потерь)**.  Вычисленные градиенты используются для обновления весов и смещений в направлении, противоположном градиенту, чтобы уменьшить ошибку.

### Математическая формализация

Для многослойной нейросети, состоящей из $L$ слоев, мы можем записать:

1. **Прямое распространение**:

$$
a^{(l)} = f(z^{(l)}) \quad \text{где} \quad z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}
$$

где:
- $a^{(l)}$ — активация на слое $l$; $a^{(0)}$ - входной слой (данные на входе сети).
- $W^{(l)}$ — матрица весов слоя $l$;
- $b^{(l)}$ — вектор смещений слоя $l$;
- $f$ — функция активации (применяется поэлементно).

2. **Обратное распространение**:

Для выходного слоя $L$:
$$
\delta^{(L)} = \frac{\partial L}{\partial a^{(L)}} \cdot f'(z^{(L)})
$$

Для скрытых слоев $l < L$:
$$
\delta^{(l)} = (W^{(l+1)})^T \delta^{(l+1)} \cdot f'(z^{(l)})
$$

Градиенты функции потерь по отношению к весам и смещениям слоя $l$:

$$
\frac{\partial L}{\partial W^{(l)}} = \delta^{(l)} (a^{(l-1)})^T
$$

$$
\frac{\partial L}{\partial b^{(l)}} = \delta^{(l)}
$$

Обновление весов и смещений (например, с использованием градиентного спуска):

$$
W^{(l)} = W^{(l)} - \alpha \frac{\partial L}{\partial W^{(l)}}
$$

$$
b^{(l)} = b^{(l)} - \alpha \frac{\partial L}{\partial b^{(l)}}
$$

где:
- $\delta^{(l)}$ — "ошибка" слоя $l$, представляющая собой градиент функции потерь по отношению к *входу* слоя $l$ ($z^{(l)}$).
- $L$ — функция потерь;
- $f'$ — производная функции активации (применяется поэлементно);
- $\alpha$ — скорость обучения (learning rate).

### Пример кода

Теперь давайте реализуем класс для нейросети, который будет включать в себя несколько слоев и методы для прямого и обратного распространения:

```python
class NeuralNetwork:
    def __init__(self):
        # Список слоев нейросети
        self.layers = []

    def add(self, layer):
        """
        Description:
            Добавление слоя в нейросеть.

        Args:
            layer: Слой, который нужно добавить.
        """
        self.layers.append(layer)

    def forward(self, x):
        """
        Description:
            Прямое распространение через нейросеть.

        Args:
            x: Входные данные.

        Returns:
            Выходные данные последнего слоя.
        """
        for layer in self.layers:
            x = layer.forward(x)            # Применяем метод forward для каждого слоя
        return x

    def backward(self, delta):
        """
        Description:
            Обратное распространение через нейросеть.

        Args:
            delta: Ошибка на выходе.

        Returns:
            Ошибка для предыдущего слоя.
        """
        for layer in reversed(self.layers):
            delta = layer.backward(delta)   # Применяем метод backward для каждого слоя
        return delta

    def update(self, learning_rate):
        """
        Description:
            Обновление весов и смещений всех слоев.

        Args:
            learning_rate: Скорость обучения.
        """
        for layer in self.layers:
            layer.update(learning_rate)     # Обновляем параметры каждого слоя

# Пример использования
nn = NeuralNetwork()
nn.add(Linear(784, 128))                            # Добавляем линейный слой
nn.add(Linear(128, 10))                             # Добавляем выходной слой

# Прямое распространение
output = nn.forward(X_train)                        # X_train - обучающие данные

# Обратное распространение
loss = cross_entropy_loss.forward(output, y_train)  # Вычисляем ошибку
delta = cross_entropy_loss.backward(loss)           # Вычисляем градиенты
nn.backward(delta)                                  # Обратное распространение
nn.update(learning_rate=0.01)                       # Обновление весов
```

### Объяснение кода

1. **Создаем класс `NeuralNetwork`**, который будет представлять всю нейросеть.
2. **Метод `add`** добавляет новый слой в нейросеть.
3. **Метод `forward`** выполняет прямое распространение через все слои, применяя метод `forward` для каждого слоя.
4. **Метод `backward`** выполняет обратное распространение, начиная с последнего слоя и применяя метод `backward` для каждого слоя.
5. **Метод `update`** обновляет веса и смещения всех слоев, используя заданную скорость обучения.
6. **Пример использования**: создаем экземпляр нейросети, добавляем слои, выполняем прямое и обратное распространение, а затем обновляем веса.

## Chunk 14

### **Название фрагмента: Добавление промежуточных слоев и функции активации в нейросети**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как многослойные нейросети могут быть использованы для распознавания цифр, а также как метод "один против всех" позволяет свести многоклассовую классификацию к нескольким бинарным задачам. Мы также рассмотрели, как реализовать класс для нейросети, который включает в себя несколько слоев и методы для прямого и обратного распространения.

## **Добавление промежуточных слоев и функций активации**

В этом фрагменте мы сосредоточимся на важности добавления промежуточных слоев и функций активации в нейросети. Мы обсудим, как эти компоненты позволяют нейросетям решать более сложные задачи, такие как нелинейно разделимые классы.

### Объяснение концепции

Добавление промежуточных слоев в нейросеть позволяет ей моделировать более сложные функции. Каждый слой может извлекать различные уровни абстракции из входных данных, что делает нейросеть более мощной и способной решать задачи, которые не могут быть решены с помощью однослойного персептрона.

Однако, если мы добавим несколько линейных слоев подряд без функций активации, то вся нейросеть будет эквивалентна одному линейному слою. Это происходит потому, что последовательное умножение на матрицы весов можно свести к одному умножению на новую матрицу весов.

Чтобы нейросеть могла решать более сложные задачи, необходимо добавлять функции активации между слоями. Эти функции, такие как гиперболический тангенс или ReLU, вводят нелинейность в модель, что позволяет ей создавать сложные разделяющие поверхности.

### Математическая формализация

Для многослойной нейросети с одним скрытым слоем и функцией активации $f$, выходной вектор $y$ можно выразить следующим образом:

1. **Прямое распространение**:

$$
a^{(1)} = f(W^{(1)} \cdot x + b^{(1)}) \quad \text{(скрытый слой)}
$$

$$
y = softmax(W^{(2)} \cdot a^{(1)} + b^{(2)}) \quad \text{(выходной слой)}
$$

где:
- $a^{(1)}$ — активация на скрытом слое;
- $W^{(1)}$ и $b^{(1)}$ — веса и смещения для скрытого слоя;
- $W^{(2)}$ и $b^{(2)}$ — веса и смещения для выходного слоя.

### Пример кода

Теперь давайте реализуем класс для функции активации гиперболического тангенса и добавим его в нашу нейросеть:

```python
class Tanh:
    def forward(self, x):
        """
        Description:
            Прямое распространение через слой гиперболического тангенса.

        Args:
            x: Входные данные.

        Returns:
            Выходные данные после применения гиперболического тангенса.
        """
        self.output = np.tanh(x)                    # Применение гиперболического тангенса
        return self.output

    def backward(self, delta):
        """
        Description:
            Обратное распространение через слой гиперболического тангенса.

        Args:
            delta: Ошибка на выходе.

        Returns:
            Ошибка для предыдущего слоя.
        """
        return delta * (1 - np.square(self.output))  # Производная гиперболического тангенса

# Пример использования
nn = NeuralNetwork()
nn.add(Linear(784, 128))      # Добавляем скрытый слой
nn.add(Tanh())                # Добавляем функцию активации
nn.add(Linear(128, 10))       # Добавляем выходной слой

# Прямое распространение
output = nn.forward(X_train)  # X_train - обучающие данные

# Обратное распространение
loss = cross_entropy_loss.forward(output, y_train)  # Вычисляем ошибку
delta = cross_entropy_loss.backward(loss)           # Вычисляем градиенты
nn.backward(delta)                                  # Обратное распространение
nn.update(learning_rate=0.01)                       # Обновление весов
```

### Объяснение кода

1. **Создаем класс `Tanh`**, который реализует функцию активации гиперболического тангенса.
2. **Метод `forward`** применяет гиперболический тангенс к входным данным и сохраняет результат.
3. **Метод `backward`** вычисляет градиенты для обратного распространения, используя производную гиперболического тангенса.
4. **Создаем экземпляр нейросети**, добавляем слои и функции активации, выполняем прямое и обратное распространение, а затем обновляем веса.

### Физический и геометрический смысл

Добавление функций активации, таких как гиперболический тангенс, позволяет нейросети моделировать сложные зависимости в данных. Это можно представить как возможность "изгибать" разделяющие поверхности, что позволяет лучше различать классы, которые не могут быть разделены линейной границей. В контексте распознавания цифр, использование нелинейных функций активации позволяет нейросети адаптироваться к различным стилям написания, улучшая точность классификации.

## Chunk 15

### **Название фрагмента: Признаки и их влияние на обучение нейросетей**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как многослойные нейросети могут решать более сложные задачи, чем однослойные персептроны, и как функции активации добавляют нелинейность в модель. Мы также рассмотрели, как реализовать класс для нейросети, который включает в себя несколько слоев и методы для прямого и обратного распространения.

## **Признаки и их влияние на обучение нейросетей**

В этом фрагменте мы сосредоточимся на важности выбора признаков для обучения нейросетей. Мы обсудим, как правильный выбор признаков может значительно улучшить качество предсказаний и упростить задачу для модели.

### Объяснение концепции

Признаки — это входные данные, которые мы используем для обучения модели. Они могут быть различными характеристиками, которые помогают модели делать предсказания. Например, в задаче распознавания цифр, пиксели изображения являются признаками. Однако не всегда достаточно просто использовать исходные данные; иногда необходимо извлекать новые признаки, чтобы улучшить качество классификации.

Например, если мы хотим классифицировать цифры 2 и 5, добавление новых признаков, таких как квадраты входных значений или произведения признаков, может помочь линейной модели лучше различать эти цифры. Это связано с тем, что некоторые задачи, такие как XOR, не могут быть решены линейными моделями, но могут быть решены, если мы добавим соответствующие признаки.

### Математическая формализация

Если у нас есть входные данные $x_1$ и $x_2$, мы можем создать новые признаки следующим образом:

1. **Квадраты признаков**:

$$
x_1^2, \quad x_2^2
$$

2. **Произведение признаков**:

$$
x_1 \cdot x_2
$$

Таким образом, мы можем расширить наш вектор признаков:

$$
x' = [x_1, x_2, x_1^2, x_2^2, x_1 \cdot x_2]
$$

## **Преобразование признаков**:

Применение математических преобразований к признакам помогает улучшить распределение данных, сделать их более "нормальными", или улучшить их взаимосвязь с целевой переменной.

Существуют такие методы как логарифмирование, степенное преобразование, нормализация и стандартизация.

### Логарифмирование:

- Помогает справиться с экспоненциальным распределением данных.

### Степенное преобразование:
- Применяется, когда данные распределены неравномерно.

### Нормализация:

- Преобразование данных таким образом, чтобы они располагались в диапазоне от 0 до 1.

**Нормализация (или Минимаксное масштабирование)** преобразует все численные признаки в диапазон между заданными минимальным и максимальным значениями, часто между 0 и 1, без изменения формы распределения данных. Это делается по формуле:

$$
\text{Нормализованное значение} = \frac{x - \min(x)}{\max(x) - \min(x)}
$$

где $(x)$ — исходное значение, $(\min(x))$ и $(\max(x))$ — минимальное и максимальное значения признака соответственно. Этот метод полезен, когда точные значения диапазонов признаков не важны или когда вы хотите подавить эффект очень больших числовых значений.

### Стандартизация:

- Преобразование данных так, чтобы иметь нулевое среднее значение и стандартное отклонение, равное 1.

**Стандартизация (или Z-оценка нормализация)** изменяет распределение значений признаков так, чтобы они имели среднее значение, равное 0, и стандартное отклонение, равное 1. Это достигается путем вычитания среднего значения признака из каждого значения и деления результата на стандартное отклонение всего признака:

$$
\text{Стандартизированное значение} = \frac{x - \mu}{\sigma}
$$

где $(x)$ — исходное значение, $(\mu)$ — среднее значение признака, а $(\sigma)$ — стандартное отклонение признака. Стандартизация полезна, когда данные имеют нормальное распределение, а также в алгоритмах, чувствительных к масштабу признаков, например, в методах, основанных на измерении расстояний.

**Основные различия между нормализацией и стандартизацией**

- **Диапазон значений**: Нормализация приводит значения к диапазону между 0 и 1 (или другому заданному диапазону), в то время как стандартизация преобразует данные к значениям с нулевым средним и единичным стандартным отклонением;

- **Распределение данных**: Стандартизация может быть более предпочтительной, когда данные распределены нормально, тогда как нормализация может быть использована независимо от распределения признаков;

- **Чувствительность к выбросам**: Нормализация может быть более чувствительной к выбросам, поскольку они влияют на минимальные и максимальные значения, используемые для масштабирования. Стандартизация менее чувствительна к выбросам, поскольку она фокусируется на распределении значений относительно среднего.

### Создание полиномиальных признаков

- Полиномиальные признаки позволяют моделям обнаруживать более сложные взаимодействия между признаками.

### One-Hot Encoding

**one-hot** — двоичный код фиксированной длины, содержащий только одну единицу.

- Преобразует категориальные переменные в формат, который можно предоставить алгоритмам машинного обучения.

**Пример**

В каждом столбце с категориальными данными надо считать число уникальных вариантов. Предположим, что в магазине продаются кроссовки десяти цветов. Определяем, какое место в числовом векторе будет соответствовать каждой расцветке. Пусть красные будут вторыми по счёту. Тогда красный цвет будет обозначаться вектором [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. Не забудьте, что индексы считаются с нуля. Каждому цвету будет соответствовать уникальный вектор.


### Анализ главных компонент (PCA)

## Определение

**Анализ главных компонент (PCA)** — это статистическая процедура, которая использует ортогональное преобразование для перевода набора наблюдений возможно коррелированных переменных в набор значений линейно некоррелированных переменных, называемых главными компонентами. Этот метод широко применяется в области сокращения размерности данных, сохраняя при этом как можно больше информации.

## Механизм работы алгоритма

Процесс PCA можно разделить на несколько основных шагов:

1. **Стандартизация данных.** Все переменные должны быть приведены к одному масштабу, поскольку PCA чувствителен к масштабу переменных;
2. **Вычисление ковариационной матрицы.** Она показывает, как переменные связаны друг с другом.
3. **Нахождение собственных векторов и собственных значений ковариационной матрицы;** Собственные векторы указывают направления максимальной вариативности данных, а собственные значения — величину этой вариативности;
4. **Сортировка собственных векторов по убыванию собственных значений.** Это позволяет ранжировать главные компоненты по степени важности;
5. **Преобразование исходных данных.** Используя собственные векторы, данные преобразуются в новый набор переменных — главные компоненты.

## Математические формулы

Ковариационная матрица $\Sigma$ вычисляется как:

$$\Sigma = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \mu)(x_i - \mu)^T$$

где $x_i$ — это вектор-столбец $i$-го наблюдения, $\mu$ — вектор средних значений каждой переменной, $n$ — количество наблюдений.

Собственные значения $\lambda$ и собственные векторы $v$ ковариационной матрицы находятся из уравнения:

$$\Sigma v = \lambda v$$

Преобразованные данные в терминах главных компонент вычисляются как:

$$Y = Xv$$

где $X$ — исходные данные, $v$ — матрица собственных векторов.

### Пример кода

Теперь давайте реализуем функцию для извлечения новых признаков из исходных данных:

```python
def extract_features(X):
    """
    Description:
        Извлечение новых признаков из исходных данных.

    Args:
        X: Исходные данные (матрица признаков).

    Returns:
        Новая матрица признаков с добавленными квадратами и произведениями.
    """
    x1 = X[:, 0]  # Первый признак
    x2 = X[:, 1]  # Второй признак

    # Создание новых признаков
    x1_squared = x1 ** 2
    x2_squared = x2 ** 2
    x1_x2 = x1 * x2

    # Объединение всех признаков в одну матрицу
    new_features = np.column_stack((x1, x2, x1_squared, x2_squared, x1_x2))
    return new_features

# Пример использования
X_train = np.random.rand(100, 2)              # Случайные входные данные (100 примеров, 2 признака)
X_train_expanded = extract_features(X_train)  # Извлечение новых признаков
print(X_train_expanded.shape)                 # Проверка размерности новой матрицы признаков
```

### Объяснение кода

1. **Создаем функцию `extract_features`**, которая принимает исходные данные и извлекает новые признаки.
2. **Извлекаем первый и второй признаки** из входной матрицы.
3. **Создаем новые признаки**: квадраты и произведение исходных признаков.
4. **Объединяем все признаки** в одну матрицу с помощью `np.column_stack`.
5. **Пример использования**: генерируем случайные входные данные и извлекаем новые признаки, проверяя размерность новой матрицы.

## Chunk 16

### **Название фрагмента: Переобучение и сложности многослойных нейросетей**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как добавление промежуточных слоев и функций активации в нейросети позволяет решать более сложные задачи, такие как распознавание нелинейно разделимых классов. Мы также рассмотрели, как реализовать класс для нейросети, который включает в себя несколько слоев и методы для прямого и обратного распространения.

## **Переобучение и сложности многослойных нейросетей**

В машинном обучении, и особенно при работе с нейронными сетями, ключевой целью является создание моделей, способных к *обобщению*. Обобщение означает способность модели корректно работать не только на данных, на которых она была обучена, но и на новых, ранее не виденных данных.  Переобучение (overfitting) является одной из основных проблем, препятствующих достижению хорошего обобщения, особенно при использовании сложных многослойных нейросетей. В этом фрагменте мы подробно рассмотрим концепцию переобучения, причины его возникновения, методы диагностики и стратегии предотвращения. Мы также обсудим, почему многослойные модели, несмотря на свою мощь, более склонны к переобучению и требуют особого внимания при обучении.

### Объяснение концепции переобучения

Переобучение (overfitting) возникает, когда модель начинает "запоминать" обучающие данные, а не учится выделять общие закономерности.  В результате модель чрезмерно адаптируется к шуму и случайным колебаниям, присутствующим в обучающем наборе. Это приводит к тому, что модель демонстрирует отличные результаты на обучающих данных, но теряет способность эффективно работать на новых, невидимых данных, таких как тестовый или валидационный набор.  Другими словами, модель теряет свою *обобщающую способность*.

**Аналогия:** Представьте студента, который заучил ответы на все вопросы в учебнике к экзамену, но не понял сами темы. На экзамене, если вопросы будут точно такими же, он получит отличную оценку. Однако, если ему зададут немного измененные вопросы, требующие понимания материала, он, скорее всего, провалится. Переобученная нейросеть ведет себя аналогично: она "заучивает" обучающие примеры, но не понимает лежащих в их основе закономерностей.

### Причины переобучения

Переобучение может быть вызвано несколькими факторами, часто действующими в совокупности:

1. **Избыточная сложность модели:** Многослойные нейросети, особенно глубокие, обладают высокой *емкостью* (capacity), то есть способностью аппроксимировать очень сложные функции.  Если модель слишком сложна для решаемой задачи и объема доступных данных, она может "переусложнить" решение, подстраиваясь под детали обучающего набора, включая шум.  Количество слоев, количество нейронов в слоях, и сложность функций активации – все это влияет на сложность модели.  Например, глубокая ResNet или Transformer модель, используемая для простой задачи классификации изображений с небольшим набором данных, будет склонна к переобучению.

2. **Недостаточный объем обучающих данных:**  Даже модель умеренной сложности может переобучиться, если обучающих данных недостаточно для того, чтобы модель выучила общие закономерности, а не частные случаи.  Чем меньше данных, тем легче модели "запомнить" их и тем выше риск переобучения.  В идеале, обучающий набор должен быть достаточно большим и репрезентативным, чтобы охватывать все разнообразие входных данных.  Например, обучение сложной языковой модели, такой как GPT, на очень маленьком корпусе текста приведет к переобучению.

3. **Шум в данных и выбросы:** Обучающие данные могут содержать шум, ошибки измерения, или выбросы (аномальные значения). Переобученная модель может попытаться "объяснить" и эти аномалии, вместо того чтобы игнорировать их как случайные отклонения.

4. **Неправильный выбор признаков (feature selection):** Если признаки, используемые для обучения, нерелевантны или избыточны, модель может сосредоточиться на несущественных деталях и шуме, вместо того чтобы выявлять важные закономерности.  Неправильно подобранные признаки могут затруднить обучение и способствовать переобучению.

### Последствия переобучения

Основным последствием переобучения является **плохая обобщающая способность**.  Это проявляется в следующем:

* **Высокая точность на обучающем наборе и низкая точность на тестовом/валидационном наборе:**  Разрыв между производительностью на обучающих и тестовых данных является ключевым индикатором переобучения. Чем больше этот разрыв, тем сильнее переобучение.
* **Нестабильность модели:** Переобученная модель может быть очень чувствительна к небольшим изменениям во входных данных.  Небольшие отклонения от обучающих примеров могут приводить к значительным изменениям в предсказаниях.
* **Плохая производительность в реальных условиях:**  В конечном итоге, цель обучения модели – ее применение в реальных условиях, на новых данных. Переобученная модель, хорошо работающая только на обучающих данных, окажется бесполезной на практике.

### Диагностика переобучения

Для выявления переобучения используются следующие методы:

1. **Сравнение производительности на обучающем и валидационном/тестовом наборах:**  Как уже упоминалось, значительное расхождение в метриках (например, точности, F1-мере, AUC-ROC) между обучающим и валидационным/тестовым наборами является явным признаком переобучения.

2. **Кривые обучения (learning curves):**  Построение графиков зависимости метрик (например, ошибки или точности) от количества эпох обучения для обучающего и валидационного наборов позволяет визуально оценить процесс обучения. При переобучении кривая ошибки на обучающем наборе продолжает снижаться, а кривая ошибки на валидационном наборе начинает расти или стабилизируется после достижения минимума.  Аналогично, кривая точности на обучающем наборе растет, а на валидационном – перестает расти или начинает снижаться.

3. **Кросс-валидация:**  Использование кросс-валидации позволяет получить более надежную оценку обобщающей способности модели. Если при кросс-валидации наблюдается значительная дисперсия в оценках производительности между разными фолдами, это может указывать на нестабильность модели и переобучение.

### Методы борьбы с переобучением (Регуляризация)

Существует ряд методов, направленных на снижение переобучения и улучшение обобщающей способности моделей:

1. **Увеличение объема обучающих данных:**  Сбор и разметка большего количества данных – один из самых эффективных способов борьбы с переобучением.  Больше данных позволяет модели лучше выучить общие закономерности и снижает влияние шума и случайных колебаний.

2. **Упрощение модели:**  Уменьшение сложности модели, например, за счет сокращения количества слоев или нейронов, использования более простых архитектур, может помочь снизить переобучение.  Однако важно найти баланс, чтобы модель оставалась достаточно мощной для решения задачи.

3. **Регуляризация:**  Методы регуляризации вводят дополнительные ограничения на параметры модели в процессе обучения,  стимулируя модель к поиску более простых и обобщающих решений.  Основные виды регуляризации:
    * **L1 и L2 регуляризация (весовая регуляризация):** Добавление к функции потерь штрафа за большие значения весов. L2 регуляризация (Ridge) штрафует квадраты весов, стремясь к равномерному распределению весов. L1 регуляризация (Lasso) штрафует абсолютные значения весов, способствуя разреженности весов (обнулению маловажных весов) и, как следствие, отбору признаков.
    * **Dropout:**  Случайное "выключение" части нейронов во время обучения.  Это заставляет сеть учиться более робастным представлениям, не полагаясь чрезмерно на отдельные нейроны, и имитирует обучение ансамбля моделей.
    * **Batch Normalization:**  Нормализация выходных данных каждого слоя.  Batch Normalization ускоряет обучение, делает его более стабильным и может оказывать регуляризующий эффект, снижая зависимость от конкретных весов.

4. **Ранняя остановка (Early Stopping):**  Мониторинг производительности модели на валидационном наборе в процессе обучения.  Обучение останавливается, как только производительность на валидационном наборе начинает ухудшаться (обычно после достижения минимума ошибки на валидации), даже если ошибка на обучающем наборе продолжает снижаться.  Это предотвращает дальнейшее "запоминание" обучающих данных.

5. **Аугментация данных (Data Augmentation):**  Создание новых обучающих примеров на основе существующих путем применения различных трансформаций (например, повороты, сдвиги, масштабирование изображений, добавление шума).  Аугментация увеличивает разнообразие обучающих данных и помогает модели стать более инвариантной к различным вариациям входных данных.

6. **Кросс-валидация для выбора гиперпараметров:**  Использование кросс-валидации для подбора оптимальных значений гиперпараметров модели (например, коэффициента регуляризации, скорости обучения, архитектуры сети).  Это позволяет выбрать модель, которая лучше всего обобщает данные.

### Математическая формализация (дополнено)

Для оценки переобучения, помимо точности, можно использовать и другие метрики, а также рассматривать их динамику на обучающем и валидационном наборах.

1. **Точность (Accuracy)** - уже представлена в исходном тексте.

2. **Ошибка (Loss) или Функция потерь:**  Функция, которую модель стремится минимизировать в процессе обучения.  Например, кросс-энтропия для задач классификации, среднеквадратичная ошибка (MSE) для задач регрессии.  Важно отслеживать ошибку как на обучающем, так и на валидационном наборе.

3. **Другие метрики классификации:**  В зависимости от задачи, могут быть важны Precision, Recall, F1-score, AUC-ROC и другие метрики, особенно в задачах с несбалансированными классами.

4. **Регуляризация (математически):**

   * **L2 регуляризация:**  К исходной функции потерь $J(\theta)$ добавляется штраф, пропорциональный сумме квадратов весов:

     $$
     J_{reg}(\theta) = J(\theta) + \lambda \sum_{i} \theta_i^2
     $$
     где $\lambda$ - коэффициент регуляризации, контролирующий силу регуляризации.

   * **L1 регуляризация:**  К исходной функции потерь $J(\theta)$ добавляется штраф, пропорциональный сумме абсолютных значений весов:

     $$
     J_{reg}(\theta) = J(\theta) + \lambda \sum_{i} |\theta_i|
     $$

### Сложности многослойных нейросетей и переобучение

Многослойные нейросети, благодаря своей глубине и нелинейности, обладают огромной выразительной мощью.  Однако именно эта мощь делает их более склонными к переобучению, чем более простые модели.  Чем больше слоев и нейронов, тем больше параметров в модели, и тем выше ее *емкость*.  Следовательно, многослойные сети требуют большего объема обучающих данных и более тщательного применения методов регуляризации для предотвращения переобучения.  Баланс между сложностью модели и ее обобщающей способностью – ключевой аспект успешного обучения глубоких нейросетей.

**Примеры:**

* **VGG, ResNet, DenseNet:**  Эти глубокие архитектуры, разработанные для ImageNet, содержат миллионы параметров.  При их применении к небольшим наборам данных (например, CIFAR-10 с 50,000 обучающих изображений) без адекватной регуляризации и аугментации данных, они легко переобучаются.
* **Трансформеры (Transformers):**  Модели-трансформеры, такие как BERT, GPT, особенно в больших версиях, имеют огромное количество параметров (от сотен миллионов до миллиардов).  Для их эффективного обучения и предотвращения переобучения требуются очень большие объемы текстовых данных и продвинутые методы регуляризации.

### Практические советы и Workflow для предотвращения переобучения

1. **Начните с простого:**  Приступая к решению задачи, начните с более простых моделей.  Увеличивайте сложность модели постепенно, только если это необходимо для достижения желаемой производительности.

2. **Оценка размера данных:**  Оцените, достаточно ли у вас данных для выбранной сложности модели.  Общее правило: чем сложнее модель, тем больше данных ей требуется.  Если данных мало, рассмотрите возможность использования более простых моделей или методов аугментации данных.

3. **Разделение данных:**  Обязательно разделите данные на обучающий, валидационный и тестовый наборы.  Валидационный набор используется для мониторинга переобучения и подбора гиперпараметров, тестовый – для финальной оценки обобщающей способности.

4. **Мониторинг кривых обучения:**  В процессе обучения регулярно отслеживайте кривые обучения (ошибки и метрики на обучающем и валидационном наборах).  Это поможет вам вовремя заметить признаки переобучения.

5. **Экспериментируйте с регуляризацией:**  Активно используйте методы регуляризации (L1, L2, Dropout, Batch Normalization).  Подбирайте оптимальные значения гиперпараметров регуляризации с помощью валидационного набора или кросс-валидации.

6. **Аугментация данных:**  Применяйте аугментацию данных, если это применимо к вашей задаче.  Аугментация может значительно улучшить обобщающую способность, особенно при ограниченном объеме данных.

7. **Ранняя остановка:**  Используйте раннюю остановку, чтобы предотвратить переобучение на поздних этапах обучения.

8. **Кросс-валидация для надежной оценки:**  Используйте кросс-валидацию для более надежной оценки производительности модели и подбора гиперпараметров.

9. **Итеративный процесс:**  Обучение нейросетей – это итеративный процесс.  Не бойтесь экспериментировать, пробовать разные подходы и анализировать результаты.  Регулярно возвращайтесь к шагам 1-8 и корректируйте свою стратегию в зависимости от результатов.

**Заключение**

Переобучение – это распространенная и серьезная проблема при обучении нейронных сетей, особенно многослойных.  Понимание причин переобучения, умение его диагностировать и применять методы борьбы с ним – важные навыки для любого специалиста по машинному обучению.  Выбор оптимальной архитектуры сети, объема данных, методов регуляризации и стратегии обучения – это итеративный процесс, требующий экспериментов и анализа результатов.  Целью всегда должно быть создание модели, которая не только хорошо работает на обучающих данных, но и обладает высокой обобщающей способностью, то есть способна эффективно решать задачу на новых, ранее не виденных данных.

### Пример кода

Теперь давайте реализуем функцию для оценки точности на обучающем и тестовом наборах данных:

```python
def calculate_accuracy(predictions, labels):
    """
    Description:
        Вычисление точности предсказаний.

    Args:
        predictions: Предсказанные классы.
        labels: Истинные классы.

    Returns:
        Точность предсказаний.
    """
    correct_predictions = np.sum(predictions == labels)              # Количество правильных предсказаний
    accuracy = correct_predictions / len(labels)                     # Вычисление точности
    return accuracy

# Пример использования
train_predictions = np.random.randint(0, 2, size=100)                # Случайные предсказания для обучающего набора
train_labels = np.random.randint(0, 2, size=100)                     # Случайные истинные метки для обучающего набора

test_predictions = np.random.randint(0, 2, size=50)                  # Случайные предсказания для тестового набора
test_labels = np.random.randint(0, 2, size=50)                       # Случайные истинные метки для тестового набора

train_accuracy = calculate_accuracy(train_predictions, train_labels) # Точность на обучающем наборе
test_accuracy = calculate_accuracy(test_predictions, test_labels)    # Точность на тестовом наборе

print(f'Точность на обучающем наборе: {train_accuracy:.2f}')
print(f'Точность на тестовом наборе: {test_accuracy:.2f}')
```

### Объяснение кода

1. **Создаем функцию `calculate_accuracy`**, которая принимает предсказания и истинные метки, вычисляет количество правильных предсказаний и возвращает точность.
2. **Генерируем случайные предсказания и метки** для обучающего и тестового наборов.
3. **Вычисляем точность** на обучающем и тестовом наборах, выводя результаты.

## Final Summary

### **История и основы нейронных сетей**

В этом фрагменте рассматривается модель персептрона, предложенная Франком Розенблатом в 1957 году. Персептрон — это простейшая модель нейронной сети, предназначенная для распознавания образов. Он принимает на вход несколько сигналов, которые суммируются и обрабатываются с использованием весов для определения выходного сигнала. Выход персептрона вычисляется как пороговая функция от скалярного произведения весов и входных данных.

### **Критерий персептрона и его оптимизация**

Критерий персептрона — это функция ошибки, которая измеряет качество классификации, фокусируясь на неправильно классифицированных точках. Ошибка определяется как разница между истинным классом и предсказанным значением. Метод градиентного спуска используется для минимизации функции ошибки, обновляя веса и смещения модели.

### **Алгоритм градиентного спуска и вычисление производных**

Градиентный спуск — это метод оптимизации, который минимизирует функцию ошибки, изменяя параметры модели в направлении, противоположном градиенту. Для обновления весов и смещений используются производные функции ошибки, которые вычисляются с помощью цепного правила.

### **Обучение нейросети и использование промежуточных слоев**

Обучение нейросети включает прямое и обратное распространение. Добавление промежуточных слоев позволяет нейросети моделировать более сложные функции и извлекать различные уровни абстракции из входных данных. Это делает нейросеть более мощной и способной решать задачи, которые не могут быть решены с помощью однослойного персептрона.

### **Добавление промежуточных слоев и функции активации**

Добавление функций активации, таких как гиперболический тангенс и ReLU, позволяет нейросети создавать сложные разделяющие поверхности. Это позволяет лучше различать классы, которые не могут быть разделены линейной границей, и улучшает точность классификации.

### **Признаки и их влияние на обучение нейросетей**

Правильный выбор признаков для обучения нейросетей может значительно улучшить качество предсказаний. Извлечение новых признаков, таких как квадраты и произведения исходных признаков, может помочь модели лучше различать классы, особенно в сложных задачах.

### **Переобучение и выбор архитектуры нейросети**

Переобучение происходит, когда модель слишком хорошо подстраивается под обучающие данные, что приводит к плохой обобщающей способности на новых данных. Чтобы избежать переобучения, важно использовать методы регуляризации и выбирать архитектуру нейросети в зависимости от объема данных и сложности задачи.

### **Заключение и дальнейшие шаги в обучении нейросетей**

Обучение нейросетей — это сложный процесс, который требует понимания различных аспектов, таких как выбор архитектуры, функции активации и методы оптимизации. Эти знания являются основой для дальнейшего изучения более сложных моделей и алгоритмов в области машинного обучения. Важно продолжать практиковаться и экспериментировать с различными архитектурами и методами, чтобы углубить понимание и навыки в этой области.
