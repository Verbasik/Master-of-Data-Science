# Оглавление

**I. Метрики оценки качества предсказаний**
*   Введение в математическое ожидание и дисперсию
*   Центральная предельная теорема и её применение
*   Вычисление математического ожидания и дисперсии для нормального распределения
*   Вычисление математического ожидания и дисперсии модуля случайной величины
*   Метрики MAPE и S-MAPE в оценке качества предсказаний
*   Проблемы с MAPE и преимущества S-MAPE
*   Симметричность S-MAPE и её ограничения
*   Сравнение метрик MAE и MSE
*   Понимание R-квадрат и его применение
*   Понимание относительных метрик и их применение
*   Гибридные метрики: Huber и Log-Cosh
*   Квантильная функция потери и её применение
*   Сравнение MSE и MAE в контексте выбросов
*   Влияние выбросов на MSE и MAE
*   Влияние выбросов на MSE и MAE, и применение Huber
*   Квантильные интервалы и метод Bootstrap
*   Метод Bootstrap для оценки качества моделей
*   Доверительные интервалы и центральная предельная теорема
*   Доверительные интервалы для MAE и MSE с использованием Bootstrap и ЦПТ
*   Понимание распределений и их влияние на метрики

**II. Заключение и рекомендации по курсу**
*   Основные выводы по метрикам и их применению
*   Рекомендации по практике и дальнейшему обучению


# Введение

В данной лекции будут рассмотрены **метрики для оценки качества предсказаний моделей**, такие как MSE, MAE, MAPE, S-MAPE, Huber и Log-Cosh. Будет обсуждаться, как **выбросы в данных могут влиять на эти метрики** и как использовать метод Bootstrap для построения доверительных интервалов. Также будет рассмотрена центральная предельная теорема и её роль в построении доверительных интервалов.


# Глассарий терминов

*   **Математическое ожидание (мат. ожидание)** – среднее значение случайной величины $X$, обозначается как $E(X)$ и вычисляется по формуле $ E(X) = \int_{-\infty}^{+\infty} x \cdot f(x) , dx $, где $f(x)$ – функция плотности вероятности случайной величины $X$.

*   **Дисперсия** – мера степени разброса значений случайной величины относительно её математического ожидания, обозначается как $D(X)$ и вычисляется по формуле $ D(X) = E((X - E(X))^2) = E(X^2) - (E(X))^2 $, где $E(X^2)$ – математическое ожидание квадрата случайной величины.

*   **Центральная предельная теорема (ЦПТ)** – утверждает, что при достаточно большом количестве независимых и одинаково распределенных случайных величин, их сумма (или среднее) будет стремиться к нормальному распределению, независимо от формы исходного распределения.

*   **Средняя абсолютная ошибка (MAE)** – среднее значение абсолютных ошибок между истинными и предсказанными значениями, вычисляется по формуле $ \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| $.

*   **Средняя квадратичная ошибка (MSE)** – среднее значение квадратов ошибок, вычисляется по формуле $ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $. MSE более чувствительна к выбросам.

*   **R-квадрат (коэффициент детерминации)** – метрика, измеряющая, насколько хорошо предсказанные значения модели соответствуют истинным значениям, позволяющая понять, какую долю вариации в данных объясняет модель.

*   **MAPE (Mean Absolute Percentage Error)** – относительная метрика, показывающая среднее абсолютное процентное отклонение предсказанных значений от истинных значений, вычисляется по формуле $ \text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100% $.

*   **S-MAPE (Symmetric Mean Absolute Percentage Error)** – относительная метрика, учитывающая как истинные, так и предсказанные значения в знаменателе, что делает её более устойчивой к малым значениям, вычисляется по формуле $ \text{S-MAPE} = \frac{1}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{|y_i| + |\hat{y}_i|} \times 100% $.

*   **Метрика Huber** – гибридная метрика, объединяющая преимущества MAE и MSE, определяемая как:
    $ L_{\delta}(y, \hat{y}) = \begin{cases} \frac{1}{2}(y - \hat{y})^2 & \text{если } |y - \hat{y}| \leq \delta \ \delta \cdot (|y - \hat{y}| - \frac{1}{2}\delta) & \text{иначе} \end{cases} $, где $\delta$ – порог, определяющий, когда использовать MSE или MAE.

*   **Метрика Log-Cosh** – гибридная метрика, определяемая как $ L(y, \hat{y}) = \log(\cosh(y - \hat{y})) $, где $\cosh(x)$ – гиперболический косинус, вычисляемый как $ \cosh(x) = \frac{e^x + e^{-x}}{2} $. Ведет себя как MSE для небольших ошибок и как MAE для больших ошибок, что делает её устойчивой к выбросам.

*   **Квантильная функция потери** – метрика, позволяющая настраивать модель в зависимости от того, насколько критично недопрогнозировать или перепрогнозировать значения, определяемая как: $ L(y, \hat{y}) = \begin{cases} \theta (y - \hat{y}) & \text{если } y - \hat{y} < 0 \ (1 - \theta)(y - \hat{y}) & \text{иначе} \end{cases} $, где $\theta$ – гиперпараметр.

*   **Метод Bootstrap** – статистический метод, позволяющий оценить распределение статистики на основе повторных выборок из имеющихся данных, используемый для построения доверительных интервалов.

*   **Доверительные интервалы** – диапазон значений, в котором с определенной вероятностью находится истинное значение метрики, показывающий надежность результатов модели.

---

# Summarization for Text

## Chunk 1

### **Название фрагмента: Введение в мат ожидание и дисперсию**

**Предыдущий контекст:** В предыдущем фрагменте обсуждались основные темы семинара, включая задачи по машинному обучению и метрики регрессии. Теперь мы переходим к основам теории вероятности, а именно к математическому ожиданию и дисперсии.

## **Математическое ожидание и дисперсия**

Математическое ожидание (мат ожидание) и дисперсия — это ключевые концепции в теории вероятностей, которые помогают описать случайные величины. 

### Математическое ожидание

Математическое ожидание случайной величины $X$ обозначается как $E(X)$ и представляет собой среднее значение, которое мы ожидаем получить, если будем многократно проводить эксперимент. Оно вычисляется по формуле:

$$
E(X) = \int_{-\infty}^{+\infty} x \cdot f(x) \, dx
$$

где:
- $f(x)$ — функция плотности вероятности случайной величины $X$.

### Дисперсия

Дисперсия случайной величины $X$, обозначаемая как $D(X)$, измеряет степень разброса значений случайной величины относительно её математического ожидания. Она вычисляется по формуле:

$$
D(X) = E((X - E(X))^2) = E(X^2) - (E(X))^2
$$

где:
- $E(X^2)$ — математическое ожидание квадрата случайной величины.

### Интуитивное понимание

Представьте себе нормальное распределение, которое выглядит как колокол. Если дисперсия велика, колокол будет широкий и плоский, что означает, что значения случайной величины сильно разбросаны. Если дисперсия мала, колокол будет узким и высоким, что указывает на то, что значения сосредоточены вокруг математического ожидания.

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет математическое ожидание и дисперсию для заданного набора данных:

```python
import numpy as np

# Функция для вычисления математического ожидания и дисперсии
def calculate_expectation_and_variance(data):
    """
    Description:
        Вычисляет математическое ожидание и дисперсию для заданного набора данных.

    Args:
        data: Список чисел, представляющих выборку.

    Returns:
        tuple: Математическое ожидание и дисперсия.
    """
    # Преобразуем данные в массив NumPy для удобства
    data_array = np.array(data)
    
    # Вычисляем математическое ожидание
    expectation = np.mean(data_array)
    
    # Вычисляем дисперсию
    variance = np.var(data_array)
    
    return expectation, variance

# Пример использования функции
data = [1, 2, 3, 4, 5]
expectation, variance = calculate_expectation_and_variance(data)
print(f"Математическое ожидание: {expectation}, Дисперсия: {variance}")
```

В этом коде:
- Мы используем библиотеку NumPy для удобного вычисления математического ожидания и дисперсии.
- Функция `calculate_expectation_and_variance` принимает список чисел и возвращает математическое ожидание и дисперсию.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике дисперсия может быть использована для описания неопределенности в измерениях. Например, если мы измеряем длину объекта несколько раз, дисперсия значений измерений покажет, насколько сильно они разбросаны. Если дисперсия мала, это означает, что наши измерения точны и близки к истинному значению.

## Chunk 2

### **Название фрагмента: Центральная предельная теорема и её применение**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили математическое ожидание и дисперсию, а также их интуитивное понимание через нормальное распределение. Теперь мы перейдем к центральной предельной теореме, которая является основополагающей в теории вероятностей и статистики.

## **Центральная предельная теорема (ЦПТ)**

Центральная предельная теорема (ЦПТ) утверждает, что при достаточно большом количестве независимых и одинаково распределенных случайных величин, их сумма (или среднее) будет стремиться к нормальному распределению, независимо от формы исходного распределения. Это свойство делает ЦПТ важным инструментом в статистике и вероятностной теории.

### Формулировка ЦПТ

Если $X_1, X_2, \ldots, X_n$ — независимые случайные величины с одинаковым распределением, имеющими конечное математическое ожидание $E(X)$ и конечную дисперсию $D(X)$, то при увеличении $n$ распределение среднего:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
$$

будет стремиться к нормальному распределению с математическим ожиданием $E(X)$ и дисперсией $\frac{D(X)}{n}$.

### Математическая формализация

ЦПТ можно записать в следующем виде:

$$
Z_n = \frac{\bar{X} - E(X)}{\sigma / \sqrt{n}} \xrightarrow{d} N(0, 1)
$$

где:
- $Z_n$ — стандартизированное значение среднего;
- $\sigma$ — стандартное отклонение случайной величины $X$;
- $N(0, 1)$ — стандартное нормальное распределение.

### Пример кода

Рассмотрим пример кода на Python, который демонстрирует применение ЦПТ на случайных величинах:

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Функция для генерации выборки и построения гистограммы
def central_limit_theorem(sample_size, num_samples):
    """
    Description:
        Генерирует выборки случайных величин и показывает, как распределение их среднего стремится к нормальному.

    Args:
        sample_size: Размер каждой выборки.
        num_samples: Количество выборок.

    Returns:
        None
    """
    # Генерируем случайные величины из равномерного распределения
    samples = [np.random.uniform(0, 1, sample_size) for _ in range(num_samples)]
    
    # Вычисляем средние значения выборок
    means = [np.mean(sample) for sample in samples]
    
    # Строим гистограмму средних значений
    sns.histplot(means, kde=True)
    plt.title('Распределение средних значений выборок')
    plt.xlabel('Средние значения')
    plt.ylabel('Частота')
    plt.show()

# Пример использования функции
central_limit_theorem(sample_size=30, num_samples=1000)
```

В этом коде:
- Мы генерируем выборки случайных величин из равномерного распределения.
- Для каждой выборки вычисляем среднее значение.
- Строим гистограмму средних значений, чтобы визуализировать, как они стремятся к нормальному распределению.

### Физический и геометрический смысл

Центральная предельная теорема имеет важное значение в физике, особенно в экспериментах, где мы измеряем одно и то же явление многократно. Например, если мы измеряем длину стержня, то каждое измерение будет случайной величиной с некоторой дисперсией. При увеличении числа измерений среднее значение будет стремиться к истинной длине стержня, и распределение этих средних значений будет приближаться к нормальному, что позволяет нам делать статистические выводы о длине стержня.

## Chunk 3

### **Название фрагмента: Вычисление математического ожидания и дисперсии для нормального распределения**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили центральную предельную теорему и её значение в статистике. Теперь мы перейдем к вычислению математического ожидания и дисперсии для нормального распределения, используя функцию плотности.

## **Вычисление математического ожидания и дисперсии**

В этом разделе мы рассмотрим, как вычислить математическое ожидание и дисперсию для случайной величины, распределенной нормально. Мы будем использовать функцию плотности нормального распределения и интегралы для нахождения этих значений.

### Математическое ожидание

Для нормального распределения с математическим ожиданием $0$ и дисперсией $\sigma^2$, функция плотности вероятности $f(x)$ имеет вид:

$$
f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}}
$$

Чтобы найти математическое ожидание от модуля случайной величины $E(|X|)$, мы можем использовать интеграл:

$$
E(|X|) = 2 \int_{0}^{+\infty} x f(x) \, dx
$$

Подставляя функцию плотности, получаем:

$$
E(|X|) = 2 \int_{0}^{+\infty} x \cdot \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}} \, dx
$$

### Замена переменных

Для упрощения интеграла мы можем сделать замену переменных. Пусть $u = \frac{x}{\sigma}$, тогда $du = \frac{1}{\sigma} dx$, и интеграл преобразуется:

$$
E(|X|) = 2 \cdot \sigma \cdot \frac{1}{\sqrt{2\pi}} \int_{0}^{+\infty} u e^{-\frac{u^2}{2}} \, du
$$

### Интеграл от $u e^{-\frac{u^2}{2}}$

Этот интеграл можно решить, используя известное свойство производной экспоненты. Мы знаем, что:

$$
\frac{d}{du} \left( -e^{-\frac{u^2}{2}} \right) = u e^{-\frac{u^2}{2}}
$$

Таким образом, интеграл можно выразить через пределы:

$$
\int_{0}^{+\infty} u e^{-\frac{u^2}{2}} \, du = \left[ -e^{-\frac{u^2}{2}} \right]_{0}^{+\infty} = 0 - (-1) = 1
$$

### Итоговое значение математического ожидания

Подставляя это значение обратно, получаем:

$$
E(|X|) = \sigma \cdot \sqrt{\frac{2}{\pi}}
$$

### Дисперсия

Теперь перейдем к вычислению дисперсии. Дисперсия случайной величины $X$ определяется как:

$$
D(X) = E(X^2) - (E(X))^2
$$

Для нормального распределения с математическим ожиданием $0$, дисперсия равна:

$$
D(X) = E(X^2)
$$

Для нормального распределения $E(X^2)$ можно найти следующим образом:

$$
E(X^2) = \int_{-\infty}^{+\infty} x^2 f(x) \, dx
$$

Подставляя функцию плотности, получаем:

$$
E(X^2) = \int_{-\infty}^{+\infty} x^2 \cdot \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}} \, dx
$$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет математическое ожидание и дисперсию для нормального распределения:

```python
import numpy as np
import scipy.stats as stats

# Функция для вычисления математического ожидания и дисперсии
def normal_distribution_params(mu, sigma):
    """
    Description:
        Вычисляет математическое ожидание и дисперсию для нормального распределения.

    Args:
        mu: Математическое ожидание.
        sigma: Стандартное отклонение.

    Returns:
        tuple: Математическое ожидание и дисперсия.
    """
    # Математическое ожидание
    expectation = mu
    
    # Дисперсия
    variance = sigma ** 2
    
    return expectation, variance

# Пример использования функции
mu = 0  # Математическое ожидание
sigma = 1  # Стандартное отклонение
expectation, variance = normal_distribution_params(mu, sigma)
print(f"Математическое ожидание: {expectation}, Дисперсия: {variance}")
```

В этом коде:
- Мы определяем функцию `normal_distribution_params`, которая принимает математическое ожидание и стандартное отклонение.
- Функция возвращает математическое ожидание и дисперсию для нормального распределения.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике дисперсия может быть использована для описания неопределенности в измерениях. Например, если мы измеряем температуру в комнате несколько раз, дисперсия значений измерений покажет, насколько сильно они разбросаны. Если дисперсия мала, это означает, что наши измерения точны и близки к истинному значению.

## Chunk 4

### **Название фрагмента: Вычисление математического ожидания и дисперсии модуля случайной величины**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили, как вычислить математическое ожидание и дисперсию для нормального распределения, используя функцию плотности. Теперь мы перейдем к вычислению математического ожидания и дисперсии модуля случайной величины.

## **Математическое ожидание и дисперсия модуля случайной величины**

В этом разделе мы рассмотрим, как вычислить математическое ожидание и дисперсию модуля случайной величины $X$, распределенной нормально. Мы будем использовать интегралы и свойства функции плотности для нахождения этих значений.

### Математическое ожидание модуля случайной величины

Чтобы найти математическое ожидание модуля случайной величины $E(|X|)$, мы можем использовать интеграл:

$$
E(|X|) = \int_{-\infty}^{+\infty} |x| f(x) \, dx
$$

где $f(x)$ — функция плотности нормального распределения:

$$
f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}}
$$

Поскольку функция плотности симметрична относительно нуля, мы можем упростить интеграл:

$$
E(|X|) = 2 \int_{0}^{+\infty} x f(x) \, dx
$$

Подставляя функцию плотности, получаем:

$$
E(|X|) = 2 \int_{0}^{+\infty} x \cdot \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}} \, dx
$$

### Математическое ожидание квадрата случайной величины

Теперь мы можем найти математическое ожидание квадрата случайной величины $E(X^2)$:

$$
E(X^2) = \int_{-\infty}^{+\infty} x^2 f(x) \, dx
$$

Подставляя функцию плотности, получаем:

$$
E(X^2) = \int_{-\infty}^{+\infty} x^2 \cdot \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}} \, dx
$$

### Дисперсия модуля случайной величины

Дисперсия модуля случайной величины $D(|X|)$ определяется как:

$$
D(|X|) = E(|X|^2) - (E(|X|))^2
$$

Где $E(|X|^2)$ можно найти как:

$$
E(|X|^2) = E(X^2)
$$

Таким образом, дисперсия модуля случайной величины будет равна:

$$
D(|X|) = E(X^2) - (E(|X|))^2
$$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет математическое ожидание и дисперсию модуля случайной величины:

```python
import numpy as np
import scipy.stats as stats

# Функция для вычисления математического ожидания и дисперсии модуля
def expectation_and_variance_of_absolute(mu, sigma):
    """
    Description:
        Вычисляет математическое ожидание и дисперсию модуля случайной величины.

    Args:
        mu: Математическое ожидание.
        sigma: Стандартное отклонение.

    Returns:
        tuple: Математическое ожидание и дисперсия модуля.
    """
    # Математическое ожидание модуля
    expectation_abs = sigma * np.sqrt(2 / np.pi)
    
    # Математическое ожидание квадрата
    expectation_square = sigma ** 2
    
    # Дисперсия модуля
    variance_abs = expectation_square - (expectation_abs ** 2)
    
    return expectation_abs, variance_abs

# Пример использования функции
mu = 0  # Математическое ожидание
sigma = 1  # Стандартное отклонение
expectation_abs, variance_abs = expectation_and_variance_of_absolute(mu, sigma)
print(f"Математическое ожидание модуля: {expectation_abs}, Дисперсия модуля: {variance_abs}")
```

В этом коде:
- Мы определяем функцию `expectation_and_variance_of_absolute`, которая принимает математическое ожидание и стандартное отклонение.
- Функция возвращает математическое ожидание и дисперсию модуля случайной величины.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике математическое ожидание модуля случайной величины может быть использовано для описания средних значений измерений, например, в экспериментах с колебаниями. Если мы измеряем амплитуду колебаний, математическое ожидание модуля даст нам представление о средней величине колебаний, а дисперсия покажет, насколько сильно эти колебания варьируются.

## Chunk 5

### **Название фрагмента: Метрики MAPE и S-MAPE в оценке качества предсказаний**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили математическое ожидание и дисперсию модуля случайной величины, а также их применение в статистике. Теперь мы перейдем к метрикам MAPE (Mean Absolute Percentage Error) и S-MAPE (Symmetric Mean Absolute Percentage Error), которые используются для оценки качества предсказаний моделей.

## **Метрики MAPE и S-MAPE**

MAPE и S-MAPE — это относительные метрики, которые помогают оценить точность предсказаний модели, сравнивая предсказанные значения с истинными значениями. Эти метрики особенно полезны в задачах регрессии, где важно понимать, насколько хорошо модель предсказывает результаты.

### Определение MAPE

MAPE определяется как среднее абсолютное процентное отклонение предсказанных значений от истинных значений:

$$
\text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%
$$

где:
- $y_i$ — истинное значение,
- $\hat{y}_i$ — предсказанное значение,
- $n$ — количество наблюдений.

### Определение S-MAPE

S-MAPE, в свою очередь, является симметричной версией MAPE и учитывает как истинные, так и предсказанные значения в знаменателе:

$$
\text{S-MAPE} = \frac{1}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{|y_i| + |\hat{y}_i|} \times 100\%
$$

### Применение метрик

1. **Ситуация 1:** Если все истинные значения $y_i$ значительно больше нуля (например, порядка $10^5$), то MAPE и S-MAPE будут вести себя аналогично. Если модель предсказывает значения правильно, то разность между истинными и предсказанными значениями будет мала, и обе метрики будут близки к нулю, что указывает на хорошую работу модели.

2. **Ситуация 2:** Если некоторые истинные значения равны нулю или близки к нулю, то MAPE становится неопределенной, так как деление на ноль невозможно. В этом случае S-MAPE может дать более стабильные результаты, так как учитывает как истинные, так и предсказанные значения в знаменателе.

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет MAPE и S-MAPE для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_mape(y_true, y_pred):
    """
    Description:
        Вычисляет MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MAPE: Среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def calculate_smap(y_true, y_pred):
    """
    Description:
        Вычисляет S-MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        S-MAPE: Симметричное среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100

# Пример использования функций
y_true = [100, 200, 300]
y_pred = [110, 190, 290]

mape = calculate_mape(y_true, y_pred)
smap = calculate_smap(y_true, y_pred)

print(f"MAPE: {mape:.2f}%, S-MAPE: {smap:.2f}%")
```

В этом коде:
- Мы определяем функции `calculate_mape` и `calculate_smap`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике метрики MAPE и S-MAPE могут быть использованы для оценки точности измерений. Например, если мы измеряем скорость объекта в разных точках времени, MAPE поможет нам понять, насколько близки наши предсказания к истинным значениям скорости. Если значения близки к нулю, это указывает на высокую точность модели, в то время как большие значения указывают на значительные ошибки в предсказаниях.

## Chunk 6

### **Название фрагмента: Проблемы с MAPE и преимущества S-MAPE**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики MAPE и S-MAPE, их определения и применение в оценке качества предсказаний. Теперь мы сосредоточимся на проблемах, связанных с использованием MAPE, особенно когда истинные значения близки к нулю, и преимуществах S-MAPE в таких ситуациях.

## **Проблемы с MAPE и преимущества S-MAPE**

MAPE (Mean Absolute Percentage Error) может давать некорректные результаты, когда истинные значения $y_t$ близки к нулю. В таких случаях ошибка может "взрываться", что приводит к очень высоким значениям метрики.

### Проблема с MAPE

Когда истинное значение $y_t$ близко к нулю, например, $0.1$, а предсказанное значение $\hat{y}$ значительно больше, например, $90$, то MAPE будет вычисляться следующим образом:

$$
\text{MAPE} = \left| \frac{y_t - \hat{y}}{y_t} \right| \times 100\%
$$

Подставляя значения, получаем:

$$
\text{MAPE} = \left| \frac{0.1 - 90}{0.1} \right| \times 100\% = \left| \frac{-89.9}{0.1} \right| \times 100\% = 89900\%
$$

Таким образом, MAPE "улетает в космос", что делает её неадекватной метрикой в таких ситуациях. Это происходит потому, что деление на очень малое значение в знаменателе приводит к огромным значениям ошибки.

### Преимущества S-MAPE

S-MAPE (Symmetric Mean Absolute Percentage Error) решает эту проблему, так как учитывает как истинные, так и предсказанные значения в знаменателе:

$$
\text{S-MAPE} = \frac{1}{n} \sum_{i=1}^{n} \frac{|y_t - \hat{y}|}{|y_t| + |\hat{y}|} \times 100\%
$$

Таким образом, S-MAPE не будет "взрываться", даже если истинные значения близки к нулю, так как в знаменателе будет сумма абсолютных значений истинного и предсказанного значений, что делает её более устойчивой к таким ситуациям.

### Пример кода

Давайте рассмотрим пример кода на Python, который демонстрирует, как MAPE и S-MAPE ведут себя при различных истинных и предсказанных значениях:

```python
import numpy as np

def calculate_mape(y_true, y_pred):
    """
    Description:
        Вычисляет MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Description:
        MAPE: Среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def calculate_smap(y_true, y_pred):
    """
    Описание:
        Вычисляет S-MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        S-MAPE: Симметричное среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100

# Пример использования функций
y_true = [0.1, 0.1, 0.1]
y_pred = [90, 90, 90]

mape = calculate_mape(y_true, y_pred)
smap = calculate_smap(y_true, y_pred)

print(f"MAPE: {mape:.2f}%, S-MAPE: {smap:.2f}%")
```

В этом коде:
- Мы определяем функции `calculate_mape` и `calculate_smap`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике, когда мы измеряем какие-либо величины, такие как скорость или давление, важно, чтобы метрики ошибки были устойчивыми к малым значениям. Например, если мы измеряем давление в системе, и истинное значение близко к нулю, использование MAPE может привести к неверным выводам о точности измерений. S-MAPE, учитывая как истинные, так и предсказанные значения, позволяет более адекватно оценивать качество предсказаний в таких ситуациях.

## Chunk 7

### **Название фрагмента: Симметричность S-MAPE и её ограничения**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили проблемы, связанные с использованием MAPE, особенно когда истинные значения близки к нулю, и преимущества S-MAPE в таких ситуациях. Теперь мы сосредоточимся на симметричности S-MAPE и её ограничениях.

## **Симметричность S-MAPE и её ограничения**

S-MAPE (Symmetric Mean Absolute Percentage Error) считается симметричной метрикой, так как она учитывает как истинные, так и предсказанные значения в знаменателе, что позволяет избежать проблем, связанных с делением на ноль, и делает её более устойчивой к малым значениям.

### Почему S-MAPE считается симметричной?

1. **Ограниченность значений:** S-MAPE ограничена диапазоном от $0$ до $200\%$. Это означает, что независимо от того, насколько сильно предсказание отклоняется от истинного значения, метрика не может превышать $200\%$. Это делает её более понятной для интерпретации, так как пользователи могут сразу увидеть, насколько хорошо или плохо работает модель.

2. **Симметрия относительно ошибок:** S-MAPE симметрична, потому что она учитывает как положительные, так и отрицательные отклонения. Это означает, что если предсказание завышено или занижено, метрика будет одинаково реагировать на оба случая. Например, если истинное значение $y_t$ близко к нулю, а предсказанное значение $\hat{y}$ значительно больше, то ошибка будет большой, но если $y_t$ также близко к нулю и $\hat{y}$ тоже, то ошибка будет мала.

### Примеры крайних случаев

1. **Ситуация 1:** Если истинное значение $y_t$ равно нулю, а предсказанное значение $\hat{y}$ значительно больше нуля, то S-MAPE будет вычисляться следующим образом:

$$
\text{S-MAPE} = \frac{|y_t - \hat{y}|}{|y_t| + |\hat{y}|} \times 100\%
$$

В этом случае, если $y_t = 0.1$ и $\hat{y} = 90$, то:

$$
\text{S-MAPE} = \frac{|0.1 - 90|}{|0.1| + |90|} \times 100\% \approx 99.89\%
$$

2. **Ситуация 2:** Если оба значения близки к нулю, например, $y_t = 0.1$ и $\hat{y} = 0.1$, то S-MAPE будет:

$$
\text{S-MAPE} = \frac{|0.1 - 0.1|}{|0.1| + |0.1|} \times 100\% = 0\%
$$

### Пример кода

Давайте рассмотрим пример кода на Python, который демонстрирует, как S-MAPE ведет себя при различных истинных и предсказанных значениях:

```python
import numpy as np

def calculate_smap(y_true, y_pred):
    """
    Description:
        Вычисляет S-MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        S-MAPE: Симметричное среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100

# Пример использования функции
y_true = [0.1, 0.1, 0.1]
y_pred = [90, 90, 90]

smap = calculate_smap(y_true, y_pred)
print(f"S-MAPE: {smap:.2f}%")
```

В этом коде:
- Мы определяем функцию `calculate_smap`, которая принимает массивы истинных и предсказанных значений.
- Функция возвращает значение S-MAPE.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике, когда мы измеряем величины, такие как температура или давление, важно, чтобы метрики ошибки были устойчивыми к малым значениям. Например, если мы измеряем давление в системе, и истинное значение близко к нулю, использование S-MAPE позволяет более адекватно оценивать качество предсказаний, так как она учитывает как истинные, так и предсказанные значения, что делает её более надежной в ситуациях, когда истинные значения могут быть малы.

## Chunk 8

### **Название фрагмента: Сравнение метрик MAE и MSE**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили проблемы с MAPE, особенно когда истинные значения близки к нулю, и преимущества S-MAPE в таких ситуациях. Теперь мы перейдем к сравнению двух других метрик: средней абсолютной ошибки (MAE) и средней квадратичной ошибки (MSE).

## **Средняя абсолютная ошибка (MAE) и средняя квадратичная ошибка (MSE)**

MAE и MSE — это две распространенные метрики, используемые для оценки качества предсказаний моделей. Они помогают понять, насколько близки предсказанные значения к истинным.

### Средняя абсолютная ошибка (MAE)

MAE определяется как среднее значение абсолютных ошибок между истинными и предсказанными значениями:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

где:
- $y_i$ — истинное значение,
- $\hat{y}_i$ — предсказанное значение,
- $n$ — количество наблюдений.

MAE показывает среднюю величину ошибок в тех же единицах, что и сами данные, что делает её легко интерпретируемой.

### Пример вычисления MAE

Для набора данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$

Вычислим MAE:

1. Вычисляем абсолютные ошибки:
   - $|3 - 2.5| = 0.5$
   - $|-0.5 - 0| = 0.5$
   - $|2 - 2| = 0$
   - $|7 - 8| = 1$

2. Суммируем абсолютные ошибки:
   - $0.5 + 0.5 + 0 + 1 = 2$

3. Делим на количество наблюдений:
   - $\text{MAE} = \frac{2}{4} = 0.5$

### Средняя квадратичная ошибка (MSE)

MSE определяется как среднее значение квадратов ошибок:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

MSE более чувствительна к выбросам, так как ошибки возводятся в квадрат, что приводит к увеличению влияния больших ошибок на итоговое значение.

### Пример вычисления MSE

Для тех же данных:

1. Вычисляем квадраты ошибок:
   - $(3 - 2.5)^2 = 0.25$
   - $(-0.5 - 0)^2 = 0.25$
   - $(2 - 2)^2 = 0$
   - $(7 - 8)^2 = 1$

2. Суммируем квадраты ошибок:
   - $0.25 + 0.25 + 0 + 1 = 1.5$

3. Делим на количество наблюдений:
   - $\text{MSE} = \frac{1.5}{4} = 0.375$

### Сравнение MAE и MSE

- **MAE**: Легко интерпретируется, показывает среднюю ошибку в тех же единицах, что и данные. Не чувствительна к выбросам.
- **MSE**: Чувствительна к выбросам, так как ошибки возводятся в квадрат. Это может быть полезно, если важно минимизировать большие ошибки.

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет MAE и MSE для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_mae(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю абсолютную ошибку (MAE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MAE: Средняя абсолютная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred))

def calculate_mse(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю квадратичную ошибку (MSE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MSE: Средняя квадратичная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean((y_true - y_pred) ** 2)

# Пример использования функций
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

mae = calculate_mae(y_true, y_pred)
mse = calculate_mse(y_true, y_pred)

print(f"MAE: {mae:.2f}, MSE: {mse:.2f}")
```

В этом коде:
- Мы определяем функции `calculate_mae` и `calculate_mse`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике MAE и MSE могут быть использованы для оценки точности измерений. Например, если мы измеряем длину объекта, MAE даст нам представление о средней ошибке в измерениях, а MSE покажет, насколько сильно отклоняются измерения от истинного значения, особенно если есть выбросы. Это позволяет исследователям и инженерам лучше понимать, насколько точны их измерения и предсказания.

## Chunk 9

### **Название фрагмента: Понимание R-квадрат и его применение**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили среднюю абсолютную ошибку (MAE) и среднюю квадратичную ошибку (MSE), а также их особенности и применение. Теперь мы перейдем к метрике R-квадрат, которая помогает оценить качество предсказаний модели в более понятных терминах.

## **Метрика R-квадрат**

R-квадрат (или коэффициент детерминации) — это метрика, которая измеряет, насколько хорошо предсказанные значения модели соответствуют истинным значениям. Она позволяет понять, какую долю вариации в данных объясняет модель.

### Формула R-квадрат

R-квадрат определяется следующим образом:

$$
R^2 = 1 - \frac{\text{MSE}_{\text{модели}}}{\text{MSE}_{\text{константной}}}
$$

где:
- $\text{MSE}_{\text{модели}}$ — средняя квадратичная ошибка модели, которую мы хотим оценить,
- $\text{MSE}_{\text{константной}}$ — средняя квадратичная ошибка константной модели, которая всегда предсказывает среднее значение истинных значений.

### Понимание R-квадрат

1. **Значение от 0 до 1:** R-квадрат принимает значения от $0$ до $1$. Если $R^2 = 1$, это означает, что модель идеально предсказывает все значения. Если $R^2 = 0$, это означает, что модель не лучше, чем простая константная модель, которая всегда предсказывает среднее значение.

2. **Интерпретация:** Если $R^2 = 0.5$, это означает, что модель объясняет 50% вариации в данных. Если $R^2 < 0.5$, это указывает на то, что модель работает хуже, чем константная модель.

### Пример вычисления R-квадрат

Для набора данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$

1. **Вычисляем MSE модели:**
   - Мы уже вычислили MSE и получили значение $0.375$.

2. **Вычисляем MSE константной модели:**
   - Сначала находим среднее значение истинных значений:
   $$
   \bar{y} = \frac{3 + (-0.5) + 2 + 7}{4} = 2.625
   $$
   - Затем вычисляем MSE для константной модели:
   $$
   \text{MSE}_{\text{константной}} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \bar{y})^2
   $$
   - Подставляем значения:
   $$
   \text{MSE}_{\text{константной}} = \frac{1}{4} \left( (3 - 2.625)^2 + (-0.5 - 2.625)^2 + (2 - 2.625)^2 + (7 - 2.625)^2 \right)
   $$
   - Вычисляем:
   $$
   = \frac{1}{4} \left( 0.140625 + 9.765625 + 0.390625 + 19.140625 \right) = \frac{29.4375}{4} = 7.359375
   $$

3. **Вычисляем R-квадрат:**
   $$
   R^2 = 1 - \frac{0.375}{7.359375} \approx 1 - 0.051 \approx 0.949
   $$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет R-квадрат для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_r_squared(y_true, y_pred):
    """
    Description:
        Вычисляет R-квадрат для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        R-квадрат: Коэффициент детерминации.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    
    # Вычисляем MSE модели
    mse_model = np.mean((y_true - y_pred) ** 2)
    
    # Вычисляем среднее значение истинных значений
    mean_y_true = np.mean(y_true)
    
    # Вычисляем MSE константной модели
    mse_constant = np.mean((y_true - mean_y_true) ** 2)
    
    # Вычисляем R-квадрат
    r_squared = 1 - (mse_model / mse_constant)
    
    return r_squared

# Пример использования функции
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

r_squared = calculate_r_squared(y_true, y_pred)
print(f"R-квадрат: {r_squared:.3f}")
```

В этом коде:
- Мы определяем функцию `calculate_r_squared`, которая принимает массивы истинных и предсказанных значений.
- Функция возвращает значение R-квадрат.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике R-квадрат может быть использован для оценки качества моделей, которые предсказывают физические явления, такие как скорость, давление или температуру. Например, если мы моделируем температуру в комнате на основе различных факторов, R-квадрат поможет понять, насколько хорошо модель объясняет вариации в температуре. Высокое значение R-квадрат указывает на то, что модель хорошо справляется с предсказаниями, в то время как низкое значение может сигнализировать о необходимости улучшения модели.

## Chunk 10

### **Название фрагмента: Понимание относительных метрик и их применение**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики MAE и MSE, а также их особенности и применение. Теперь мы сосредоточимся на относительных метриках, таких как MAPE и S-MAPE, и их значении для оценки качества предсказаний моделей.

## **Относительные метрики: MAPE и S-MAPE**

Относительные метрики, такие как MAPE (Mean Absolute Percentage Error) и S-MAPE (Symmetric Mean Absolute Percentage Error), позволяют оценить ошибки предсказаний в процентах. Это делает их более понятными для людей, не знакомых с математикой, например, для бизнес-аналитиков.

### Значение MAPE и S-MAPE

1. **MAPE**: Эта метрика показывает среднее абсолютное процентное отклонение предсказанных значений от истинных значений. Она вычисляется по формуле:

$$
\text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right| \times 100\%
$$

где $y_i$ — истинное значение, $\hat{y}_i$ — предсказанное значение, а $n$ — количество наблюдений.

2. **S-MAPE**: Эта метрика учитывает как истинные, так и предсказанные значения в знаменателе, что делает её более устойчивой к малым значениям:

$$
\text{S-MAPE} = \frac{1}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{|y_i| + |\hat{y}_i|} \times 100\%
$$

### Проблемы с R-квадрат

R-квадрат (коэффициент детерминации) также является важной метрикой, но она может принимать отрицательные значения, если модель предсказывает хуже, чем простая константная модель. Это может произойти, если модель не учитывает данные должным образом или если в данных есть ошибки. В идеале R-квадрат должен находиться в диапазоне от $0$ до $1$, где $1$ указывает на идеальное предсказание.

### Пример вычисления MAPE и S-MAPE

Для набора данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$

1. **Вычисляем MAPE:**
   - Абсолютные ошибки:
     - $|3 - 2.5| = 0.5$
     - $|-0.5 - 0| = 0.5$
     - $|2 - 2| = 0$
     - $|7 - 8| = 1$
   - Суммируем: $0.5 + 0.5 + 0 + 1 = 2$
   - MAPE: $\frac{2}{4} \times 100\% = 50\%$

2. **Вычисляем S-MAPE:**
   - S-MAPE: $\frac{1}{4} \left( \frac{|3 - 2.5|}{|3| + |2.5|} + \frac{|-0.5 - 0|}{|-0.5| + |0|} + \frac{|2 - 2|}{|2| + |2|} + \frac{|7 - 8|}{|7| + |8|} \right) \times 100\%$
   - Подсчитываем: $\frac{1}{4} \left( \frac{0.5}{5.5} + \frac{0.5}{0.5} + 0 + \frac{1}{15} \right) \times 100\%$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет MAPE и S-MAPE для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_mape(y_true, y_pred):
    """
    Description:
        Вычисляет MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MAPE: Среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def calculate_smap(y_true, y_pred):
    """
    Description:
        Вычисляет S-MAPE для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        S-MAPE: Симметричное среднее абсолютное процентное отклонение.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100

# Пример использования функций
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

mape = calculate_mape(y_true, y_pred)
smap = calculate_smap(y_true, y_pred)

print(f"MAPE: {mape:.2f}%, S-MAPE: {smap:.2f}%")
```

В этом коде:
- Мы определяем функции `calculate_mape` и `calculate_smap`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике относительные метрики, такие как MAPE и S-MAPE, могут быть использованы для оценки точности измерений. Например, если мы измеряем скорость объекта, MAPE поможет нам понять, насколько близки наши предсказания к истинным значениям скорости. Высокие значения MAPE могут указывать на необходимость улучшения модели, в то время как низкие значения указывают на высокую точность предсказаний.

## Chunk 11

### **Название фрагмента: Гибридные метрики: Huber и Log-Cosh**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили относительные метрики, такие как MAPE и S-MAPE, и их значение для оценки качества предсказаний моделей. Теперь мы сосредоточимся на гибридных метриках, таких как Huber и Log-Cosh, которые объединяют преимущества других метрик.

## **Метрика Huber и Log-Cosh**

Метрика Huber и Log-Cosh являются гибридными метриками, которые стремятся объединить преимущества средней абсолютной ошибки (MAE) и средней квадратичной ошибки (MSE). Они позволяют более эффективно справляться с выбросами и обеспечивают более стабильные результаты.

### Метрика Huber

Метрика Huber определяется следующим образом:

$$
L_{\delta}(y, \hat{y}) = 
\begin{cases} 
\frac{1}{2}(y - \hat{y})^2 & \text{если } |y - \hat{y}| \leq \delta \\
\delta \cdot (|y - \hat{y}| - \frac{1}{2}\delta) & \text{иначе}
\end{cases}
$$

где:
- $y$ — истинное значение,
- $\hat{y}$ — предсказанное значение,
- $\delta$ — порог, который определяет, когда использовать MSE или MAE.

1. **Когда использовать MSE:** Если ошибка (разность между истинным и предсказанным значениями) меньше порога $\delta$, используется MSE, что позволяет более точно оценивать небольшие ошибки.
2. **Когда использовать MAE:** Если ошибка больше порога $\delta$, используется MAE, что делает метрику менее чувствительной к выбросам.

### Пример вычисления Huber

Для набора данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$
- Порог $\delta = 1$

1. Вычисляем ошибки:
   - $|3 - 2.5| = 0.5$ (используем MSE)
   - $|-0.5 - 0| = 0.5$ (используем MSE)
   - $|2 - 2| = 0$ (используем MSE)
   - $|7 - 8| = 1$ (используем MAE)

2. Подсчитываем Huber:
   - $L_{\delta}(3, 2.5) = \frac{1}{2}(0.5)^2 = 0.125$
   - $L_{\delta}(-0.5, 0) = \frac{1}{2}(0.5)^2 = 0.125$
   - $L_{\delta}(2, 2) = \frac{1}{2}(0)^2 = 0$
   - $L_{\delta}(7, 8) = 1 \cdot (1 - \frac{1}{2}) = 0.5$

3. Итоговая метрика Huber:
   - $L_H = \frac{0.125 + 0.125 + 0 + 0.5}{4} = 0.1875$

### Метрика Log-Cosh

Log-Cosh — это еще одна гибридная метрика, которая определяется как:

$$
L(y, \hat{y}) = \log(\cosh(y - \hat{y}))
$$

где $\cosh(x)$ — гиперболический косинус, который вычисляется как:

$$
\cosh(x) = \frac{e^x + e^{-x}}{2}
$$

Log-Cosh ведет себя как MSE для небольших ошибок и как MAE для больших ошибок, что делает её устойчивой к выбросам.

### Пример вычисления Log-Cosh

Для тех же данных:

1. Вычисляем Log-Cosh для каждой ошибки:
   - $L(3, 2.5) = \log(\cosh(0.5))$
   - $L(-0.5, 0) = \log(\cosh(0.5))$
   - $L(2, 2) = \log(\cosh(0)) = 0$
   - $L(7, 8) = \log(\cosh(-1))$

2. Подсчитываем итоговое значение Log-Cosh.

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет Huber и Log-Cosh для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_huber(y_true, y_pred, delta):
    """
    Description:
        Вычисляет метрику Huber для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.
        delta: Порог для определения использования MSE или MAE.

    Returns:
        Huber: Значение метрики Huber.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    error = np.abs(y_true - y_pred)
    return np.mean(np.where(error <= delta, 0.5 * error**2, delta * (error - 0.5 * delta)))

def calculate_log_cosh(y_true, y_pred):
    """
    Description:
        Вычисляет метрику Log-Cosh для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        Log-Cosh: Значение метрики Log-Cosh.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.log(np.cosh(y_true - y_pred)))

# Пример использования функций
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]
delta = 1

huber = calculate_huber(y_true, y_pred, delta)
log_cosh = calculate_log_cosh(y_true, y_pred)

print(f"Huber: {huber:.3f}, Log-Cosh: {log_cosh:.3f}")
```

В этом коде:
- Мы определяем функции `calculate_huber` и `calculate_log_cosh`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике метрики Huber и Log-Cosh могут быть использованы для оценки точности измерений, особенно в ситуациях, когда данные содержат выбросы. Например, если мы измеряем скорость объекта, Huber и Log-Cosh помогут более точно оценить качество предсказаний, так как они учитывают как небольшие, так и большие ошибки, что делает их более надежными в реальных условиях.

## Chunk 12

### **Название фрагмента: Квантильная функция потери и её применение**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики Huber и Log-Cosh, которые помогают справляться с выбросами и обеспечивают более стабильные результаты. Теперь мы сосредоточимся на квантильной функции потери, которая позволяет учитывать разные уровни ошибок в зависимости от задачи.

## **Квантильная функция потери**

Квантильная функция потери — это метрика, которая позволяет настраивать модель в зависимости от того, насколько критично недопрогнозировать или перепрогнозировать значения. Она используется для оценки качества предсказаний, учитывая, что в некоторых ситуациях недопрогноз может быть более критичным, чем перепрогноз.

### Формула квантильной функции потери

Квантильная функция потери может быть записана следующим образом:

$$
L(y, \hat{y}) = 
\begin{cases} 
\theta (y - \hat{y}) & \text{если } y - \hat{y} < 0 \\
(1 - \theta)(y - \hat{y}) & \text{иначе}
\end{cases}
$$

где:
- $y$ — истинное значение,
- $\hat{y}$ — предсказанное значение,
- $\theta$ — гиперпараметр, который определяет, насколько сильно мы хотим наказывать за недопрогноз или перепрогноз.

### Понимание квантильной функции потери

1. **Недопрогноз:** Если предсказанное значение меньше истинного, то используется первый случай формулы, где мы умножаем разность на $\theta$. Это позволяет более строго наказывать модель за недопрогноз.

2. **Перепрогноз:** Если предсказанное значение больше истинного, то используется второй случай, где разность умножается на $(1 - \theta)$. Это позволяет менее строго наказывать модель за перепрогноз.

### Пример применения

Предположим, у нас есть задача предсказать поставки продуктов на склад. Если мы предскажем 90 коробок, когда нужно 100, это приведет к недопродаже, что может быть критично для бизнеса. Если же мы предскажем 110 коробок, это приведет к избыточным запасам, что менее критично.

Если мы установим $\theta = 0.6$, это означает, что мы будем наказывать модель сильнее за недопрогноз, чем за перепрогноз. Таким образом, если модель предсказывает 90, то потеря будет:

$$
L(100, 90) = 0.6 \cdot (100 - 90) = 6
$$

А если модель предсказывает 110:

$$
L(100, 110) = 0.4 \cdot (100 - 110) = -4
$$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет квантильную функцию потери для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_quantile_loss(y_true, y_pred, theta):
    """
    Description:
        Вычисляет квантильную функцию потери для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.
        theta: Гиперпараметр для настройки потерь.

    Returns:
        Quantile Loss: Значение квантильной функции потери.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    loss = np.where(y_true - y_pred < 0, 
                    theta * (y_true - y_pred), 
                    (1 - theta) * (y_true - y_pred))
    return np.mean(loss)

# Пример использования функции
y_true = [100, 100, 100]
y_pred = [90, 110, 95]
theta = 0.6

quantile_loss = calculate_quantile_loss(y_true, y_pred, theta)
print(f"Квантильная функция потери: {quantile_loss:.2f}")
```

В этом коде:
- Мы определяем функцию `calculate_quantile_loss`, которая принимает массивы истинных и предсказанных значений, а также гиперпараметр $\theta$.
- Функция возвращает значение квантильной функции потери.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике квантильная функция потери может быть использована для оценки предсказаний в задачах, где последствия недопрогноза и перепрогноза различны. Например, в задачах управления запасами, где недостача товара может привести к потерям, а избыточные запасы могут быть менее критичными. Квантильная функция потери позволяет более точно настраивать модель в зависимости от бизнес-целей и рисков.

## Chunk 13

### **Название фрагмента: Сравнение MSE и MAE в контексте выбросов**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики Huber и Log-Cosh, которые помогают справляться с выбросами и обеспечивают более стабильные результаты. Теперь мы сосредоточимся на сравнении средней квадратичной ошибки (MSE) и средней абсолютной ошибки (MAE) в контексте наличия выбросов.

## **Сравнение MSE и MAE**

MSE и MAE — это две основные метрики, используемые для оценки качества предсказаний моделей. Они имеют разные свойства и поведение, особенно в присутствии выбросов.

### Средняя квадратичная ошибка (MSE)

MSE определяется как среднее значение квадратов ошибок:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

где:
- $y_i$ — истинное значение,
- $\hat{y}_i$ — предсказанное значение,
- $n$ — количество наблюдений.

MSE более чувствительна к выбросам, так как ошибки возводятся в квадрат. Это означает, что большие ошибки оказывают значительно большее влияние на итоговое значение MSE.

### Средняя абсолютная ошибка (MAE)

MAE определяется как среднее значение абсолютных ошибок:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

MAE менее чувствительна к выбросам, так как она просто суммирует абсолютные ошибки, не возводя их в квадрат.

### Пример сравнения MSE и MAE

Предположим, у нас есть набор данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$

1. **Вычисляем MSE:**
   - Ошибки: 
     - $(3 - 2.5)^2 = 0.25$
     - $(-0.5 - 0)^2 = 0.25$
     - $(2 - 2)^2 = 0$
     - $(7 - 8)^2 = 1$
   - Суммируем: $0.25 + 0.25 + 0 + 1 = 1.5$
   - MSE: $\frac{1.5}{4} = 0.375$

2. **Вычисляем MAE:**
   - Абсолютные ошибки:
     - $|3 - 2.5| = 0.5$
     - $|-0.5 - 0| = 0.5$
     - $|2 - 2| = 0$
     - $|7 - 8| = 1$
   - Суммируем: $0.5 + 0.5 + 0 + 1 = 2$
   - MAE: $\frac{2}{4} = 0.5$

### Математическое ожидание и дисперсия

Для дальнейшего анализа, давайте рассмотрим математическое ожидание и дисперсию ошибок. 

1. **Дисперсия** определяется как:

$$
D(X) = E(X^2) - (E(X))^2
$$

где $E(X)$ — математическое ожидание.

2. **Математическое ожидание** для MSE можно записать как:

$$
E(\text{MSE}) = E((y - \hat{y})^2)
$$

3. **Математическое ожидание** для MAE можно записать как:

$$
E(\text{MAE}) = E(|y - \hat{y}|)
$$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет MSE и MAE для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_mae(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю абсолютную ошибку (MAE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MAE: Средняя абсолютная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred))

def calculate_mse(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю квадратичную ошибку (MSE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MSE: Средняя квадратичная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean((y_true - y_pred) ** 2)

# Пример использования функций
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

mae = calculate_mae(y_true, y_pred)
mse = calculate_mse(y_true, y_pred)

print(f"MAE: {mae:.2f}, MSE: {mse:.2f}")
```

В этом коде:
- Мы определяем функции `calculate_mae` и `calculate_mse`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике MAE и MSE могут быть использованы для оценки точности измерений. Например, если мы измеряем длину объекта, MAE даст нам представление о средней ошибке в измерениях, а MSE покажет, насколько сильно отклоняются измерения от истинного значения, особенно если есть выбросы. Это позволяет исследователям и инженерам лучше понимать, насколько точны их измерения и предсказания.

## Chunk 14

### **Название фрагмента: Влияние выбросов на MSE и MAE**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики Huber и Log-Cosh, а также их применение для оценки качества предсказаний в условиях наличия выбросов. Теперь мы сосредоточимся на сравнении MSE и MAE в контексте наличия выбросов и их влияния на математическое ожидание.

## **Влияние выбросов на MSE и MAE**

Выбросы в данных могут значительно повлиять на метрики оценки качества предсказаний, такие как средняя квадратичная ошибка (MSE) и средняя абсолютная ошибка (MAE). Понимание этого влияния важно для правильной интерпретации результатов.

### Математическое ожидание MSE и MAE

1. **MSE**: Если в данных присутствуют выбросы, то MSE будет увеличиваться, так как она чувствительна к большим ошибкам. Математическое ожидание MSE можно записать как:

$$
E(\text{MSE}) = P_{\text{базовая}} \cdot E(\text{базовая ошибка}) + P_{\text{выброс}} \cdot E(\text{выброс})
$$

где:
- $P_{\text{базовая}}$ — вероятность того, что ошибка является базовой (например, $0.95$),
- $E(\text{базовая ошибка})$ — математическое ожидание базовой ошибки,
- $P_{\text{выброс}}$ — вероятность того, что ошибка является выбросом (например, $0.05$),
- $E(\text{выброс})$ — математическое ожидание ошибки для выбросов.

2. **MAE**: Аналогично, математическое ожидание MAE можно записать как:

$$
E(\text{MAE}) = P_{\text{базовая}} \cdot E(|\text{базовая ошибка}|) + P_{\text{выброс}} \cdot E(|\text{выброс}|) 
$$

### Пример вычисления

Предположим, что у нас есть 5% выбросов в данных. Если базовая ошибка имеет дисперсию $1$, а выбросы имеют дисперсию $25$, то:

1. **Для MSE:**
   - $E(\text{MSE}) = 0.95 \cdot 1 + 0.05 \cdot 25 = 0.95 + 1.25 = 2.20$

2. **Для MAE:**
   - Если базовая ошибка равна $1$, а выбросы имеют модуль ошибки $5$, то:
   - $E(\text{MAE}) = 0.95 \cdot 1 + 0.05 \cdot 5 = 0.95 + 0.25 = 1.20$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет MSE и MAE с учетом выбросов:

```python
import numpy as np

def calculate_mse_with_outliers(y_true, y_pred, p_outliers, mse_base, mse_outlier):
    """
    Description:
        Вычисляет MSE с учетом выбросов.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.
        p_outliers: Вероятность выбросов.
        mse_base: Математическое ожидание базовой ошибки.
        mse_outlier: Математическое ожидание ошибки для выбросов.

    Returns:
        MSE: Средняя квадратичная ошибка с учетом выбросов.
    """
    p_base = 1 - p_outliers
    return p_base * mse_base + p_outliers * mse_outlier

# Пример использования функции
p_outliers = 0.05  # 5% выбросов
mse_base = 1       # Математическое ожидание базовой ошибки
mse_outlier = 25   # Математическое ожидание ошибки для выбросов

mse_with_outliers = calculate_mse_with_outliers([], [], p_outliers, mse_base, mse_outlier)
print(f"MSE с учетом выбросов: {mse_with_outliers:.2f}")
```

В этом коде:
- Мы определяем функцию `calculate_mse_with_outliers`, которая принимает вероятность выбросов и математические ожидания ошибок.
- Функция возвращает значение MSE с учетом выбросов.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике выбросы могут возникать в результате ошибок измерений или аномальных условий. Например, если мы измеряем температуру в разных точках, выбросы могут указывать на неправильные показания термометра. Понимание влияния выбросов на MSE и MAE позволяет исследователям и инженерам более точно оценивать качество своих моделей и принимать обоснованные решения о том, как обрабатывать данные.

## Chunk 15

### **Название фрагмента: Влияние выбросов на MSE и MAE, и применение Huber**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики MSE и MAE, а также их поведение в условиях наличия выбросов. Теперь мы сосредоточимся на том, как выбросы влияют на эти метрики и как метрика Huber может быть использована для их оценки.

## **Влияние выбросов на MSE и MAE, и применение Huber**

Выбросы в данных могут значительно повлиять на метрики оценки качества предсказаний, такие как MSE и MAE. Понимание этого влияния важно для правильной интерпретации результатов и выбора подходящей метрики.

### Математическое ожидание MSE и MAE

1. **MSE**: Если в данных присутствуют выбросы, то MSE будет увеличиваться, так как она чувствительна к большим ошибкам. Математическое ожидание MSE можно записать как:

$$
E(\text{MSE}) = P_{\text{базовая}} \cdot E(\text{базовая ошибка}) + P_{\text{выброс}} \cdot E(\text{выброс})
$$

где:
- $P_{\text{базовая}}$ — вероятность того, что ошибка является базовой (например, $0.95$),
- $E(\text{базовая ошибка})$ — математическое ожидание базовой ошибки,
- $P_{\text{выброс}}$ — вероятность того, что ошибка является выбросом (например, $0.05$),
- $E(\text{выброс})$ — математическое ожидание ошибки для выбросов.

2. **MAE**: Аналогично, математическое ожидание MAE можно записать как:

$$
E(\text{MAE}) = P_{\text{базовая}} \cdot E(|\text{базовая ошибка}|) + P_{\text{выброс}} \cdot E(|\text{выброс}|) 
$$

### Пример вычисления

Предположим, что у нас есть 5% выбросов в данных. Если базовая ошибка имеет дисперсию $1$, а выбросы имеют дисперсию $25$, то:

1. **Для MSE:**
   - $E(\text{MSE}) = 0.95 \cdot 1 + 0.05 \cdot 25 = 0.95 + 1.25 = 2.20$

2. **Для MAE:**
   - Если базовая ошибка равна $1$, а выбросы имеют модуль ошибки $5$, то:
   - $E(\text{MAE}) = 0.95 \cdot 1 + 0.05 \cdot 5 = 0.95 + 0.25 = 1.20$

### Применение Huber

Метрика Huber может быть использована для более устойчивой оценки ошибок в условиях наличия выбросов. Она сочетает в себе преимущества MSE и MAE, позволяя использовать MSE для небольших ошибок и MAE для больших ошибок.

1. **Формула Huber:**

$$
L_{\delta}(y, \hat{y}) = 
\begin{cases} 
\frac{1}{2}(y - \hat{y})^2 & \text{если } |y - \hat{y}| \leq \delta \\
\delta \cdot (|y - \hat{y}| - \frac{1}{2}\delta) & \text{иначе}
\end{cases}
$$

где $\delta$ — порог, который определяет, когда использовать MSE или MAE.

### Пример кода для Huber

Давайте рассмотрим пример кода на Python, который вычисляет Huber для заданных истинных и предсказанных значений:

```python
import numpy as np

def calculate_huber(y_true, y_pred, delta):
    """
    Description:
        Вычисляет метрику Huber для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.
        delta: Порог для определения использования MSE или MAE.

    Returns:
        Huber: Значение метрики Huber.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    error = np.abs(y_true - y_pred)
    return np.mean(np.where(error <= delta, 0.5 * error**2, delta * (error - 0.5 * delta)))

# Пример использования функции
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]
delta = 1

huber = calculate_huber(y_true, y_pred, delta)
print(f"Huber: {huber:.3f}")
```

В этом коде:
- Мы определяем функцию `calculate_huber`, которая принимает массивы истинных и предсказанных значений, а также порог $\delta$.
- Функция возвращает значение Huber.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике метрики Huber и Log-Cosh могут быть использованы для оценки точности измерений, особенно в ситуациях, когда данные содержат выбросы. Например, если мы измеряем скорость объекта, Huber поможет более точно оценить качество предсказаний, так как она учитывает как небольшие, так и большие ошибки, что делает её более надежной в реальных условиях.

## Chunk 16

### **Название фрагмента: Квантильные интервалы и метод Bootstrap**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили влияние выбросов на метрики MSE и MAE, а также применение метрики Huber для более устойчивой оценки ошибок. Теперь мы сосредоточимся на методе Bootstrap и его применении для оценки доверительных интервалов метрик.

## **Метод Bootstrap и доверительные интервалы**

Метод Bootstrap — это статистический метод, который позволяет оценить распределение статистики (например, среднего, медианы или других метрик) на основе повторных выборок из имеющихся данных. Он особенно полезен для построения доверительных интервалов, которые помогают понять, насколько надежны результаты модели.

### Зачем нужны доверительные интервалы?

Доверительные интервалы показывают диапазон значений, в котором с определенной вероятностью (например, 99%) находится истинное значение метрики. Это важно для оценки качества модели, так как позволяет понять, насколько результаты воспроизводимы.

1. **Воспроизводимость модели:** Если модель возвращает результаты, которые сильно варьируются, это может указывать на то, что модель не стабильна и не подходит для использования в продакшене. Доверительные интервалы помогают выявить такие проблемы.

2. **Проверка результатов:** Другие исследователи или аналитики могут проверить, действительно ли модель дает стабильные результаты, основываясь на доверительных интервалах.

### Применение метода Bootstrap

Метод Bootstrap включает следующие шаги:

1. **Создание Bootstrap выборок:** Из исходного набора данных создаются несколько выборок (обычно $B$), каждая из которых имеет такой же размер, как и исходный набор. При этом объекты могут повторяться, так как выборка производится с возвращением.

2. **Вычисление метрики:** Для каждой Bootstrap выборки вычисляется интересующая метрика (например, MAE или MSE).

3. **Оценка доверительного интервала:** На основе полученных значений метрики из Bootstrap выборок можно построить доверительный интервал. Например, можно взять 2.5-й и 97.5-й процентиль значений метрики, чтобы получить 95% доверительный интервал.

### Пример кода

Давайте рассмотрим пример кода на Python, который реализует метод Bootstrap для оценки доверительного интервала:

```python
import numpy as np

def bootstrap_ci(data, num_samples, metric_func, alpha=0.05):
    """
    Description:
        Вычисляет доверительный интервал для заданной метрики с использованием метода Bootstrap.

    Args:
        data: Массив данных.
        num_samples: Количество Bootstrap выборок.
        metric_func: Функция для вычисления метрики.
        alpha: Уровень значимости для доверительного интервала.

    Returns:
        Доверительный интервал: нижняя и верхняя границы.
    """
    n = len(data)
    metrics = []

    for _ in range(num_samples):
        sample = np.random.choice(data, size=n, replace=True)    # Bootstrap выборка
        metrics.append(metric_func(sample))                      # Вычисляем метрику для выборки

    lower_bound = np.percentile(metrics, 100 * alpha / 2)         # Нижняя граница
    upper_bound = np.percentile(metrics, 100 * (1 - alpha / 2))  # Верхняя граница

    return lower_bound, upper_bound

# Пример использования функции
data = [3, -0.5, 2, 7]  # Исходные данные
num_samples = 1000      # Количество Bootstrap выборок

# Функция для вычисления MAE
def mae(data):
    return np.mean(np.abs(data - np.mean(data)))

ci = bootstrap_ci(data, num_samples, mae)
print(f"95% доверительный интервал для MAE: {ci}")
```

В этом коде:
- Мы определяем функцию `bootstrap_ci`, которая принимает массив данных, количество Bootstrap выборок, функцию для вычисления метрики и уровень значимости.
- Функция возвращает доверительный интервал для заданной метрики.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике метод Bootstrap может быть использован для оценки неопределенности в измерениях. Например, если мы измеряем длину объекта несколько раз, метод Bootstrap позволит нам оценить, насколько стабильны наши измерения и какова вероятность того, что истинная длина объекта находится в определенном диапазоне. Это особенно полезно в экспериментах, где точность измерений критична.

## Chunk 17

### **Название фрагмента: Метод Bootstrap для оценки качества моделей**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метрики Huber и Log-Cosh, а также их применение для оценки качества предсказаний в условиях наличия выбросов. Теперь мы сосредоточимся на методе Bootstrap и его использовании для оценки качества моделей, а также на том, как он помогает в построении доверительных интервалов.

## **Метод Bootstrap и его применение**

Метод Bootstrap — это статистический метод, который позволяет оценить распределение статистики (например, ошибки модели) на основе повторных выборок из имеющихся данных. Он особенно полезен для построения доверительных интервалов, которые помогают понять, насколько надежны результаты модели.

### Как работает метод Bootstrap

1. **Создание Bootstrap выборок:** Из исходного набора данных создаются несколько выборок (обычно $B$), каждая из которых имеет такой же размер, как и исходный набор. При этом объекты могут повторяться, так как выборка производится с возвращением.

2. **Вычисление метрики:** Для каждой Bootstrap выборки вычисляется интересующая метрика (например, MSE или MAE).

3. **Оценка доверительного интервала:** На основе полученных значений метрики из Bootstrap выборок можно построить доверительный интервал. Например, можно взять 5-й и 95-й процентиль значений метрики, чтобы получить 90% доверительный интервал.

### Пример вычисления доверительного интервала

Предположим, у нас есть две модели с MSE:
- Модель A: MSE = 1100
- Модель B: MSE = 1000

Чтобы понять, какая модель лучше, мы можем использовать метод Bootstrap для оценки их качества.

1. **Создаем Bootstrap выборки:** Генерируем $B$ выборок из исходных данных для каждой модели.

2. **Вычисляем MSE для каждой выборки:** Для каждой выборки вычисляем MSE и сохраняем результаты.

3. **Строим доверительный интервал:** Находим 5-й и 95-й процентиль для каждой модели, чтобы получить доверительные интервалы.

### Пример кода

Давайте рассмотрим пример кода на Python, который реализует метод Bootstrap для оценки доверительного интервала MSE:

```python
import numpy as np

def bootstrap_mse(y_true, y_pred, num_samples=1000, alpha=0.05):
    """
    Description:
        Вычисляет доверительный интервал для MSE с использованием метода Bootstrap.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.
        num_samples: Количество Bootstrap выборок.
        alpha: Уровень значимости для доверительного интервала.

    Returns:
        Доверительный интервал: нижняя и верхняя границы.
    """
    n = len(y_true)
    mse_samples = []

    for _ in range(num_samples):
        indices = np.random.choice(range(n), size=n, replace=True)  # Bootstrap выборка
        mse = np.mean((y_true[indices] - y_pred[indices]) ** 2)     # Вычисляем MSE для выборки
        mse_samples.append(mse)

    lower_bound = np.percentile(mse_samples, 100 * alpha / 2)        # Нижняя граница
    upper_bound = np.percentile(mse_samples, 100 * (1 - alpha / 2))  # Верхняя граница

    return lower_bound, upper_bound

# Пример использования функции
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

ci = bootstrap_mse(np.array(y_true), np.array(y_pred))
print(f"95% доверительный интервал для MSE: {ci}")
```

В этом коде:
- Мы определяем функцию `bootstrap_mse`, которая принимает массивы истинных и предсказанных значений, количество Bootstrap выборок и уровень значимости.
- Функция возвращает доверительный интервал для MSE.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике метод Bootstrap может быть использован для оценки неопределенности в измерениях. Например, если мы измеряем длину объекта несколько раз, метод Bootstrap позволит нам оценить, насколько стабильны наши измерения и какова вероятность того, что истинная длина объекта находится в определенном диапазоне. Это особенно полезно в экспериментах, где точность измерений критична.

## Chunk 18

### **Название фрагмента: Доверительные интервалы и центральная предельная теорема**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метод Bootstrap для оценки доверительных интервалов метрик, таких как MSE и MAE. Теперь мы сосредоточимся на том, как строить доверительные интервалы с использованием центральной предельной теоремы и как это связано с метриками качества моделей.

## **Доверительные интервалы и центральная предельная теорема**

Доверительные интервалы позволяют оценить, насколько надежны результаты модели, и помогают понять, в каком диапазоне значений может находиться истинное значение метрики. Центральная предельная теорема (ЦПТ) играет ключевую роль в построении этих интервалов.

### Центральная предельная теорема

ЦПТ утверждает, что при достаточно большом размере выборки распределение выборочного среднего будет стремиться к нормальному распределению, независимо от формы исходного распределения. Это позволяет использовать нормальное распределение для построения доверительных интервалов.

1. **Формулировка ЦПТ:** Если $X_1, X_2, \ldots, X_n$ — независимые случайные величины с одинаковым распределением, имеющими конечное математическое ожидание $E(X)$ и конечную дисперсию $D(X)$, то при увеличении $n$ распределение среднего:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
$$

будет стремиться к нормальному распределению с математическим ожиданием $E(X)$ и дисперсией $\frac{D(X)}{n}$.

### Построение доверительного интервала

Для построения доверительного интервала для MSE можно использовать следующую формулу:

$$
\text{CI} = \hat{mse} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
$$

где:
- $\hat{mse}$ — оценка MSE,
- $z_{\alpha/2}$ — квантиль стандартного нормального распределения,
- $\sigma$ — стандартное отклонение выборки,
- $n$ — размер выборки.

### Пример вычисления доверительного интервала

Предположим, у нас есть две модели с MSE:
- Модель A: $\hat{mse} = 1100$
- Модель B: $\hat{mse} = 1000$

1. **Вычисляем стандартное отклонение:** Предположим, что стандартное отклонение для модели A равно $30$, а для модели B — $25$.

2. **Вычисляем доверительный интервал для модели A:**
   - Уровень значимости $\alpha = 0.05$, тогда $z_{\alpha/2} \approx 1.96$.
   - Доверительный интервал:
   $$
   \text{CI}_A = 1100 \pm 1.96 \cdot \frac{30}{\sqrt{n}}
   $$

3. **Вычисляем доверительный интервал для модели B:**
   - Доверительный интервал:
   $$
   \text{CI}_B = 1000 \pm 1.96 \cdot \frac{25}{\sqrt{n}}
   $$

### Пример кода

Давайте рассмотрим пример кода на Python, который вычисляет доверительный интервал для MSE с использованием ЦПТ:

```python
import numpy as np
import scipy.stats as stats

def calculate_ci_mse(mse, std_dev, n, alpha=0.05):
    """
    Description:
        Вычисляет доверительный интервал для MSE с использованием центральной предельной теоремы.

    Args:
        mse: Оценка MSE.
        std_dev: Стандартное отклонение.
        n: Размер выборки.
        alpha: Уровень значимости для доверительного интервала.

    Returns:
        Доверительный интервал: нижняя и верхняя границы.
    """
    z = stats.norm.ppf(1 - alpha / 2)             # Квантиль стандартного нормального распределения
    margin_of_error = z * (std_dev / np.sqrt(n))  # Погрешность
    return mse - margin_of_error, mse + margin_of_error

# Пример использования функции
mse_a = 1100
std_dev_a = 30
n_a = 100  # Размер выборки

ci_a = calculate_ci_mse(mse_a, std_dev_a, n_a)
print(f"95% доверительный интервал для модели A: {ci_a}")

mse_b = 1000
std_dev_b = 25
n_b = 100  # Размер выборки

ci_b = calculate_ci_mse(mse_b, std_dev_b, n_b)
print(f"95% доверительный интервал для модели B: {ci_b}")
```

В этом коде:
- Мы определяем функцию `calculate_ci_mse`, которая принимает оценку MSE, стандартное отклонение, размер выборки и уровень значимости.
- Функция возвращает доверительный интервал для MSE.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике доверительные интервалы могут быть использованы для оценки неопределенности в измерениях. Например, если мы измеряем длину объекта несколько раз, доверительный интервал позволит нам оценить, насколько стабильны наши измерения и какова вероятность того, что истинная длина объекта находится в определенном диапазоне. Это особенно полезно в экспериментах, где точность измерений критична.

## Chunk 19

### **Название фрагмента: Доверительные интервалы для MAE и MSE с использованием Bootstrap и ЦПТ**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метод Bootstrap для оценки доверительных интервалов метрик, таких как MSE и MAE, а также влияние выбросов на эти метрики. Теперь мы сосредоточимся на том, как строить доверительные интервалы для MAE и MSE, используя центральную предельную теорему (ЦПТ) и метод Bootstrap.

## **Доверительные интервалы для MAE и MSE**

Доверительные интервалы позволяют оценить, насколько надежны результаты модели, и помогают понять, в каком диапазоне значений может находиться истинное значение метрики. Для построения доверительных интервалов для MAE и MSE можно использовать как метод Bootstrap, так и центральную предельную теорему.

### Метод Bootstrap

Метод Bootstrap позволяет генерировать множество выборок из исходных данных и оценивать метрики для каждой выборки. Это позволяет получить распределение метрик и, следовательно, доверительные интервалы.

1. **Создание Bootstrap выборок:** Из исходного набора данных создаются несколько выборок (обычно $B$), каждая из которых имеет такой же размер, как и исходный набор. При этом объекты могут повторяться, так как выборка производится с возвращением.

2. **Вычисление метрики:** Для каждой Bootstrap выборки вычисляется интересующая метрика (например, MAE или MSE).

3. **Оценка доверительного интервала:** На основе полученных значений метрики из Bootstrap выборок можно построить доверительный интервал, например, взяв 5-й и 95-й процентиль значений метрики.

### Центральная предельная теорема (ЦПТ)

ЦПТ утверждает, что при достаточно большом размере выборки распределение выборочного среднего будет стремиться к нормальному распределению, независимо от формы исходного распределения. Это позволяет использовать нормальное распределение для построения доверительных интервалов.

1. **Формулировка ЦПТ:** Если $X_1, X_2, \ldots, X_n$ — независимые случайные величины с одинаковым распределением, имеющими конечное математическое ожидание $E(X)$ и конечную дисперсию $D(X)$, то при увеличении $n$ распределение среднего:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
$$

будет стремиться к нормальному распределению с математическим ожиданием $E(X)$ и дисперсией $\frac{D(X)}{n}$.

### Пример вычисления доверительного интервала для MAE и MSE

Для набора данных:
- Истинные значения: $[3, -0.5, 2, 7]$
- Предсказанные значения: $[2.5, 0, 2, 8]$

1. **Вычисляем MAE и MSE:**
   - MAE: $0.5$
   - MSE: $0.375$

2. **Строим доверительные интервалы:**
   - Для MAE и MSE можно использовать как метод Bootstrap, так и ЦПТ для оценки доверительных интервалов.

### Пример кода для оценки доверительных интервалов

```python
import numpy as np
import scipy.stats as stats

def bootstrap_ci(data, num_samples, metric_func, alpha=0.05):
    """
    Description:
        Вычисляет доверительный интервал для заданной метрики с использованием метода Bootstrap.

    Args:
        data: Массив данных.
        num_samples: Количество Bootstrap выборок.
        metric_func: Функция для вычисления метрики.
        alpha: Уровень значимости для доверительного интервала.

    Returns:
        Доверительный интервал: нижняя и верхняя границы.
    """
    n = len(data)
    metrics = []

    for _ in range(num_samples):
        sample = np.random.choice(data, size=n, replace=True)  # Bootstrap выборка
        metrics.append(metric_func(sample))                    # Вычисляем метрику для выборки

    lower_bound = np.percentile(metrics, 100 * alpha / 2)        # Нижняя граница
    upper_bound = np.percentile(metrics, 100 * (1 - alpha / 2))  # Верхняя граница

    return lower_bound, upper_bound

# Пример использования функции
data = [3, -0.5, 2, 7]  # Исходные данные
num_samples = 1000      # Количество Bootstrap выборок

# Функция для вычисления MAE
def mae(data):
    return np.mean(np.abs(data - np.mean(data)))

ci = bootstrap_ci(data, num_samples, mae)
print(f"95% доверительный интервал для MAE: {ci}")
```

В этом коде:
- Мы определяем функцию `bootstrap_ci`, которая принимает массив данных, количество Bootstrap выборок, функцию для вычисления метрики и уровень значимости.
- Функция возвращает доверительный интервал для заданной метрики.
- Мы выводим результат на экран.

### Физический и геометрический смысл

В физике метод Bootstrap может быть использован для оценки неопределенности в измерениях. Например, если мы измеряем длину объекта несколько раз, метод Bootstrap позволит нам оценить, насколько стабильны наши измерения и какова вероятность того, что истинная длина объекта находится в определенном диапазоне. Это особенно полезно в экспериментах, где точность измерений критична.

## Chunk 20

### **Название фрагмента: Понимание распределений и их влияние на метрики**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили метод Bootstrap для оценки доверительных интервалов и его применение в контексте метрик MSE и MAE. Теперь мы сосредоточимся на том, как распределения случайных величин влияют на метрики и как это понимание может помочь в решении практических задач.

## **Влияние распределений на метрики и функции потерь**

Распределение случайных величин играет важную роль в оценке качества предсказаний моделей. Понимание того, как различные функции потерь и метрики ведут себя в зависимости от распределения данных, позволяет более точно интерпретировать результаты и выбирать подходящие методы.

### Распределения случайных величин

1. **Нормальное распределение:** Многие статистические методы, включая MSE и MAE, предполагают, что ошибки распределены нормально. Это означает, что большинство ошибок будут близки к нулю, а крайние значения будут встречаться реже.

2. **Ненормальное распределение:** В реальных данных часто встречаются выбросы и аномалии, которые могут нарушить предположение о нормальности. Например, если ошибки имеют распределение с тяжелыми хвостами, это может привести к неправильным выводам при использовании MSE.

### Математическое ожидание и дисперсия

Для оценки качества предсказаний важно вычислить математическое ожидание и дисперсию ошибок. Например, для MAE и MSE можно записать:

1. **MAE:**
   $$ 
   E(\text{MAE}) = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| 
   $$

2. **MSE:**
   $$ 
   E(\text{MSE}) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 
   $$

### Пример с выбросами

Если в данных присутствуют выбросы, то MSE будет значительно увеличиваться, так как она чувствительна к большим ошибкам. Например, если 5% данных являются выбросами, то математическое ожидание MSE можно записать как:

$$
E(\text{MSE}) = P_{\text{базовая}} \cdot E(\text{базовая ошибка}) + P_{\text{выброс}} \cdot E(\text{выброс})
$$

где $P_{\text{базовая}}$ — вероятность базовой ошибки, а $P_{\text{выброс}}$ — вероятность выброса.

### Пример кода для оценки MSE и MAE с учетом выбросов

```python
import numpy as np

def calculate_mae(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю абсолютную ошибку (MAE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MAE: Средняя абсолютная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs(y_true - y_pred))

def calculate_mse(y_true, y_pred):
    """
    Description:
        Вычисляет среднюю квадратичную ошибку (MSE) для заданных истинных и предсказанных значений.

    Args:
        y_true: Массив истинных значений.
        y_pred: Массив предсказанных значений.

    Returns:
        MSE: Средняя квадратичная ошибка.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean((y_true - y_pred) ** 2)

# Пример использования функций
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]

mae = calculate_mae(y_true, y_pred)
mse = calculate_mse(y_true, y_pred)

print(f"MAE: {mae:.2f}, MSE: {mse:.2f}")
```

В этом коде:
- Мы определяем функции `calculate_mae` и `calculate_mse`, которые принимают массивы истинных и предсказанных значений.
- Каждая функция возвращает соответствующую метрику.
- Мы выводим результаты на экран.

### Физический и геометрический смысл

В физике понимание распределений случайных величин и их влияние на метрики позволяет более точно оценивать качество моделей. Например, если мы измеряем температуру в разных точках, выбросы могут указывать на неправильные показания термометра. Понимание того, как распределения влияют на MAE и MSE, позволяет исследователям и инженерам более точно оценивать качество своих моделей и принимать обоснованные решения о том, как обрабатывать данные.

## Final Summary

### **Название фрагмента: Итоги семинара и рекомендации**

**Предыдущий контекст:** В предыдущем фрагменте мы обсудили влияние выбросов на метрики MSE и MAE, а также применение метода Bootstrap для оценки доверительных интервалов. Теперь мы подводим итоги семинара и делаем рекомендации по дальнейшему обучению.

## **Итоги семинара и рекомендации**

В ходе семинара мы рассмотрели различные метрики, используемые для оценки качества предсказаний моделей, такие как MSE, MAE, Huber и Log-Cosh. Мы также обсудили, как выбросы в данных могут влиять на эти метрики и как использовать метод Bootstrap для построения доверительных интервалов.

### Основные выводы

1. **Выбор метрики:** Важно выбирать метрику, которая соответствует специфике задачи. Например, если в данных присутствуют выбросы, лучше использовать MAE или Huber, так как они менее чувствительны к большим ошибкам.

2. **Доверительные интервалы:** Построение доверительных интервалов позволяет оценить надежность предсказаний модели. Метод Bootstrap является универсальным инструментом для этой цели.

3. **Центральная предельная теорема:** ЦПТ позволяет использовать нормальное распределение для построения доверительных интервалов, что делает её важным инструментом в статистическом анализе.

### Рекомендации

- **Практика:** Рекомендуется практиковаться в вычислении различных метрик и доверительных интервалов на реальных данных. Это поможет лучше понять, как они работают и как их применять в различных ситуациях.

- **Обсуждение:** Если у вас возникли вопросы или предложения по курсу, не стесняйтесь делиться ими. Обратная связь важна для улучшения качества обучения.

- **Дополнительные материалы:** Мы планируем предоставить дополнительные материалы, такие как PDF с условиями задач, чтобы вы могли лучше подготовиться к следующему семинару.

### Заключение

Спасибо всем за участие в семинаре! Надеемся, что вы получили полезные знания и навыки, которые сможете применить в своей практике. Если у вас есть какие-либо вопросы или комментарии, пожалуйста, пишите в чат или обращайтесь напрямую. Желаем вам удачи в дальнейших исследованиях и обучении!
